{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2a9654",
   "metadata": {},
   "source": [
    "## initial ERP analysis \n",
    "(1st click and eyes closed data for healthy subjects, just for analyses purposes)\n",
    "\n",
    "for classification and anomaly detection, skip to section \"feature extraction: healthy subjects resting state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fbde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat \n",
    "import mne, glob \n",
    "import pandas as pd\n",
    "import mat73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242a165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PreProcessed_AD001_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD002_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD003_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD004_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD006_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD008_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD010_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD011_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD012_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD013_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD014_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD015_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD016_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD017_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD018_Preprocessed_FirstClick.mat',\n",
       " 'PreProcessed_AD020_Preprocessed_FirstClick.mat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the matfiles in the current directory \n",
    "matfiles = glob.glob('*.mat')\n",
    "\n",
    "data = {}\n",
    "matfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5da13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels are\n",
      "['MEG0112+0113' 'MEG0122+0123' 'MEG0132+0133' 'MEG0142+0143'\n",
      " 'MEG0212+0213' 'MEG0222+0223' 'MEG0232+0233' 'MEG0242+0243'\n",
      " 'MEG0312+0313' 'MEG0322+0323' 'MEG0332+0333' 'MEG0342+0343'\n",
      " 'MEG0412+0413' 'MEG0422+0423' 'MEG0432+0433' 'MEG0442+0443'\n",
      " 'MEG0512+0513' 'MEG0522+0523' 'MEG0532+0533' 'MEG0542+0543'\n",
      " 'MEG0612+0613' 'MEG0622+0623' 'MEG0632+0633' 'MEG0642+0643'\n",
      " 'MEG0712+0713' 'MEG0722+0723' 'MEG0732+0733' 'MEG0742+0743'\n",
      " 'MEG0812+0813' 'MEG0822+0823' 'MEG0912+0913' 'MEG0922+0923'\n",
      " 'MEG0932+0933' 'MEG0942+0943' 'MEG1012+1013' 'MEG1022+1023'\n",
      " 'MEG1032+1033' 'MEG1042+1043' 'MEG1112+1113' 'MEG1122+1123'\n",
      " 'MEG1132+1133' 'MEG1142+1143' 'MEG1212+1213' 'MEG1222+1223'\n",
      " 'MEG1232+1233' 'MEG1242+1243' 'MEG1312+1313' 'MEG1322+1323'\n",
      " 'MEG1332+1333' 'MEG1342+1343' 'MEG1412+1413' 'MEG1422+1423'\n",
      " 'MEG1432+1433' 'MEG1442+1443' 'MEG1512+1513' 'MEG1522+1523'\n",
      " 'MEG1532+1533' 'MEG1542+1543' 'MEG1612+1613' 'MEG1622+1623'\n",
      " 'MEG1632+1633' 'MEG1642+1643' 'MEG1712+1713' 'MEG1722+1723'\n",
      " 'MEG1732+1733' 'MEG1742+1743' 'MEG1812+1813' 'MEG1822+1823'\n",
      " 'MEG1832+1833' 'MEG1842+1843' 'MEG1912+1913' 'MEG1922+1923'\n",
      " 'MEG1932+1933' 'MEG1942+1943' 'MEG2012+2013' 'MEG2022+2023'\n",
      " 'MEG2032+2033' 'MEG2042+2043' 'MEG2112+2113' 'MEG2122+2123'\n",
      " 'MEG2132+2133' 'MEG2142+2143' 'MEG2212+2213' 'MEG2222+2223'\n",
      " 'MEG2232+2233' 'MEG2242+2243' 'MEG2312+2313' 'MEG2322+2323'\n",
      " 'MEG2332+2333' 'MEG2342+2343' 'MEG2412+2413' 'MEG2422+2423'\n",
      " 'MEG2432+2433' 'MEG2442+2443' 'MEG2512+2513' 'MEG2522+2523'\n",
      " 'MEG2532+2533' 'MEG2542+2543' 'MEG2612+2613' 'MEG2622+2623'\n",
      " 'MEG2632+2633' 'MEG2642+2643']\n",
      "<U12\n"
     ]
    }
   ],
   "source": [
    "data_for_chan=mat73.loadmat(matfiles[0])\n",
    "data_chan = pd.DataFrame.from_dict(data_for_chan)\n",
    "chan=data_chan.iloc[4,0]\n",
    "result_array = np.array([item for sublist in chan for item in sublist], dtype=str)\n",
    "result_array\n",
    "channels=result_array[0:102]\n",
    "print('channels are')\n",
    "print(channels)\n",
    "print(channels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228d7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = channels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ec460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=data_chan.iloc[2,0]\n",
    "pos=location['chanpos']\n",
    "position=pos[0:102,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91eaf865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00075722e+01,  3.65128630e+00, -2.25105759e+00],\n",
       "       [-1.00621064e+01,  5.41282576e+00,  1.21426809e+00],\n",
       "       [-1.05140172e+01,  2.08403908e+00,  1.12193825e+00],\n",
       "       [-1.01240423e+01,  2.99298532e-01, -2.43275739e+00],\n",
       "       [-1.08367367e+01,  2.42531954e+00,  4.56424844e+00],\n",
       "       [-1.04351099e+01,  3.27754793e+00,  7.96055022e+00],\n",
       "       [-1.04496296e+01, -3.25349648e-01,  7.97673586e+00],\n",
       "       [-1.07277930e+01, -9.80692656e-01,  4.55195115e+00],\n",
       "       [-9.09741576e+00,  9.13935512e+00,  4.74954632e+00],\n",
       "       [-9.61617502e+00,  6.87580031e+00,  7.98214670e+00],\n",
       "       [-8.13470060e+00,  7.04733974e+00,  1.11388049e+01],\n",
       "       [-1.03150464e+01,  5.76595163e+00,  4.57486396e+00],\n",
       "       [-9.01232708e+00,  3.53965618e+00,  1.12300844e+01],\n",
       "       [-6.48532589e+00,  3.67729556e+00,  1.38783412e+01],\n",
       "       [-6.42388187e+00,  2.05244753e-01,  1.41232341e+01],\n",
       "       [-9.03684434e+00,  1.97289632e-02,  1.13746798e+01],\n",
       "       [-7.07210463e+00,  1.19415687e+01,  5.40785941e+00],\n",
       "       [-4.16394793e+00,  1.35577312e+01,  6.11421700e+00],\n",
       "       [-4.52085838e+00,  1.23830239e+01,  9.23438019e+00],\n",
       "       [-7.70068027e+00,  1.03274429e+01,  8.46208411e+00],\n",
       "       [-4.92502678e+00,  1.01580182e+01,  1.19057413e+01],\n",
       "       [-1.46904798e+00,  7.67545381e+00,  1.45639508e+01],\n",
       "       [-3.23796088e+00,  4.23655394e+00,  1.53834322e+01],\n",
       "       [-5.06940022e+00,  7.23435429e+00,  1.36802152e+01],\n",
       "       [-3.10327932e+00,  8.92683020e-01,  1.57962249e+01],\n",
       "       [ 5.82680683e-01,  1.10865396e+00,  1.62393270e+01],\n",
       "       [ 8.13844449e-01, -2.28044256e+00,  1.59580808e+01],\n",
       "       [-2.86801226e+00, -2.53504521e+00,  1.55062437e+01],\n",
       "       [-8.97337326e-01,  1.42329481e+01,  6.63004480e+00],\n",
       "       [-1.20382954e+00,  1.30013708e+01,  9.77732697e+00],\n",
       "       [ 2.42522017e+00,  1.39411912e+01,  6.89689182e+00],\n",
       "       [ 5.60446129e+00,  1.26692362e+01,  6.92189435e+00],\n",
       "       [ 5.65132128e+00,  1.10953685e+01,  1.00777292e+01],\n",
       "       [ 2.18521635e+00,  1.27638216e+01,  1.00509108e+01],\n",
       "       [-1.40866294e+00,  1.08201497e+01,  1.25320842e+01],\n",
       "       [ 2.18874927e+00,  1.05725641e+01,  1.27611083e+01],\n",
       "       [ 2.24341012e+00,  7.65030012e+00,  1.45698230e+01],\n",
       "       [ 4.17290741e-01,  4.46978855e+00,  1.58123782e+01],\n",
       "       [ 3.95943428e+00,  4.28552814e+00,  1.51443070e+01],\n",
       "       [ 7.05872116e+00,  4.47692730e+00,  1.31724878e+01],\n",
       "       [ 7.43318721e+00,  9.69849792e-01,  1.33551657e+01],\n",
       "       [ 4.22825949e+00,  8.55664076e-01,  1.54133618e+01],\n",
       "       [ 8.03480654e+00,  1.01170118e+01,  6.80013164e+00],\n",
       "       [ 9.62304532e+00,  6.93786213e+00,  6.98193618e+00],\n",
       "       [ 8.01879980e+00,  7.90240925e+00,  1.01025434e+01],\n",
       "       [ 5.79023380e+00,  7.85993961e+00,  1.28339054e+01],\n",
       "       [ 9.22519499e+00,  4.43214600e+00,  1.03242311e+01],\n",
       "       [ 1.05117478e+01,  3.66943307e+00,  7.14145619e+00],\n",
       "       [ 1.08043342e+01,  2.72882709e-01,  7.11004552e+00],\n",
       "       [ 9.63570016e+00,  8.44535943e-01,  1.04120074e+01],\n",
       "       [ 1.02207380e+01,  6.58272016e+00,  3.61291261e+00],\n",
       "       [ 1.11656301e+01,  4.93463700e+00,  3.34197089e-01],\n",
       "       [ 1.17059679e+01,  1.57083265e+00,  2.42070781e-01],\n",
       "       [ 1.10299848e+01,  3.32941198e+00,  3.75281003e+00],\n",
       "       [-1.03379552e+01, -1.26031199e+00,  1.02504831e+00],\n",
       "       [-9.45515192e+00, -4.50042297e+00,  1.22369739e+00],\n",
       "       [-8.29737655e+00, -6.16693577e+00, -2.04848627e+00],\n",
       "       [-9.63336332e+00, -3.04305208e+00, -2.28957226e+00],\n",
       "       [-9.87302244e+00, -4.22689740e+00,  4.56627296e+00],\n",
       "       [-9.64889687e+00, -3.81582542e+00,  7.96817424e+00],\n",
       "       [-7.77701727e+00, -6.91812853e+00,  8.28456143e+00],\n",
       "       [-8.20561265e+00, -7.15110077e+00,  4.81411139e+00],\n",
       "       [-6.23177001e+00, -8.78635903e+00, -1.72803548e+00],\n",
       "       [-7.73866574e+00, -7.41171186e+00,  1.47721966e+00],\n",
       "       [-5.33130411e+00, -9.73106087e+00,  1.85315701e+00],\n",
       "       [-3.44836882e+00, -1.06035082e+01, -1.35558034e+00],\n",
       "       [-8.37903915e+00, -3.45193303e+00,  1.11966596e+01],\n",
       "       [-5.99980473e+00, -3.15251752e+00,  1.38139579e+01],\n",
       "       [-2.49765759e+00, -5.61166368e+00,  1.42454489e+01],\n",
       "       [-5.87798355e+00, -6.71749070e+00,  1.16737912e+01],\n",
       "       [-4.98634692e+00, -9.09600517e+00,  8.69516325e+00],\n",
       "       [-2.71803395e+00, -1.07766792e+01,  5.62141675e+00],\n",
       "       [-2.25904459e+00, -1.10183748e+01,  2.25098417e+00],\n",
       "       [-5.79030770e+00, -9.45968285e+00,  5.20230857e+00],\n",
       "       [-2.12269224e+00, -8.25096067e+00,  1.19870334e+01],\n",
       "       [ 1.57484546e+00, -8.04589388e+00,  1.24216507e+01],\n",
       "       [ 1.85242985e+00, -9.81204911e+00,  9.53954517e+00],\n",
       "       [-1.51636818e+00, -1.00081744e+01,  9.13453794e+00],\n",
       "       [ 6.30978980e-01, -1.11114794e+01,  6.11525887e+00],\n",
       "       [ 1.05794939e+00, -1.13766531e+01,  2.69008724e+00],\n",
       "       [ 3.15549933e+00, -1.12628127e+01, -5.13056830e-01],\n",
       "       [-2.33762061e-01, -1.14600079e+01, -9.30737633e-01],\n",
       "       [ 4.28705681e+00, -2.54328303e+00,  1.50606668e+01],\n",
       "       [ 7.24288297e+00, -2.51087264e+00,  1.30949840e+01],\n",
       "       [ 5.10717288e+00, -6.08788506e+00,  1.29842688e+01],\n",
       "       [ 1.10951205e+00, -5.40196837e+00,  1.46691064e+01],\n",
       "       [ 5.21039970e+00, -8.50221008e+00,  9.92101121e+00],\n",
       "       [ 6.86064161e+00, -8.72234281e+00,  6.74297583e+00],\n",
       "       [ 4.31004745e+00, -1.06355261e+01,  3.05087387e+00],\n",
       "       [ 3.92053972e+00, -1.03996494e+01,  6.42917964e+00],\n",
       "       [ 9.27450528e+00, -2.69366574e+00,  1.02531409e+01],\n",
       "       [ 1.03410781e+01, -3.03872383e+00,  7.01649949e+00],\n",
       "       [ 9.00952918e+00, -6.13785774e+00,  6.89368071e+00],\n",
       "       [ 7.75150518e+00, -6.02371600e+00,  1.01517694e+01],\n",
       "       [ 7.21098318e+00, -9.00982836e+00,  3.38151029e+00],\n",
       "       [ 9.37684442e+00, -6.42429548e+00,  3.55553338e+00],\n",
       "       [ 8.82767393e+00, -7.92012471e+00,  9.29746511e-02],\n",
       "       [ 6.26232421e+00, -1.00385863e+01, -1.88315493e-01],\n",
       "       [ 1.12755016e+01, -1.05608559e-02,  3.66436490e+00],\n",
       "       [ 1.15925312e+01, -1.81707545e+00,  3.02652116e-01],\n",
       "       [ 1.06041664e+01, -5.06650322e+00,  2.54313689e-01],\n",
       "       [ 1.07586397e+01, -3.33236625e+00,  3.68456179e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91578471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #left side channels\n",
    "# ch_aud_loc=[]\n",
    "# for i in range(len(position)):\n",
    "#      if list_1[i] == 'MEG0142+0143' or list_1[i] == 'MEG1512+1513'or list_1[i] == 'MEG1542+1543' or list_1[i] =='MEG1812+1813' or list_1[i] == 'MEG1622+1623' or list_1[i] == 'MEG1522+1523' or list_1[i] == 'MEG1612+1613'or list_1[i] == 'MEG1632+1633'or list_1[i] == 'MEG0232+0233'or list_1[i] == 'MEG0242+0243':\n",
    "#         ch_aud_loc.append(i)\n",
    "# ch_aud_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf15398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #right side channels\n",
    "# ch_aud_loc=[]\n",
    "# for i in range(len(position)):\n",
    "#     if list_1[i] == 'MEG2412+2413' or list_1[i] == 'MEG2222+2223'or list_1[i] == 'MEG2422+2423' or list_1[i] =='MEG2442+2443' or list_1[i] == 'MEG1432+1433' or list_1[i] == 'MEG2612+2613' or list_1[i] == 'MEG2622+2623'or list_1[i] == 'MEG2642+2643'or list_1[i] == 'MEG1332+1333'or list_1[i] == 'MEG1342+1343':\n",
    "#         ch_aud_loc.append(i)\n",
    "# ch_aud_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "047822e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rleft and ight side channels\n",
    "# ch_aud_loc=[]\n",
    "# for i in range(len(position)):\n",
    "#     if list_1[i] == 'MEG2412+2413' or list_1[i] == 'MEG2222+2223'or list_1[i] == 'MEG2422+2423' or list_1[i] =='MEG2442+2443' or list_1[i] == 'MEG1432+1433' or list_1[i] == 'MEG2612+2613' or list_1[i] == 'MEG2622+2623'or list_1[i] == 'MEG2642+2643'or list_1[i] == 'MEG1332+1333'or list_1[i] == 'MEG1342+1343' or list_1[i] == 'MEG0142+0143' or list_1[i] == 'MEG1512+1513'or list_1[i] == 'MEG1542+1543' or list_1[i] =='MEG1812+1813' or list_1[i] == 'MEG1622+1623' or list_1[i] == 'MEG1522+1523' or list_1[i] == 'MEG1612+1613'or list_1[i] == 'MEG1632+1633'or list_1[i] == 'MEG0232+0233'or list_1[i] == 'MEG0242+0243':\n",
    "#         ch_aud_loc.append(i)\n",
    "# ch_aud_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f3801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_aud=list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2883b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfabdc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "61\n",
      "21\n",
      "32\n",
      "35\n",
      "28\n",
      "35\n",
      "28\n",
      "44\n",
      "40\n",
      "34\n",
      "26\n",
      "26\n",
      "26\n",
      "33\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "num_trials=0\n",
    "for subject in range(len(matfiles)):\n",
    "    subject_data = []\n",
    "    dat = mat73.loadmat(matfiles[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    new=data.iloc[7,0]\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c617ec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c46d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 102, 151)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the size of the empty array\n",
    "array_size = (num_trials, 102, 151)\n",
    "\n",
    "# Create an empty array of zeros with the specified size\n",
    "empty_array = np.zeros(array_size)\n",
    "\n",
    "# Display the shape of the empty array\n",
    "print(empty_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c4a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 102, 151)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d8f7a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "31\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(525, 102, 151)\n",
      "31\n",
      "92\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(33, 102, 151)\n",
      "(34, 102, 151)\n",
      "(35, 102, 151)\n",
      "(36, 102, 151)\n",
      "(37, 102, 151)\n",
      "(38, 102, 151)\n",
      "(39, 102, 151)\n",
      "(40, 102, 151)\n",
      "(41, 102, 151)\n",
      "(42, 102, 151)\n",
      "(43, 102, 151)\n",
      "(44, 102, 151)\n",
      "(45, 102, 151)\n",
      "(46, 102, 151)\n",
      "(47, 102, 151)\n",
      "(48, 102, 151)\n",
      "(49, 102, 151)\n",
      "(50, 102, 151)\n",
      "(51, 102, 151)\n",
      "(52, 102, 151)\n",
      "(53, 102, 151)\n",
      "(54, 102, 151)\n",
      "(55, 102, 151)\n",
      "(56, 102, 151)\n",
      "(57, 102, 151)\n",
      "(58, 102, 151)\n",
      "(59, 102, 151)\n",
      "(60, 102, 151)\n",
      "(61, 102, 151)\n",
      "(525, 102, 151)\n",
      "92\n",
      "113\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(525, 102, 151)\n",
      "113\n",
      "145\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(525, 102, 151)\n",
      "145\n",
      "180\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(33, 102, 151)\n",
      "(34, 102, 151)\n",
      "(35, 102, 151)\n",
      "(525, 102, 151)\n",
      "180\n",
      "208\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(525, 102, 151)\n",
      "208\n",
      "243\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(33, 102, 151)\n",
      "(34, 102, 151)\n",
      "(35, 102, 151)\n",
      "(525, 102, 151)\n",
      "243\n",
      "271\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(525, 102, 151)\n",
      "271\n",
      "315\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(33, 102, 151)\n",
      "(34, 102, 151)\n",
      "(35, 102, 151)\n",
      "(36, 102, 151)\n",
      "(37, 102, 151)\n",
      "(38, 102, 151)\n",
      "(39, 102, 151)\n",
      "(40, 102, 151)\n",
      "(41, 102, 151)\n",
      "(42, 102, 151)\n",
      "(43, 102, 151)\n",
      "(44, 102, 151)\n",
      "(525, 102, 151)\n",
      "315\n",
      "355\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(33, 102, 151)\n",
      "(34, 102, 151)\n",
      "(35, 102, 151)\n",
      "(36, 102, 151)\n",
      "(37, 102, 151)\n",
      "(38, 102, 151)\n",
      "(39, 102, 151)\n",
      "(40, 102, 151)\n",
      "(525, 102, 151)\n",
      "355\n",
      "389\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(33, 102, 151)\n",
      "(34, 102, 151)\n",
      "(525, 102, 151)\n",
      "389\n",
      "415\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(525, 102, 151)\n",
      "415\n",
      "441\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(525, 102, 151)\n",
      "441\n",
      "467\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(525, 102, 151)\n",
      "467\n",
      "500\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(26, 102, 151)\n",
      "(27, 102, 151)\n",
      "(28, 102, 151)\n",
      "(29, 102, 151)\n",
      "(30, 102, 151)\n",
      "(31, 102, 151)\n",
      "(32, 102, 151)\n",
      "(33, 102, 151)\n",
      "(525, 102, 151)\n",
      "500\n",
      "525\n",
      "(1, 102, 151)\n",
      "(2, 102, 151)\n",
      "(3, 102, 151)\n",
      "(4, 102, 151)\n",
      "(5, 102, 151)\n",
      "(6, 102, 151)\n",
      "(7, 102, 151)\n",
      "(8, 102, 151)\n",
      "(9, 102, 151)\n",
      "(10, 102, 151)\n",
      "(11, 102, 151)\n",
      "(12, 102, 151)\n",
      "(13, 102, 151)\n",
      "(14, 102, 151)\n",
      "(15, 102, 151)\n",
      "(16, 102, 151)\n",
      "(17, 102, 151)\n",
      "(18, 102, 151)\n",
      "(19, 102, 151)\n",
      "(20, 102, 151)\n",
      "(21, 102, 151)\n",
      "(22, 102, 151)\n",
      "(23, 102, 151)\n",
      "(24, 102, 151)\n",
      "(25, 102, 151)\n",
      "(525, 102, 151)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject in range(len(matfiles)):\n",
    "    subject_data = []\n",
    "    dat = mat73.loadmat(matfiles[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    for trial1 in range(0,len(new)):\n",
    "        # Simulating data for demonstration purposes\n",
    "        trial=new[trial1][0:102,200:351]\n",
    "        subject_data.append(trial)\n",
    "        sub_data=np.array(subject_data)\n",
    "        print(sub_data.shape)\n",
    "    \n",
    "    empty_array[start:num_trials,:,:]=sub_data\n",
    "    start=num_trials\n",
    "    end=num_trials\n",
    "    print(empty_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efabd922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.52651669e-12 2.47600476e-12 2.39582113e-12 ... 4.87943089e-12\n",
      "   5.24331335e-12 5.53127524e-12]\n",
      "  [3.00274355e-12 3.06934650e-12 3.06917920e-12 ... 7.00144127e-12\n",
      "   7.21571077e-12 7.33876674e-12]\n",
      "  [4.60371772e-12 4.85297196e-12 5.14311980e-12 ... 5.15999249e-12\n",
      "   5.89760516e-12 6.59613941e-12]\n",
      "  ...\n",
      "  [2.51959351e-12 2.43530450e-12 2.28739941e-12 ... 2.10148503e-12\n",
      "   2.29641088e-12 2.42910050e-12]\n",
      "  [3.71650909e-13 7.57128257e-13 1.16042836e-12 ... 2.75861843e-12\n",
      "   2.94515765e-12 3.09937576e-12]\n",
      "  [3.23381437e-12 3.19679950e-12 3.10008145e-12 ... 1.51949197e-12\n",
      "   1.82265921e-12 2.09418933e-12]]\n",
      "\n",
      " [[2.46599728e-12 2.40724851e-12 2.35484571e-12 ... 2.40537979e-12\n",
      "   2.82981085e-12 3.38114018e-12]\n",
      "  [4.26617941e-12 4.26770867e-12 4.28197451e-12 ... 2.95341723e-12\n",
      "   2.91405728e-12 2.90021981e-12]\n",
      "  [4.45670133e-12 4.78947119e-12 5.01931613e-12 ... 5.46739117e-13\n",
      "   3.82075581e-13 2.53107341e-13]\n",
      "  ...\n",
      "  [3.62459995e-12 4.16875426e-12 4.69889657e-12 ... 1.22666552e-12\n",
      "   1.58744673e-12 1.97482153e-12]\n",
      "  [3.56427500e-12 3.00664726e-12 2.55049221e-12 ... 1.48100710e-12\n",
      "   1.86761457e-12 2.22527379e-12]\n",
      "  [1.05172082e-11 1.01836008e-11 9.79076862e-12 ... 3.80316358e-12\n",
      "   3.52291199e-12 3.25319703e-12]]\n",
      "\n",
      " [[2.53658011e-12 2.59917103e-12 2.68875890e-12 ... 3.37750897e-12\n",
      "   3.61178371e-12 3.80388794e-12]\n",
      "  [1.16964860e-12 1.08976424e-12 9.60778891e-13 ... 2.08653897e-12\n",
      "   2.10033025e-12 2.10340706e-12]\n",
      "  [2.58617100e-12 3.02681103e-12 3.49243561e-12 ... 1.75731821e-12\n",
      "   1.86361370e-12 1.98659282e-12]\n",
      "  ...\n",
      "  [3.84779830e-12 3.68989426e-12 3.57218602e-12 ... 3.44924964e-12\n",
      "   3.75878782e-12 4.02652652e-12]\n",
      "  [5.20813351e-12 5.80655096e-12 6.37446591e-12 ... 1.72699425e-12\n",
      "   1.09336155e-12 5.06854731e-13]\n",
      "  [9.64869196e-12 1.01996288e-11 1.07223659e-11 ... 5.28278418e-12\n",
      "   5.53211670e-12 5.75780437e-12]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[4.47228042e-12 4.61833103e-12 4.74720588e-12 ... 2.60622603e-12\n",
      "   2.39267500e-12 2.31626998e-12]\n",
      "  [3.37893231e-12 3.10649278e-12 2.82958995e-12 ... 4.24365264e-12\n",
      "   3.97035627e-12 3.68351285e-12]\n",
      "  [4.35226282e-12 4.11195182e-12 3.79185053e-12 ... 3.68778274e-12\n",
      "   3.77677225e-12 3.82392704e-12]\n",
      "  ...\n",
      "  [5.11844575e-12 5.37604387e-12 5.55483006e-12 ... 9.40869981e-12\n",
      "   9.11001538e-12 8.68403349e-12]\n",
      "  [7.52448732e-12 8.04847964e-12 8.42766951e-12 ... 1.01848428e-11\n",
      "   9.76744526e-12 9.27365300e-12]\n",
      "  [1.02369286e-11 1.04932823e-11 1.07012757e-11 ... 9.22685765e-12\n",
      "   9.23943061e-12 9.19023013e-12]]\n",
      "\n",
      " [[6.27998988e-12 6.24373514e-12 6.09928306e-12 ... 3.10454518e-12\n",
      "   2.91667460e-12 2.78107949e-12]\n",
      "  [2.57956155e-12 2.70008107e-12 2.75949017e-12 ... 2.00226808e-12\n",
      "   1.61457483e-12 1.17514735e-12]\n",
      "  [8.89461582e-12 9.13522418e-12 9.26679433e-12 ... 2.35503136e-12\n",
      "   2.55691886e-12 2.78716313e-12]\n",
      "  ...\n",
      "  [3.93586393e-12 3.61936883e-12 3.30212529e-12 ... 2.44074116e-12\n",
      "   1.90355873e-12 1.37649078e-12]\n",
      "  [2.11775848e-12 1.62952792e-12 1.22089436e-12 ... 2.25614133e-12\n",
      "   1.35138548e-12 4.88796468e-13]\n",
      "  [2.67040928e-12 2.46225151e-12 2.24743334e-12 ... 3.29541817e-12\n",
      "   3.15635021e-12 3.02895415e-12]]\n",
      "\n",
      " [[2.62768772e-12 2.70666259e-12 2.76639241e-12 ... 5.65140871e-12\n",
      "   5.68946318e-12 5.70478646e-12]\n",
      "  [7.10364545e-12 7.10064288e-12 7.07644258e-12 ... 5.28600901e-12\n",
      "   5.73176173e-12 6.18094432e-12]\n",
      "  [3.20901760e-12 3.30751323e-12 3.34918025e-12 ... 9.46112585e-12\n",
      "   9.24638776e-12 9.01504209e-12]\n",
      "  ...\n",
      "  [2.95469394e-12 3.14089371e-12 3.33744630e-12 ... 5.52812853e-12\n",
      "   5.86487833e-12 6.21565875e-12]\n",
      "  [3.25378883e-12 3.46293984e-12 3.66172937e-12 ... 7.91371949e-13\n",
      "   1.98555475e-13 5.47788457e-13]\n",
      "  [6.33794683e-12 6.43108472e-12 6.55417434e-12 ... 5.60082960e-12\n",
      "   6.74695853e-12 7.85498573e-12]]]\n"
     ]
    }
   ],
   "source": [
    "aud_data=empty_array[:,:,:]\n",
    "print(aud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dbfcf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channels_aud = len(aud_data[1,:,1])\n",
    "n_channels_aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "308456ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #left side channels\n",
    "#  #   tfa on selected auditory channels of the brain\n",
    "# ch_aud=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1812+1813', 'MEG1622+1623' ,'MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eabaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #right side channels\n",
    "# #tfa on selected auditory channels of the brain\n",
    "# ch_aud=['MEG2412+2413','MEG2222+2223','MEG2422+2423','MEG2442+2443','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643','MEG1332+1333','MEG1342+1343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ef9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ch_aud=10 left side channels and 10 right side channels of brain that correspond to auditory processing\n",
    "#  #   tfa on selected auditory channels of the brain\n",
    "# ch_aud=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1812+1813', 'MEG1622+1623' ,'MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG2412+2413','MEG2222+2223','MEG2422+2423','MEG2442+2443','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643','MEG1332+1333','MEG1342+1343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4fa522",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33cb7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_channels = len(trials_sub[1,:,1])\n",
    "\n",
    "# Initialize an info structure\n",
    "info = mne.create_info(\n",
    "        ch_names = ch_aud,\n",
    "        ch_types = ['grad']*n_channels_aud,\n",
    "        sfreq    = sfreq \n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1bf8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(position)):\n",
    "    info['chs'][i]['loc'][:3]=position[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0676572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 102, 151)\n",
      "(61, 102, 151)\n",
      "(21, 102, 151)\n",
      "(32, 102, 151)\n",
      "(35, 102, 151)\n",
      "(28, 102, 151)\n",
      "(35, 102, 151)\n",
      "(28, 102, 151)\n",
      "(44, 102, 151)\n",
      "(40, 102, 151)\n",
      "(34, 102, 151)\n",
      "(26, 102, 151)\n",
      "(26, 102, 151)\n",
      "(26, 102, 151)\n",
      "(33, 102, 151)\n",
      "(25, 102, 151)\n",
      "Identifying common channels ...\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "# or 'Qt4Agg' depending on your system and Matplotlib version\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directory='D:/internship_ulster_university/figures/erp_1st_click_healthy_all_channels/'\n",
    "\n",
    "\n",
    "\n",
    "# Assume you have a list of trial counts for each subject\n",
    "trial_counts = [31, 61, 21,32,35,28,35,28,44,40,34,26,26,26,33,25]\n",
    "#trial_counts = [45,34,39,44,44]\n",
    "\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "\n",
    "# Loop through subjects\n",
    "for subject_idx, trials in enumerate(trial_counts):\n",
    "    # Extract data for the current subject\n",
    "    subject_data = aud_data[:trials, :, :]  # Adjusted time range\n",
    "    print(subject_data.shape)\n",
    "    \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data = np.mean(subject_data, axis=0)\n",
    "    \n",
    "    # Create Evoked object for the current subject with time information\n",
    "    evoked = mne.EvokedArray(average_data, info)  # Adjusted time range\n",
    "    evoked_list.append(evoked)\n",
    "\n",
    "grand_average_healthy = mne.grand_average(evoked_list)\n",
    "\n",
    "# Plot the grand average\n",
    "fig=grand_average_healthy.plot()\n",
    "# fig.axes[0].set_ylim(data_min, data_max)\n",
    "# Set xlabel and ylabel\n",
    "fig.axes[0].set_xlabel('Time (s)')\n",
    "fig.axes[0].set_ylabel('Amplitude (pT)')\n",
    "\n",
    "    \n",
    "fig.suptitle(f'ERP - ALL Channels')\n",
    "\n",
    "fig.show()\n",
    "fig.patch.set_facecolor('white')\n",
    "   \n",
    "# Save the figure with the specified filename\n",
    "filename = \"all channels.png\"\n",
    "filepath = os.path.join(directory, filename)\n",
    "fig.savefig(filepath)\n",
    "plt.close(fig)  # Close the figure to release memory\n",
    "\n",
    "ylim = fig.axes[0].get_ylim()\n",
    "\n",
    "# Plot the ERP for each channel separately\n",
    "for ch_idx in range(len(info['ch_names'])):\n",
    "    fig=grand_average_healthy.plot(picks=ch_aud[ch_idx], show=False)\n",
    "    \n",
    "    \n",
    "    # Set y-axis limits to match the first plot\n",
    "    fig.axes[0].set_ylim(ylim)\n",
    "    \n",
    "    fig.axes[0].set_xlabel('Time (s)')\n",
    "    fig.axes[0].set_ylabel('Amplitude (pT)')\n",
    "\n",
    "    \n",
    "        # Plot PSD for the current channel\n",
    "    fig.suptitle(f'ERP - Channel {ch_aud[ch_idx]}')\n",
    "\n",
    "    # Optional: Save the plot\n",
    "    # fig.savefig(f'psd_channel_{ch_name}.png')\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    fig.patch.set_facecolor('white')\n",
    "   \n",
    "   # Save the figure with the specified filename\n",
    "    filename = f\"channel_{ch_aud[ch_idx]}.png\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    fig.savefig(filepath)\n",
    "    plt.close(fig)  # Close the figure to release memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7e1c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected .mat files:\n",
      "PreProcessed_AD001_Preprocessed_EC.mat\n",
      "PreProcessed_AD002_Preprocessed_EC.mat\n",
      "PreProcessed_AD003_Preprocessed_EC.mat\n",
      "PreProcessed_AD004_Preprocessed_EC.mat\n",
      "PreProcessed_AD006_Preprocessed_EC.mat\n",
      "PreProcessed_AD008_Preprocessed_EC.mat\n",
      "PreProcessed_AD010_Preprocessed_EC.mat\n",
      "PreProcessed_AD011_Preprocessed_EC.mat\n",
      "PreProcessed_AD012_Preprocessed_EC.mat\n",
      "PreProcessed_AD013_Preprocessed_EC.mat\n",
      "PreProcessed_AD014_Preprocessed_EC.mat\n",
      "PreProcessed_AD015_Preprocessed_EC.mat\n",
      "PreProcessed_AD016_Preprocessed_EC.mat\n",
      "PreProcessed_AD017_Preprocessed_EC.mat\n",
      "PreProcessed_AD018_Preprocessed_EC.mat\n",
      "PreProcessed_AD020_Preprocessed_EC.mat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path2 = \"D:\\internship_ulster_university\\preprocessed_filtered_eyes_closed_healthy\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path2)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "mat_files_rs = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in mat_files_rs:\n",
    "    print(file)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a925978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "num_trials_rs_ec=0\n",
    "for subject in range(len(mat_files_rs)):\n",
    "    subject_data_rs_es = []\n",
    "    dat_rs_ec = mat73.loadmat(mat_files_rs[subject])\n",
    "    data_rs_ec = pd.DataFrame.from_dict(dat_rs_ec)\n",
    "    new_rs_ec=data_rs_ec.iloc[6,0]\n",
    "    print(len(new_rs_ec))\n",
    "    num_trials_rs_ec+=len(new_rs_ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47bc29bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 102, 9901)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the size of the empty array\n",
    "array_size_rs_ec = (num_trials_rs_ec, 102, 9901)\n",
    "\n",
    "# Create an empty array of zeros with the specified size\n",
    "empty_array_rs_ec = np.zeros(array_size_rs_ec)\n",
    "\n",
    "# Display the shape of the empty array\n",
    "print(empty_array_rs_ec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "306ae13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "16\n",
      "nu actual\n",
      "1\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "2\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "3\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "4\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "5\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "6\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "7\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "8\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "9\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "10\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "11\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "12\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "13\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "14\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "15\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "16\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "16\n",
      "16\n",
      "nu actual\n",
      "17\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "18\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "19\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "20\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "21\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "22\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "23\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "24\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "25\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "26\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "27\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "28\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "29\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "30\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "31\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "32\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "32\n",
      "16\n",
      "nu actual\n",
      "33\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "34\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "35\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "36\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "37\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "38\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "39\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "40\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "41\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "42\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "43\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "44\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "45\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "46\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "47\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "48\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "48\n",
      "16\n",
      "nu actual\n",
      "49\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "50\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "51\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "52\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "53\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "54\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "55\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "56\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "57\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "58\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "59\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "60\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "61\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "62\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "63\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "64\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "64\n",
      "16\n",
      "nu actual\n",
      "65\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "66\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "67\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "68\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "69\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "70\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "71\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "72\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "73\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "74\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "75\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "76\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "77\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "78\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "79\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "80\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "80\n",
      "16\n",
      "nu actual\n",
      "81\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "82\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "83\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "84\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "85\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "86\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "87\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "88\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "89\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "90\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "91\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "92\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "93\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "94\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "95\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "96\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "96\n",
      "16\n",
      "nu actual\n",
      "97\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "98\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "99\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "100\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "101\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "102\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "103\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "104\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "105\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "106\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "107\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "108\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "109\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "110\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "111\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "112\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "112\n",
      "16\n",
      "nu actual\n",
      "113\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "114\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "115\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "116\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "117\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "118\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "119\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "120\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "121\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "122\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "123\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "124\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "125\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "126\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "127\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "128\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "128\n",
      "16\n",
      "nu actual\n",
      "129\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "130\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "131\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "132\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "133\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "134\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "135\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "136\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "137\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "138\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "139\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "140\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "141\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "142\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "143\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "144\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "144\n",
      "16\n",
      "nu actual\n",
      "145\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "146\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "147\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "148\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "149\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "150\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "151\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "152\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "153\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "154\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "155\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "156\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "157\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "158\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "159\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "160\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "160\n",
      "16\n",
      "nu actual\n",
      "161\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "162\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "163\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "164\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "165\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "166\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "167\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "168\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "169\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "170\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "171\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "172\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "173\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "174\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "175\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "176\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "176\n",
      "16\n",
      "nu actual\n",
      "177\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "178\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "179\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "180\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "181\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "182\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "183\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "184\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "185\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "186\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "187\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "188\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "189\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "190\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "191\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "192\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "192\n",
      "16\n",
      "nu actual\n",
      "193\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "194\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "195\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "196\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "197\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "198\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "199\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "200\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "201\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "202\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "203\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "204\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "205\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "206\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "207\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "208\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "208\n",
      "16\n",
      "nu actual\n",
      "209\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "210\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "211\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "212\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "213\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "214\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "215\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "216\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "217\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "218\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "219\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "220\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "221\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "222\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "223\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "224\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "224\n",
      "16\n",
      "nu actual\n",
      "225\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "226\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "227\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "228\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "229\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "230\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "231\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "232\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "233\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "234\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "235\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "236\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "237\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "238\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "239\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "240\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n",
      "240\n",
      "16\n",
      "nu actual\n",
      "241\n",
      "(1, 102, 9901)\n",
      "nu actual\n",
      "242\n",
      "(2, 102, 9901)\n",
      "nu actual\n",
      "243\n",
      "(3, 102, 9901)\n",
      "nu actual\n",
      "244\n",
      "(4, 102, 9901)\n",
      "nu actual\n",
      "245\n",
      "(5, 102, 9901)\n",
      "nu actual\n",
      "246\n",
      "(6, 102, 9901)\n",
      "nu actual\n",
      "247\n",
      "(7, 102, 9901)\n",
      "nu actual\n",
      "248\n",
      "(8, 102, 9901)\n",
      "nu actual\n",
      "249\n",
      "(9, 102, 9901)\n",
      "nu actual\n",
      "250\n",
      "(10, 102, 9901)\n",
      "nu actual\n",
      "251\n",
      "(11, 102, 9901)\n",
      "nu actual\n",
      "252\n",
      "(12, 102, 9901)\n",
      "nu actual\n",
      "253\n",
      "(13, 102, 9901)\n",
      "nu actual\n",
      "254\n",
      "(14, 102, 9901)\n",
      "nu actual\n",
      "255\n",
      "(15, 102, 9901)\n",
      "nu actual\n",
      "256\n",
      "(16, 102, 9901)\n",
      "(256, 102, 9901)\n"
     ]
    }
   ],
   "source": [
    "# Number of subjects\n",
    "num_subjects = 5\n",
    "trial_counts=[]\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 401)\n",
    "num_trials=0\n",
    "start=0\n",
    "num_actual_trials=0\n",
    "\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject in range(len(mat_files_rs)):\n",
    "    \n",
    "    dat = mat73.loadmat(mat_files_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    new=data.iloc[6,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials-num_actual_trials\n",
    "    print(end)\n",
    "    trial_counts.append(num_actual_trials)\n",
    "  \n",
    "    subject_data = []\n",
    "    for trial1 in range(0,len(new)):\n",
    "        # Simulating data for demonstration purposes\n",
    "        trial=new[trial1][0:102,:9901]\n",
    "        \n",
    "        num_actual_trials=num_actual_trials+1\n",
    "        print(\"nu actual\")\n",
    "        print(num_actual_trials)\n",
    "        subject_data.append(trial)\n",
    "        #print(subject_data)\n",
    "        sub_data=np.array(subject_data)\n",
    "        print(sub_data.shape)\n",
    "    \n",
    "    empty_array_rs_ec[start:num_actual_trials,:,:]=sub_data\n",
    "    start=num_actual_trials\n",
    "    end=num_actual_trials\n",
    "    print(empty_array_rs_ec.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6146b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 102, 9901)\n"
     ]
    }
   ],
   "source": [
    "aud_data_rsec = empty_array_rs_ec[:,:,:]\n",
    "print(aud_data_rsec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91bf3a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_counts=[16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16]\n",
    "#tr_counts=[16,16,16,16]\n",
    "tr_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ff8f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying common channels ...\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n",
      "Need more than one channel to make topography for grad. Disabling interactivity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need more than one channel to make topography for grad. Disabling interactivity.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')  # or 'Qt4Agg' depending on your system and Matplotlib version\n",
    "\n",
    "directory='D:/internship_ulster_university/figures/erp_resting_state_eyes_closed_healthy_all_channels/'\n",
    "\n",
    "\n",
    "\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list_rs_ec = []\n",
    "\n",
    "# Loop through subjects\n",
    "for subject_idx, trials in enumerate(tr_counts):\n",
    "    # Extract data for the current subject\n",
    "    subject_data_rsec= aud_data_rsec[:trials, :, :]\n",
    "    \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_rsec = np.mean(subject_data_rsec, axis=0)\n",
    "    \n",
    "    \n",
    "    # Create Evoked object for the current subject\n",
    "    evoked_rsec = mne.EvokedArray(average_data_rsec, info)\n",
    "    \n",
    "    # Append the Evoked object to the list\n",
    "    evoked_list_rs_ec.append(evoked_rsec)\n",
    "\n",
    "# Compute the grand average across subjects\n",
    "grand_average_rsec_healthy = mne.grand_average(evoked_list_rs_ec)\n",
    "\n",
    "\n",
    "# Plot the grand average\n",
    "fig=grand_average_rsec_healthy.plot()\n",
    "\n",
    "\n",
    "fig.axes[0].set_xlabel('Time (s)')\n",
    "fig.axes[0].set_ylabel('Amplitude (pT)')\n",
    "\n",
    " \n",
    "fig.suptitle(f'ERP - ALL Channels')\n",
    "\n",
    "fig.show()\n",
    "fig.patch.set_facecolor('white')\n",
    "   \n",
    "# Save the figure with the specified filename\n",
    "filename = \"all channels resting state eyes closed.png\"\n",
    "filepath = os.path.join(directory, filename)\n",
    "fig.savefig(filepath)\n",
    "plt.close(fig)  # Close the figure to release memory\n",
    "\n",
    "ylim = fig.axes[0].get_ylim()\n",
    "\n",
    "# Plot the ERP for each channel separately\n",
    "for ch_idx in range(len(info['ch_names'])):\n",
    "    fig=grand_average_rsec_healthy.plot(picks=ch_aud[ch_idx], show=False)\n",
    "    \n",
    "    \n",
    "    fig.axes[0].set_ylim(ylim)\n",
    "    fig.axes[0].set_xlabel('Time (s)')\n",
    "    fig.axes[0].set_ylabel('Amplitude (pT)')\n",
    "\n",
    "        # Plot PSD for the current channel\n",
    "    fig.suptitle(f'ERP - Channel {ch_aud[ch_idx]}')\n",
    "\n",
    "    # Optional: Save the plot\n",
    "    # fig.savefig(f'psd_channel_{ch_name}.png')\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    fig.patch.set_facecolor('white')\n",
    "   \n",
    "   # Save the figure with the specified filename\n",
    "    filename = f\"channel_{ch_aud[ch_idx]}.png\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    fig.savefig(filepath)\n",
    "    plt.close(fig)  # Close the figure to release memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb77bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5fb856b",
   "metadata": {},
   "source": [
    "# feature extraction: healthy subjects resting state  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc8b7d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected .mat files:\n",
      "PreProcessed_AD001_Preprocessed_EC.mat\n",
      "PreProcessed_AD001_Preprocessed_EO.mat\n",
      "PreProcessed_AD002_Preprocessed_EC.mat\n",
      "PreProcessed_AD002_Preprocessed_EO.mat\n",
      "PreProcessed_AD003_Preprocessed_EC.mat\n",
      "PreProcessed_AD003_Preprocessed_EO.mat\n",
      "PreProcessed_AD004_Preprocessed_EC.mat\n",
      "PreProcessed_AD004_Preprocessed_EO.mat\n",
      "PreProcessed_AD006_Preprocessed_EC.mat\n",
      "PreProcessed_AD006_Preprocessed_EO.mat\n",
      "PreProcessed_AD008_Preprocessed_EC.mat\n",
      "PreProcessed_AD008_Preprocessed_EO.mat\n",
      "PreProcessed_AD010_Preprocessed_EC.mat\n",
      "PreProcessed_AD010_Preprocessed_EO.mat\n",
      "PreProcessed_AD011_Preprocessed_EC.mat\n",
      "PreProcessed_AD011_Preprocessed_EO.mat\n",
      "PreProcessed_AD012_Preprocessed_EC.mat\n",
      "PreProcessed_AD012_Preprocessed_EO.mat\n",
      "PreProcessed_AD013_Preprocessed_EC.mat\n",
      "PreProcessed_AD013_Preprocessed_EO.mat\n",
      "PreProcessed_AD014_Preprocessed_EC.mat\n",
      "PreProcessed_AD014_Preprocessed_EO.mat\n",
      "PreProcessed_AD015_Preprocessed_EC.mat\n",
      "PreProcessed_AD015_Preprocessed_EO.mat\n",
      "PreProcessed_AD016_Preprocessed_EC.mat\n",
      "PreProcessed_AD016_Preprocessed_EO.mat\n",
      "PreProcessed_AD017_Preprocessed_EC.mat\n",
      "PreProcessed_AD017_Preprocessed_EO.mat\n",
      "PreProcessed_AD018_Preprocessed_EC.mat\n",
      "PreProcessed_AD018_Preprocessed_EO.mat\n",
      "PreProcessed_AD020_Preprocessed_EC.mat\n",
      "PreProcessed_AD020_Preprocessed_EO.mat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_healthy_rs\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_healthy_rs = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_healthy_rs:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d2eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcessed_AD001_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD001_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD002_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD002_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD003_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD003_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD004_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD004_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD006_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD006_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD008_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD008_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD010_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD010_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD011_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD011_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD012_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD012_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD013_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD013_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD014_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD014_Preprocessed_EO.mat\n"
     ]
    }
   ],
   "source": [
    "num_trials=0\n",
    "trial_counts_healthy_rs=[]\n",
    "for subject in range(len(matfiles_healthy_rs)):\n",
    "    subject_data = []\n",
    "    name=matfiles_healthy_rs[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_healthy_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_healthy_rs.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trial_counts_healthy_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e576874",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df986bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_healthy_rs = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_healthy_rs):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_healthy_rs[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_healthy_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "   # Create RawArray object for the current trial\n",
    "    raw = mne.io.RawArray(average_data_healthy, info)\n",
    "\n",
    "    # Append the Raw object to the list\n",
    "    raw_list_mean_healthy_rs.append(raw)\n",
    "    print(len(raw_list_mean_healthy_rs))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_healthy_rs = mne.concatenate_raws(raw_list_mean_healthy_rs)\n",
    "\n",
    "# print(len(raw_combined_mean_healthy_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f933fdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_healthy_rs = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_healthy_rs):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_healthy_rs[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_healthy_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "   # Create RawArray object for the current trial\n",
    "    raw = mne.io.RawArray(average_data_healthy, info)\n",
    "\n",
    "    # Append the Raw object to the list\n",
    "    raw_list_mean_healthy_rs.append(raw)\n",
    "    print(len(raw_list_mean_healthy_rs))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_healthy_rs = mne.concatenate_raws(raw_list_mean_healthy_rs)\n",
    "\n",
    "# print(len(raw_combined_mean_healthy_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2116705",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_mean_healthy_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b156e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# Define frequency bands\n",
    "alpha_band = (8, 13)  # Alpha band frequencies\n",
    "beta_band = (13, 30)  # Beta band frequencies\n",
    "\n",
    "features_psd_healthy_rs = []\n",
    "for raw in raw_list_mean_healthy_rs:\n",
    "    # Compute PSD\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=0, fmax=40, tmin=None, tmax=None)\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    \n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(ch_aud):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "\n",
    "    # Statistical Features\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "    \n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        print('mean_power')\n",
    "        print(mean_power)\n",
    "        print('v_power')\n",
    "        print(variance_power)\n",
    "        print('s_power')\n",
    "        print(skewness_power)\n",
    "\n",
    "    # Frequency-Domain Features\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            # Compute entropy for alpha band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Compute entropy for beta band\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        \n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "    \n",
    "    features_psd_healthy_rs.append(features)\n",
    "    \n",
    "features_psd_healthy_rs = np.array(features_psd_healthy_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features_psd_healthy_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03665f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_psd_healthy_rs[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_healthy_rs = np.delete(features_psd_healthy_rs, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_healthy_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999fa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "features_erp_healthy_rs = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_healthy_rs):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_healthy_rs[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_healthy_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end) \n",
    "    print(new[0].shape)\n",
    "    trial_data=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "    \n",
    "# Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "\n",
    "\n",
    "# Iterate through channels\n",
    "    for ch_idx in range(len(info['ch_names'])):\n",
    "        # Extract ERP data for the current channel\n",
    "        channel_data = average_data_healthy[ch_idx,:]\n",
    "        \n",
    "    \n",
    "    # Compute peak amplitude and latency\n",
    "        peak_amplitude = np.max(channel_data)\n",
    "         # Compute peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "        print('ptp amp for ch')\n",
    "        print(ch_idx)\n",
    "        print(peak_to_peak_amplitude)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "        # Compute mean absolute amplitude\n",
    "        mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "        print('ma amp for ch')\n",
    "        print(ch_idx)\n",
    "        print(mean_absolute_amplitude)\n",
    "        mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "            # Compute RMS amplitude\n",
    "        rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "        print('rms amp for ch')\n",
    "        print(ch_idx)\n",
    "        print(rms_amplitude)\n",
    "        rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "        # Compute standard deviation\n",
    "        std_dev = np.std(channel_data)\n",
    "        print('std for ch')\n",
    "        print(ch_idx)\n",
    "        print(std_dev)\n",
    "        std_devs.append(std_dev)\n",
    "\n",
    "        # Compute skewness\n",
    "        skewness = skew(channel_data)\n",
    "        print('s for ch')\n",
    "        print(ch_idx)\n",
    "        print(skewness)\n",
    "        skewness_values.append(skewness)\n",
    "\n",
    "        # Compute kurtosis\n",
    "        kurtosis_val = kurtosis(channel_data)\n",
    "        print('k for ch')\n",
    "        print(ch_idx)\n",
    "        print(kurtosis_val)\n",
    "        kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "        # Compute zero crossing rate\n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        print('zc for ch')\n",
    "        print(ch_idx)\n",
    "        print(zero_crossings)\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "        \n",
    "\n",
    "        latency = times[np.argmax(channel_data)]\n",
    "        print('l for ch')\n",
    "        print(ch_idx)\n",
    "        print(latency)\n",
    "    \n",
    "    # Calculate area under the curve (AUC)\n",
    "        auc_value = simps(channel_data, times)\n",
    "    \n",
    "    # Calculate slope (e.g., by fitting a linear regression model)\n",
    "    # You can use numpy's polyfit function for this purpose\n",
    "        slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "        slope = slope_coefficients[0]\n",
    "        \n",
    "        \n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        # Compute AAR\n",
    "        aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "        aar_values.append(aar)\n",
    "\n",
    "        # Compute ZORK\n",
    "        zork = zero_crossings / kurtosis_val\n",
    "        zork_values.append(zork)\n",
    "\n",
    "        \n",
    "        channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                            peak_to_peak_amplitude, \n",
    "                                 mean_absolute_amplitude, \n",
    "                                 rms_amplitude, \n",
    "                                 std_dev, \n",
    "                                 skewness, \n",
    "                                 kurtosis_val, \n",
    "                                 zero_crossings,aar,zork]\n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "\n",
    "    \n",
    "    features_erp_healthy_rs.append(features)\n",
    "    \n",
    "features_erp_healthy_rs = np.array(features_erp_healthy_rs,dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4be3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_erp_healthy_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Iterate over each element of the feature array\n",
    "nan_found = False\n",
    "for i in range(features_erp_healthy_rs.shape[0]):\n",
    "    for j in range(features_erp_healthy_rs.shape[1]):\n",
    "        for k in range(features_erp_healthy_rs.shape[2]):\n",
    "            # Check if the current element is NaN\n",
    "            print(features_erp_healthy_rs[i, j, k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cc8f7",
   "metadata": {},
   "source": [
    "# feature extraction: healthy subjects task state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75463c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_healthy_ts\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_healthy_ts = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_healthy_ts:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matfiles_healthy_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41329c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials=0\n",
    "trial_counts_healthy_ts=[]\n",
    "for subject in range(len(matfiles_healthy_ts)):\n",
    "    subject_data = []\n",
    "    name=matfiles_healthy_ts[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_healthy_ts[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_healthy_ts.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5110dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_counts_healthy_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f735582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_healthy_ts = []\n",
    "\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_healthy_ts):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    print('trial is')\n",
    "    print(trials)\n",
    "    \n",
    "    name=matfiles_healthy_ts[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_healthy_ts[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    print(len(new))\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "#     print(start)\n",
    "    end=num_trials\n",
    "#     print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            #print(new[trial][:102,200:351].shape)\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "#     print('trial data')\n",
    "#     print(len(trial_data))\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print('all trial data for subject after mean')\n",
    "    print(average_data_healthy.shape)\n",
    "   # Create RawArray object for the current trial\n",
    "    raw = mne.io.RawArray(average_data_healthy, info)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Append the Raw object to the list\n",
    "    raw_list_mean_healthy_ts.append(raw)\n",
    "#     print(len(raw_list_mean_healthy_ts))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_healthy_ts = mne.concatenate_raws(raw_list_mean_healthy_ts)\n",
    "\n",
    "# print(len(raw_combined_mean_healthy_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a66c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_mean_healthy_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "features_psd_healthy_ts = []\n",
    "for raw in raw_list_mean_healthy_ts:\n",
    "    # Compute PSD\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=0, fmax=40, tmin=None, tmax=None)\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    \n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(ch_aud):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "        print(psd_data.shape)\n",
    "        \n",
    "\n",
    "    # Statistical Features\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        print(band_power_alpha)\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        features.append(channel_features)\n",
    "    features_psd_healthy_ts.append(features)  \n",
    "features_psd_healthy_ts = np.array(features_psd_healthy_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_psd_healthy_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_psd_healthy_ts[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_healthy_ts = np.delete(features_psd_healthy_ts, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_healthy_ts[0,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b42f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_healthy_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "features_erp_healthy_ts = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_healthy_ts):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_healthy_ts[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_healthy_ts[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end) \n",
    "    print(new[0].shape)\n",
    "    trial_data=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "    \n",
    "# Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "\n",
    "\n",
    "# Iterate through channels\n",
    "    for ch_idx in range(len(info['ch_names'])):\n",
    "        # Extract ERP data for the current channel\n",
    "        channel_data = average_data_healthy[ch_idx,:]\n",
    "        \n",
    "    \n",
    "    # Compute peak amplitude and latency\n",
    "        peak_amplitude = np.max(channel_data)\n",
    "         # Compute peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "        # Compute mean absolute amplitude\n",
    "        mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "        mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "            # Compute RMS amplitude\n",
    "        rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "        rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "        # Compute standard deviation\n",
    "        std_dev = np.std(channel_data)\n",
    "        std_devs.append(std_dev)\n",
    "\n",
    "        # Compute skewness\n",
    "        skewness = skew(channel_data)\n",
    "        skewness_values.append(skewness)\n",
    "\n",
    "        # Compute kurtosis\n",
    "        kurtosis_val = kurtosis(channel_data)\n",
    "        kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "        # Compute zero crossing rate\n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        latency = times[np.argmax(channel_data)]\n",
    "    \n",
    "    # Calculate area under the curve (AUC)\n",
    "        auc_value = simps(channel_data, times)\n",
    "    \n",
    "    # Calculate slope (e.g., by fitting a linear regression model)\n",
    "    # You can use numpy's polyfit function for this purpose\n",
    "        slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "        slope = slope_coefficients[0]\n",
    "        \n",
    "        \n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        # Compute AAR\n",
    "        aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "        aar_values.append(aar)\n",
    "\n",
    "        # Compute ZORK\n",
    "        zork = zero_crossings / kurtosis_val\n",
    "        zork_values.append(zork)\n",
    "        \n",
    "        channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                            peak_to_peak_amplitude, \n",
    "                                 mean_absolute_amplitude, \n",
    "                                 rms_amplitude, \n",
    "                                 std_dev, \n",
    "                                 skewness, \n",
    "                                 kurtosis_val, \n",
    "                                 zero_crossings,aar,zork]\n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "\n",
    "    \n",
    "    features_erp_healthy_ts.append(features)\n",
    "    \n",
    "features_erp_healthy_ts = np.array(features_erp_healthy_ts,dtype=object)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5809994",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_healthy_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e27c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Iterate over each element of the feature array\n",
    "nan_found = False\n",
    "for i in range(features_erp_healthy_ts.shape[0]):\n",
    "    for j in range(features_erp_healthy_ts.shape[1]):\n",
    "        for k in range(features_erp_healthy_ts.shape[2]):\n",
    "            # Check if the current element is NaN\n",
    "            print(features_erp_healthy_ts[i, j, k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f1767",
   "metadata": {},
   "source": [
    "# feature extraction: MCI subjects resting state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_mci_rs\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_mci_rs = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_mci_rs:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb019a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials=0\n",
    "trial_counts_mci_rs=[]\n",
    "for subject in range(len(matfiles_mci_rs)):\n",
    "    subject_data = []\n",
    "    name=matfiles_mci_rs[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_mci_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_mci_rs.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_counts_mci_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4865ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_mci_rs = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_mci_rs):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_mci_rs[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_mci_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "   # Create RawArray object for the current trial\n",
    "    raw = mne.io.RawArray(average_data_healthy, info)\n",
    "\n",
    "    # Append the Raw object to the list\n",
    "    raw_list_mean_mci_rs.append(raw)\n",
    "    print(len(raw_list_mean_mci_rs))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_mci_rs = mne.concatenate_raws(raw_list_mean_mci_rs)\n",
    "\n",
    "# print(len(raw_combined_mean_mci_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f265c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_mean_mci_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde94a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "features_psd_mci_rs = []\n",
    "for raw in raw_list_mean_mci_rs:\n",
    "    # Compute PSD\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=0, fmax=40, tmin=None, tmax=None)\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    \n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(ch_aud):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "    \n",
    "    features_psd_mci_rs.append(features)\n",
    "    \n",
    "features_psd_mci_rs = np.array(features_psd_mci_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_psd_mci_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0706a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_psd_mci_rs[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae06898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_mci_rs = np.delete(features_psd_mci_rs, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_mci_rs[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_mci_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89191196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "features_erp_mci_rs = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_mci_rs):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject) \n",
    "    name=matfiles_mci_rs[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_mci_rs[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]   \n",
    "    num_trials+=len(new)\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end) \n",
    "    print(new[0].shape)\n",
    "    trial_data=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "    \n",
    "# Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "\n",
    "\n",
    "# Iterate through channels\n",
    "    for ch_idx in range(len(info['ch_names'])):\n",
    "        # Extract ERP data for the current channel\n",
    "        channel_data = average_data_healthy[ch_idx,:]\n",
    "        \n",
    "    \n",
    "    # Compute peak amplitude and latency\n",
    "        peak_amplitude = np.max(channel_data)\n",
    "         # Compute peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "        # Compute mean absolute amplitude\n",
    "        mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "        mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "            # Compute RMS amplitude\n",
    "        rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "        rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "        # Compute standard deviation\n",
    "        std_dev = np.std(channel_data)\n",
    "        std_devs.append(std_dev)\n",
    "\n",
    "        # Compute skewness\n",
    "        skewness = skew(channel_data)\n",
    "        skewness_values.append(skewness)\n",
    "\n",
    "        # Compute kurtosis\n",
    "        kurtosis_val = kurtosis(channel_data)\n",
    "        kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "        # Compute zero crossing rate\n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        latency = times[np.argmax(channel_data)]\n",
    "    \n",
    "    # Calculate area under the curve (AUC)\n",
    "        auc_value = simps(channel_data, times)\n",
    "    \n",
    "    # Calculate slope (e.g., by fitting a linear regression model)\n",
    "    # You can use numpy's polyfit function for this purpose\n",
    "        slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "        slope = slope_coefficients[0]\n",
    "        \n",
    "        \n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        # Compute AAR\n",
    "        aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "        aar_values.append(aar)\n",
    "\n",
    "        # Compute ZORK\n",
    "        zork = zero_crossings / kurtosis_val\n",
    "        zork_values.append(zork)\n",
    "        channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                            peak_to_peak_amplitude, \n",
    "                                 mean_absolute_amplitude, \n",
    "                                 rms_amplitude, \n",
    "                                 std_dev, \n",
    "                                 skewness, \n",
    "                                 kurtosis_val, \n",
    "                                 zero_crossings,aar,zork]\n",
    "\n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "\n",
    "    \n",
    "    features_erp_mci_rs.append(features)\n",
    "    \n",
    "features_erp_mci_rs = np.array(features_erp_mci_rs,dtype=object)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49897339",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_mci_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae21bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Iterate over each element of the feature array\n",
    "nan_found = False\n",
    "for i in range(features_erp_mci_rs.shape[0]):\n",
    "    for j in range(features_erp_mci_rs.shape[1]):\n",
    "        for k in range(features_erp_mci_rs.shape[2]):\n",
    "            # Check if the current element is NaN\n",
    "            print(features_erp_mci_rs[i, j, k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ea806",
   "metadata": {},
   "source": [
    "# feature extraction: MCI subjects task state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_mci_ts\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_mci_ts = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_mci_ts:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials=0\n",
    "trial_counts_mci_ts=[]\n",
    "for subject in range(len(matfiles_mci_ts)):\n",
    "    subject_data = []\n",
    "    name=matfiles_mci_ts[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_mci_ts[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_mci_ts.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc923f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_counts_mci_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_mci_ts = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_mci_ts):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_mci_ts[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_mci_ts[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "   # Create RawArray object for the current trial\n",
    "    raw = mne.io.RawArray(average_data_healthy, info)\n",
    "\n",
    "    # Append the Raw object to the list\n",
    "    raw_list_mean_mci_ts.append(raw)\n",
    "    print(len(raw_list_mean_mci_ts))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_mci_ts = mne.concatenate_raws(raw_list_mean_mci_ts)\n",
    "\n",
    "# print(len(raw_combined_mean_mci_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e2ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_mean_mci_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "features_psd_mci_ts = []\n",
    "for raw in raw_list_mean_mci_ts:\n",
    "    # Compute PSD\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=0, fmax=40, tmin=None, tmax=None)\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    \n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(ch_aud):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "\n",
    "    # Statistical Features\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "    \n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        #print('mean_power')\n",
    "        #print(mean_power)\n",
    "#         #print('v_power')\n",
    "#         print(variance_power)\n",
    "#         print('s_power')\n",
    "#         print(skewness_power)\n",
    "\n",
    "    # Frequency-Domain Features\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        \n",
    "                    # Compute entropy for alpha band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Compute entropy for beta band\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        \n",
    " \n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        \n",
    "       \n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "    \n",
    "    features_psd_mci_ts.append(features)\n",
    "    \n",
    "features_psd_mci_ts = np.array(features_psd_mci_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a35c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_psd_mci_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8706621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_mci_ts = np.delete(features_psd_mci_ts, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee32036",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_mci_ts[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afe72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_mci_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "features_erp_mci_ts = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_mci_ts):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_mci_ts[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_mci_ts[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end) \n",
    "    print(new[0].shape)\n",
    "    trial_data=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][ch_aud_loc,:9901])\n",
    "            #trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][ch_aud_loc,200:351])\n",
    "            #trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "    \n",
    "# Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "\n",
    "\n",
    "# Iterate through channels\n",
    "    for ch_idx in range(len(info['ch_names'])):\n",
    "        # Extract ERP data for the current channel\n",
    "        channel_data = average_data_healthy[ch_idx,:]\n",
    "        \n",
    "    \n",
    "    # Compute peak amplitude and latency\n",
    "        peak_amplitude = np.max(channel_data)\n",
    "         # Compute peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "        # Compute mean absolute amplitude\n",
    "        mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "        mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "            # Compute RMS amplitude\n",
    "        rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "        rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "        # Compute standard deviation\n",
    "        std_dev = np.std(channel_data)\n",
    "        std_devs.append(std_dev)\n",
    "\n",
    "        # Compute skewness\n",
    "        skewness = skew(channel_data)\n",
    "        skewness_values.append(skewness)\n",
    "\n",
    "        # Compute kurtosis\n",
    "        kurtosis_val = kurtosis(channel_data)\n",
    "        kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "        # Compute zero crossing rate\n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        latency = times[np.argmax(channel_data)]\n",
    "    \n",
    "    # Calculate area under the curve (AUC)\n",
    "        auc_value = simps(channel_data, times)\n",
    "    \n",
    "    # Calculate slope (e.g., by fitting a linear regression model)\n",
    "    # You can use numpy's polyfit function for this purpose\n",
    "        slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "        slope = slope_coefficients[0]\n",
    "        \n",
    "        \n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        # Compute AAR\n",
    "        aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "        aar_values.append(aar)\n",
    "\n",
    "        # Compute ZORK\n",
    "        zork = zero_crossings / kurtosis_val\n",
    "        zork_values.append(zork)\n",
    "        \n",
    "        peak_to_peak_amplitudes1=np.array(peak_to_peak_amplitudes)\n",
    "        channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                            peak_to_peak_amplitude, \n",
    "                                 mean_absolute_amplitude, \n",
    "                                 rms_amplitude, \n",
    "                                 std_dev, \n",
    "                                 skewness, \n",
    "                                 kurtosis_val, \n",
    "                                 zero_crossings,aar,zork]\n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "\n",
    "    \n",
    "    features_erp_mci_ts.append(features)\n",
    "    \n",
    "features_erp_mci_ts = np.array(features_erp_mci_ts,dtype=object)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_mci_ts[0,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_mci_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae795314",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_healthy_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6641e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_mci_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_healthy_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_mci_ts[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_healthy_ts[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b950b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_mci_rs[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03926d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_psd_healthy_rs[:,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_features_psd_healthy_rs=new_features_psd_healthy_rs[:,:,4:8]\n",
    "print(usable_features_psd_healthy_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b445cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_healthy_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63652883",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_features_psd_healthy_ts=new_features_psd_healthy_ts[:,:,4:8]\n",
    "print(usable_features_psd_healthy_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_erp_healthy_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PSD Features for Resting State data type:\", usable_features_psd_healthy_rs.dtype)\n",
    "print(\"ERP Features for Resting State data type:\", features_erp_healthy_rs.dtype)\n",
    "print(\"PSD Features for Task State data type:\", usable_features_psd_healthy_ts.dtype)\n",
    "print(\"ERP Features for Task State data type:\", features_erp_healthy_ts.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86919652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert variables to NumPy arrays\n",
    "usable_features_psd_healthy_rs = np.array(usable_features_psd_healthy_rs)\n",
    "features_erp_healthy_rs = np.array(features_erp_healthy_rs)\n",
    "usable_features_psd_healthy_ts = np.array(usable_features_psd_healthy_ts)\n",
    "features_erp_healthy_ts = np.array(features_erp_healthy_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_erp_healthy_rs[0,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usable_features_psd_healthy_ts[0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b316e9a",
   "metadata": {},
   "source": [
    "# binary classification: healthy subjects resting state vs healthy subjects task state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "961ca44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine PSD and ERP features for resting state\n",
    "resting_state_features = np.concatenate((usable_features_psd_healthy_rs, features_erp_healthy_rs), axis=2)\n",
    "\n",
    "# Combine PSD and ERP features for task state\n",
    "task_state_features = np.concatenate((usable_features_psd_healthy_ts, features_erp_healthy_ts), axis=2)\n",
    "\n",
    "# Combine the labels\n",
    "resting_state_labels = np.zeros(resting_state_features.shape[0])\n",
    "task_state_labels = np.ones(task_state_features.shape[0])\n",
    "\n",
    "# Combine the features and labels\n",
    "all_features = np.concatenate((resting_state_features, task_state_features), axis=0)\n",
    "all_labels = np.concatenate((resting_state_labels, task_state_labels), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d2cfc5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 20, 17)\n",
      "(32, 20, 17)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "all_features.shape\n",
    "print(resting_state_features.shape)\n",
    "print(task_state_features.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0715d584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.726607352397975"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[1,1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7faa2121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(all_labels.reshape(-1, 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f788a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 340)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reshape all_features\n",
    "reshaped_features = all_features.reshape(all_features.shape[0], -1)  # Flatten the last two dimensions\n",
    "print(reshaped_features.shape)\n",
    "# Add labels as an additional column\n",
    "features_with_labels = np.column_stack((reshaped_features, all_labels.reshape(-1, 1)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(features_with_labels)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('binary_class_healthy_rs_vs_ts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5688c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.726607352397975"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_features[1,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "715a5f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEG2412+2413',\n",
       " 'MEG2222+2223',\n",
       " 'MEG2422+2423',\n",
       " 'MEG2442+2443',\n",
       " 'MEG1432+1433',\n",
       " 'MEG2612+2613',\n",
       " 'MEG2622+2623',\n",
       " 'MEG2642+2643',\n",
       " 'MEG1332+1333',\n",
       " 'MEG1342+1343',\n",
       " 'MEG0142+0143',\n",
       " 'MEG1512+1513',\n",
       " 'MEG1542+1543',\n",
       " 'MEG1812+1813',\n",
       " 'MEG1622+1623',\n",
       " 'MEG1522+1523',\n",
       " 'MEG1612+1613',\n",
       " 'MEG1632+1633',\n",
       " 'MEG0232+0233',\n",
       " 'MEG0242+0243']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3897f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('binary_class_healthy_rs_vs_ts.csv')\n",
    "\n",
    "# Define column names\n",
    "channels = ['MEG2412+2413', 'MEG2222+2223', 'MEG2422+2423', 'MEG2442+2443', 'MEG1432+1433',\n",
    "            'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343',\n",
    "            'MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813', 'MEG1622+1623',\n",
    "            'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "\n",
    "features = ['band_power_alpha', 'band_power_beta', 'spectral_entropy_alpha', 'spectral_entropy_beta',\n",
    "            'peak_amplitude', 'latency', 'auc_value', 'slope', 'peak_to_peak_amplitude',\n",
    "            'mean_absolute_amplitude', 'rms_amplitude', 'std_dev', 'skewness', 'kurtosis_val',\n",
    "            'zero_crossings', 'aar', 'zork']\n",
    "\n",
    "# Generate column names\n",
    "column_names = [f'Channel {channel_idx} {feature}' for channel_idx in range(1, 21) for feature in features]\n",
    "# Add \"labels\" column name\n",
    "column_names.append(\"labels\")\n",
    "# Assign column names to DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('features_and_labels_with_names.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ea51df9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 340)\n",
      "(64, 340)\n",
      "Shape of selected features: (51, 11)\n",
      "Shape of selected test features: (13, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine PSD and ERP features for resting state\n",
    "resting_state_features = np.concatenate((usable_features_psd_healthy_rs, features_erp_healthy_rs), axis=2)\n",
    "\n",
    "# Combine PSD and ERP features for task state\n",
    "task_state_features = np.concatenate((usable_features_psd_healthy_ts, features_erp_healthy_ts), axis=2)\n",
    "\n",
    "# Combine the labels\n",
    "resting_state_labels = np.zeros(resting_state_features.shape[0])\n",
    "task_state_labels = np.ones(task_state_features.shape[0])\n",
    "\n",
    "# Combine the features and labels\n",
    "all_features = np.concatenate((resting_state_features, task_state_features), axis=0)\n",
    "all_labels = np.concatenate((resting_state_labels, task_state_labels), axis=0)\n",
    "\n",
    "\n",
    "indices = np.arange(all_features.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "shuffled_features = all_features[indices]\n",
    "shuffled_labels = all_labels[indices]\n",
    "\n",
    "\n",
    "# Reshape the features for Random Forest\n",
    "n_samples, n_channels, n_features = shuffled_features.shape\n",
    "X_train = shuffled_features.reshape(n_samples, -1)\n",
    "\n",
    "\n",
    "# Convert to float to handle potential non-numeric data\n",
    "X_train = X_train.astype(float)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "# # Find indices of columns with NaN values in train_healthy_selected_features_rsec\n",
    "# nan_indices = np.isnan(X_train).any(axis=0)\n",
    "# # Remove columns with NaN values from train_healthy_selected_features_rsec\n",
    "# X_train1 = X_train[:, ~nan_indices]\n",
    "#     # Print shape after removing NaN columns\n",
    "# print(\"Shape of train_healthy_selected_features_rsec after removing NaN columns:\", X_train1.shape)\n",
    "\n",
    "# # Remove corresponding columns from X_test\n",
    "# from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "# shuffled_labels1=usable_test_features_rsec[:, ~nan_indices]\n",
    "\n",
    "\n",
    "# print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rsec.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, shuffled_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Create the LASSO model\n",
    "lasso = LassoCV(cv=5)\n",
    "\n",
    "# Use SelectFromModel for feature selection\n",
    "sfm = SelectFromModel(lasso)\n",
    "X_train_selected = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Shape of selected features:\", X_train_selected.shape)\n",
    "# Use SelectFromModel to select features for test data\n",
    "X_test_selected = sfm.transform(X_test)\n",
    "\n",
    "# Print the selected features for test data\n",
    "print(\"Shape of selected test features:\", X_test_selected.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e23f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean accuracy: 1.0\n",
      "Accuracy on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a new Random Forest classifier\n",
    "clf_selected = RandomForestClassifier()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf_selected, X_train_selected, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = clf_selected.score(X_test_selected, y_test)\n",
    "print(\"Accuracy on test data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c3342da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         4\n",
      "         1.0       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = clf_selected.predict(X_test_selected)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7dc38bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = clf_selected.predict(X_test_selected)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", fmt=\"d\", xticklabels=['Resting State', 'Task State'], yticklabels=['Resting State', 'Task State'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Random Forest Classifier on Test Data')\n",
    "plt.savefig('confusion_matrix_heatmap.jpeg')  # Save the heatmap as an image\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e28efda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 340)\n",
      "Shape of selected features: (51, 61)\n",
      "Shape of selected features: (51, 61)\n",
      "Shape of selected test features: (13, 61)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine PSD and ERP features for resting state\n",
    "resting_state_features = np.concatenate((usable_features_psd_healthy_rs, features_erp_healthy_rs), axis=2)\n",
    "\n",
    "# Combine PSD and ERP features for task state\n",
    "task_state_features = np.concatenate((usable_features_psd_healthy_ts, features_erp_healthy_ts), axis=2)\n",
    "\n",
    "# Combine the labels\n",
    "resting_state_labels = np.zeros(resting_state_features.shape[0])\n",
    "task_state_labels = np.ones(task_state_features.shape[0])\n",
    "\n",
    "# Combine the features and labels\n",
    "all_features = np.concatenate((resting_state_features, task_state_features), axis=0)\n",
    "all_labels = np.concatenate((resting_state_labels, task_state_labels), axis=0)\n",
    "\n",
    "\n",
    "indices = np.arange(all_features.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "shuffled_features = all_features[indices]\n",
    "shuffled_labels = all_labels[indices]\n",
    "\n",
    "\n",
    "# Reshape the features for Random Forest\n",
    "n_samples, n_channels, n_features = shuffled_features.shape\n",
    "X_train = shuffled_features.reshape(n_samples, -1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, shuffled_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Use SelectFromModel for feature selection\n",
    "sfm = SelectFromModel(clf)\n",
    "X_train_selected = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Shape of selected features:\", X_train_selected.shape)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Shape of selected features:\", X_train_selected.shape)\n",
    "# Use SelectFromModel to select features for test data\n",
    "X_test_selected = sfm.transform(X_test)\n",
    "\n",
    "# Print the selected features for test data\n",
    "print(\"Shape of selected test features:\", X_test_selected.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e41c678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean accuracy: 1.0\n",
      "Accuracy on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a new Random Forest classifier\n",
    "clf_selected = RandomForestClassifier()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf_selected, X_train_selected, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = clf_selected.score(X_test_selected, y_test)\n",
    "print(\"Accuracy on test data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a9a86bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for SVC: [1. 1. 1. 1. 1.]\n",
      "Mean accuracy for SVC: 1.0\n",
      "Accuracy on test data for SVC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define a new SVC classifier\n",
    "clf_selected_svc = SVC()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_svc = cross_val_score(clf_selected_svc, X_train_selected, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores for SVC\n",
    "print(\"Cross-validation scores for SVC:\", cv_scores_svc)\n",
    "print(\"Mean accuracy for SVC:\", np.mean(cv_scores_svc))\n",
    "\n",
    "# Train the SVC classifier on the full training data\n",
    "clf_selected_svc.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy_svc = clf_selected_svc.score(X_test_selected, y_test)\n",
    "print(\"Accuracy on test data for SVC:\", accuracy_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4d77003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = clf_selected_svc.predict(X_test_selected)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", fmt=\"d\", xticklabels=['Resting State', 'Task State'], yticklabels=['Resting State', 'Task State'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for SVC Classifier on Test Data')\n",
    "plt.savefig('confusion_matrix_heatmap.jpeg')  # Save the heatmap as an image\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b314c878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         9\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected_svc.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = clf_selected_svc.predict(X_test_selected)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae086ca9",
   "metadata": {},
   "source": [
    "# binary classification: MCI subjects resting state vs MCI subjects task state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "63f6880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 20, 4)\n"
     ]
    }
   ],
   "source": [
    "usable_features_psd_mci_rs=new_features_psd_mci_rs[:,:,4:8]\n",
    "print(usable_features_psd_mci_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dd739571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 4)\n"
     ]
    }
   ],
   "source": [
    "usable_features_psd_mci_ts=new_features_psd_mci_ts[:,:,4:8]\n",
    "print(usable_features_psd_mci_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8f0f12a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 20, 13)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_mci_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a72f566f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 13)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_mci_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4d64dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSD Features for Resting State data type: object\n",
      "ERP Features for Resting State data type: object\n",
      "PSD Features for Task State data type: object\n",
      "ERP Features for Task State data type: object\n"
     ]
    }
   ],
   "source": [
    "print(\"PSD Features for Resting State data type:\", usable_features_psd_mci_rs.dtype)\n",
    "print(\"ERP Features for Resting State data type:\", features_erp_mci_rs.dtype)\n",
    "print(\"PSD Features for Task State data type:\", usable_features_psd_mci_ts.dtype)\n",
    "print(\"ERP Features for Task State data type:\", features_erp_mci_ts.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9de66220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert variables to NumPy arrays\n",
    "usable_features_psd_mci_rs = np.array(usable_features_psd_mci_rs)\n",
    "features_erp_mci_rs = np.array(features_erp_mci_rs)\n",
    "usable_features_psd_mci_ts = np.array(usable_features_psd_mci_ts)\n",
    "features_erp_mci_ts = np.array(features_erp_mci_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e56dfb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0a22c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine PSD and ERP features for resting state\n",
    "resting_state_features = np.concatenate((usable_features_psd_mci_rs, features_erp_mci_rs), axis=2)\n",
    "\n",
    "# Combine PSD and ERP features for task state\n",
    "task_state_features = np.concatenate((usable_features_psd_mci_ts, features_erp_mci_ts), axis=2)\n",
    "\n",
    "# Combine the labels\n",
    "resting_state_labels = np.zeros(resting_state_features.shape[0])\n",
    "task_state_labels = np.ones(task_state_features.shape[0])\n",
    "\n",
    "# Combine the features and labels\n",
    "all_features = np.concatenate((resting_state_features, task_state_features), axis=0)\n",
    "all_labels = np.concatenate((resting_state_labels, task_state_labels), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "43d7b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 20, 17)\n",
      "(10, 20, 17)\n",
      "(19,)\n"
     ]
    }
   ],
   "source": [
    "all_features.shape\n",
    "print(resting_state_features.shape)\n",
    "print(task_state_features.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2d2db85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 340)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reshape all_features\n",
    "reshaped_features = all_features.reshape(all_features.shape[0], -1)  # Flatten the last two dimensions\n",
    "print(reshaped_features.shape)\n",
    "# Add labels as an additional column\n",
    "features_with_labels = np.column_stack((reshaped_features, all_labels.reshape(-1, 1)))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(features_with_labels)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('binary_class_MCI_rs_vs_ts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "09e015f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('binary_class_MCI_rs_vs_ts.csv')\n",
    "\n",
    "# Define column names\n",
    "channels = ['MEG2412+2413', 'MEG2222+2223', 'MEG2422+2423', 'MEG2442+2443', 'MEG1432+1433',\n",
    "            'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343',\n",
    "            'MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813', 'MEG1622+1623',\n",
    "            'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "\n",
    "features = ['band_power_alpha', 'band_power_beta', 'spectral_entropy_alpha', 'spectral_entropy_beta',\n",
    "            'peak_amplitude', 'latency', 'auc_value', 'slope', 'peak_to_peak_amplitude',\n",
    "            'mean_absolute_amplitude', 'rms_amplitude', 'std_dev', 'skewness', 'kurtosis_val',\n",
    "            'zero_crossings', 'aar', 'zork']\n",
    "\n",
    "# Generate column names\n",
    "column_names = [f'Channel {channel_idx} {feature}' for channel_idx in range(1, 21) for feature in features]\n",
    "# Add \"labels\" column name\n",
    "column_names.append(\"labels\")\n",
    "# Assign column names to DataFrame\n",
    "df.columns = column_names\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv('features_and_labels_with_names.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "185db981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 340)\n",
      "Shape of selected features: (15, 5)\n",
      "Shape of selected test features: (4, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine PSD and ERP features for resting state\n",
    "resting_state_features = np.concatenate((usable_features_psd_mci_rs, features_erp_mci_rs), axis=2)\n",
    "\n",
    "# Combine PSD and ERP features for task state\n",
    "task_state_features = np.concatenate((usable_features_psd_mci_ts, features_erp_mci_ts), axis=2)\n",
    "\n",
    "# Combine the labels\n",
    "resting_state_labels = np.zeros(resting_state_features.shape[0])\n",
    "task_state_labels = np.ones(task_state_features.shape[0])\n",
    "\n",
    "# Combine the features and labels\n",
    "all_features = np.concatenate((resting_state_features, task_state_features), axis=0)\n",
    "all_labels = np.concatenate((resting_state_labels, task_state_labels), axis=0)\n",
    "\n",
    "\n",
    "indices = np.arange(all_features.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "shuffled_features = all_features[indices]\n",
    "shuffled_labels = all_labels[indices]\n",
    "\n",
    "\n",
    "# Reshape the features for Random Forest\n",
    "n_samples, n_channels, n_features = shuffled_features.shape\n",
    "X_train = shuffled_features.reshape(n_samples, -1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, shuffled_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Create the LASSO model\n",
    "lasso = LassoCV(cv=5)\n",
    "\n",
    "# Use SelectFromModel for feature selection\n",
    "sfm = SelectFromModel(lasso)\n",
    "X_train_selected = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Shape of selected features:\", X_train_selected.shape)\n",
    "# Use SelectFromModel to select features for test data\n",
    "X_test_selected = sfm.transform(X_test)\n",
    "\n",
    "# Print the selected features for test data\n",
    "print(\"Shape of selected test features:\", X_test_selected.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "76692e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean accuracy: 1.0\n",
      "Accuracy on test data: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a new Random Forest classifier\n",
    "clf_selected = RandomForestClassifier()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf_selected, X_train_selected, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = clf_selected.score(X_test_selected, y_test)\n",
    "print(\"Accuracy on test data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0f044275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         2\n",
      "         1.0       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = clf_selected.predict(X_test_selected)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "497674c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your feature selection and data splitting code\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a new Random Forest classifier\n",
    "clf_selected = RandomForestClassifier()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf_selected, X_train_selected, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Plotting heatmap\n",
    "sns.heatmap(np.array(cv_scores).reshape(1, -1), annot=True, cmap=\"YlGnBu\", fmt=\".3f\", cbar=False)\n",
    "plt.title(\"Cross-validation scores\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8e856006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 340)\n",
      "Shape of selected features: (15, 57)\n",
      "Shape of selected features: (15, 57)\n",
      "Shape of selected test features: (4, 57)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine PSD and ERP features for resting state\n",
    "resting_state_features = np.concatenate((usable_features_psd_mci_rs, features_erp_mci_rs), axis=2)\n",
    "\n",
    "# Combine PSD and ERP features for task state\n",
    "task_state_features = np.concatenate((usable_features_psd_mci_ts, features_erp_mci_ts), axis=2)\n",
    "\n",
    "# Combine the labels\n",
    "resting_state_labels = np.zeros(resting_state_features.shape[0])\n",
    "task_state_labels = np.ones(task_state_features.shape[0])\n",
    "\n",
    "# Combine the features and labels\n",
    "all_features = np.concatenate((resting_state_features, task_state_features), axis=0)\n",
    "all_labels = np.concatenate((resting_state_labels, task_state_labels), axis=0)\n",
    "\n",
    "\n",
    "indices = np.arange(all_features.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "shuffled_features = all_features[indices]\n",
    "shuffled_labels = all_labels[indices]\n",
    "\n",
    "\n",
    "# Reshape the features for Random Forest\n",
    "n_samples, n_channels, n_features = shuffled_features.shape\n",
    "X_train = shuffled_features.reshape(n_samples, -1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, shuffled_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Use SelectFromModel for feature selection\n",
    "sfm = SelectFromModel(clf)\n",
    "X_train_selected = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Shape of selected features:\", X_train_selected.shape)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Shape of selected features:\", X_train_selected.shape)\n",
    "# Use SelectFromModel to select features for test data\n",
    "X_test_selected = sfm.transform(X_test)\n",
    "\n",
    "# Print the selected features for test data\n",
    "print(\"Shape of selected test features:\", X_test_selected.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11918541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean accuracy: 1.0\n",
      "Accuracy on test data: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a new Random Forest classifier\n",
    "clf_selected = RandomForestClassifier()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf_selected, X_train_selected, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = clf_selected.score(X_test_selected, y_test)\n",
    "print(\"Accuracy on test data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8ae91b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for SVC: [1. 1. 1. 1. 1.]\n",
      "Mean accuracy for SVC: 1.0\n",
      "Accuracy on test data for SVC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define a new SVC classifier\n",
    "clf_selected_svc = SVC()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_svc = cross_val_score(clf_selected_svc, X_train_selected, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores for SVC\n",
    "print(\"Cross-validation scores for SVC:\", cv_scores_svc)\n",
    "print(\"Mean accuracy for SVC:\", np.mean(cv_scores_svc))\n",
    "\n",
    "# Train the SVC classifier on the full training data\n",
    "clf_selected_svc.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy_svc = clf_selected_svc.score(X_test_selected, y_test)\n",
    "print(\"Accuracy on test data for SVC:\", accuracy_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "df1d4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = clf_selected_svc.predict(X_test_selected)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", fmt=\"d\", xticklabels=['Resting State', 'Task State'], yticklabels=['Resting State', 'Task State'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for SVC Classifier on Test Data')\n",
    "plt.savefig('confusion_matrix_heatmap_mci.jpeg')  # Save the heatmap as an image\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cdd51e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the classifier on the full training data\n",
    "clf_selected_svc.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = clf_selected_svc.predict(X_test_selected)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "16be61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8d660110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.571, 4.413, 9.533, 2.506, 1.661, 9.553, 9.527, 9.538, 9.662,\n",
       "        9.534, 9.491, 9.488, 9.618, 4.652, 5.83, 2.503, 9.468, 9.634,\n",
       "        9.483, 9.567],\n",
       "       [9.483, 9.4, 9.599, 5.638, 5.639, 8.808, 9.591, 9.591, 9.572,\n",
       "        9.621, 5.401, 4.416, 4.239, 9.585, 8.433, 5.636, 9.589, 9.624,\n",
       "        9.49, 9.591],\n",
       "       [9.628, 9.44, 9.613, 9.513, 9.51, 9.68, 4.144, 9.598, 9.637,\n",
       "        9.499, 7.853, 0.293, 9.72, 0.105, 9.69, 9.687, 0.019, 9.492,\n",
       "        9.628, 0.139],\n",
       "       [9.66, 4.609, 9.681, 1.451, 1.479, 7.264, 9.676, 1.19, 9.681,\n",
       "        5.472, 4.059, 4.063, 4.058, 2.063, 2.634, 9.562, 6.253, 9.526,\n",
       "        9.504, 6.584],\n",
       "       [9.576, 9.579, 9.625, 9.509, 9.653, 9.489, 9.549, 9.693, 9.604,\n",
       "        9.583, 9.574, 9.549, 9.579, 9.588, 9.584, 9.466, 9.603, 9.619,\n",
       "        9.622, 9.59],\n",
       "       [1.417, 9.625, 9.446, 9.581, 9.628, 9.58, 9.578, 9.57, 9.57,\n",
       "        9.633, 9.607, 9.603, 9.614, 9.596, 9.561, 9.686, 9.899, 9.433,\n",
       "        9.481, 9.664],\n",
       "       [9.653, 9.599, 9.679, 9.652, 9.546, 0.0, 9.547, 9.667, 9.647,\n",
       "        9.568, 9.6, 9.541, 9.599, 9.598, 9.547, 9.456, 9.553, 9.455,\n",
       "        9.597, 9.571],\n",
       "       [9.474, 1.037, 1.879, 9.596, 1.444, 9.9, 1.038, 1.422, 9.478,\n",
       "        1.041, 1.924, 8.589, 0.198, 4.247, 9.592, 2.601, 9.543, 7.034,\n",
       "        9.611, 0.292],\n",
       "       [8.457, 7.442, 8.396, 7.532, 4.588, 7.442, 7.537, 7.537, 9.522,\n",
       "        5.373, 7.443, 7.441, 7.538, 8.459, 7.442, 7.533, 7.442, 7.443,\n",
       "        4.586, 3.733],\n",
       "       [9.371, 6.358, 9.371, 1.3, 8.474, 9.373, 9.371, 9.369, 9.369,\n",
       "        9.371, 8.709, 9.371, 9.371, 5.217, 5.217, 8.466, 8.331, 6.358,\n",
       "        9.557, 8.332],\n",
       "       [9.502, 9.555, 3.956, 9.574, 9.553, 2.773, 9.468, 9.466, 9.564,\n",
       "        9.564, 9.562, 9.591, 6.508, 6.431, 7.203, 9.698, 9.682, 9.584,\n",
       "        2.767, 9.576],\n",
       "       [9.521, 1.648, 9.519, 9.652, 9.58, 9.569, 1.497, 1.494, 9.544,\n",
       "        9.499, 3.113, 1.22, 9.538, 9.502, 9.587, 2.604, 9.574, 9.538,\n",
       "        9.567, 9.542],\n",
       "       [9.41, 0.153, 0.289, 1.035, 9.635, 9.053, 7.425, 8.112, 9.571,\n",
       "        2.027, 7.362, 7.374, 2.028, 0.893, 1.622, 1.631, 0.416, 0.478,\n",
       "        1.677, 0.923],\n",
       "       [3.67, 4.905, 8.724, 9.588, 4.184, 8.716, 8.726, 2.431, 8.569,\n",
       "        3.849, 2.002, 3.135, 9.539, 2.887, 2.49, 1.368, 7.534, 8.565,\n",
       "        8.721, 3.746],\n",
       "       [4.898, 9.549, 9.9, 6.025, 1.418, 9.536, 9.589, 9.587, 9.523,\n",
       "        8.363, 9.503, 9.728, 9.898, 9.543, 4.895, 4.897, 9.693, 9.627,\n",
       "        9.529, 9.44],\n",
       "       [3.877, 9.562, 9.545, 4.908, 0.848, 9.559, 9.531, 9.9, 3.878,\n",
       "        9.556, 8.721, 9.633, 9.635, 9.588, 0.626, 9.564, 9.67, 9.559,\n",
       "        9.553, 9.562],\n",
       "       [4.898, 9.549, 9.9, 6.025, 1.418, 9.536, 9.589, 9.587, 9.523,\n",
       "        8.363, 9.503, 9.728, 9.898, 9.543, 4.895, 4.897, 9.693, 9.627,\n",
       "        9.529, 9.44],\n",
       "       [3.877, 9.562, 9.545, 4.908, 0.848, 9.559, 9.531, 9.9, 3.878,\n",
       "        9.556, 8.721, 9.633, 9.635, 9.588, 0.626, 9.564, 9.67, 9.559,\n",
       "        9.553, 9.562],\n",
       "       [9.531, 9.604, 7.148, 9.403, 1.246, 9.62, 2.025, 1.397, 2.73,\n",
       "        1.398, 2.023, 9.678, 9.449, 8.952, 1.249, 9.524, 6.549, 9.636,\n",
       "        9.276, 0.263],\n",
       "       [9.572, 9.549, 9.546, 9.631, 7.704, 9.9, 9.551, 9.55, 9.62, 9.54,\n",
       "        4.095, 9.744, 9.547, 9.646, 5.013, 7.709, 9.421, 9.597, 9.37,\n",
       "        9.65],\n",
       "       [8.96, 9.612, 9.52, 7.533, 8.899, 9.639, 0.308, 9.537, 8.965,\n",
       "        7.105, 9.493, 9.491, 9.487, 9.714, 5.113, 5.111, 5.116, 7.3,\n",
       "        9.638, 7.301],\n",
       "       [9.608, 9.512, 9.526, 9.649, 9.624, 9.535, 9.521, 9.528, 9.524,\n",
       "        9.517, 9.515, 9.66, 9.534, 9.469, 8.64, 7.834, 9.726, 8.2, 9.641,\n",
       "        9.643],\n",
       "       [9.583, 9.691, 9.554, 9.587, 7.075, 9.665, 9.551, 9.651, 9.545,\n",
       "        0.771, 9.663, 0.182, 9.579, 7.081, 9.57, 9.573, 9.556, 9.566,\n",
       "        9.565, 9.568],\n",
       "       [4.457, 8.514, 9.597, 8.559, 9.443, 9.48, 9.638, 9.596, 7.566,\n",
       "        8.515, 8.513, 1.171, 9.38, 7.153, 7.152, 9.344, 9.701, 8.559,\n",
       "        9.51, 9.579],\n",
       "       [9.688, 9.574, 9.502, 9.616, 9.431, 0.264, 9.506, 9.545, 9.507,\n",
       "        9.6, 9.573, 9.625, 9.627, 9.62, 2.776, 2.386, 9.679, 9.555,\n",
       "        9.445, 9.486],\n",
       "       [9.545, 8.639, 9.529, 7.639, 7.773, 9.301, 9.64, 9.527, 9.639,\n",
       "        9.62, 9.452, 8.539, 9.454, 9.709, 9.525, 9.581, 9.596, 4.023,\n",
       "        9.543, 9.703],\n",
       "       [5.237, 9.659, 9.57, 9.565, 9.63, 9.568, 9.59, 9.6, 9.564, 9.66,\n",
       "        9.655, 9.588, 9.512, 7.667, 3.883, 9.648, 9.418, 9.531, 9.56,\n",
       "        9.651],\n",
       "       [9.606, 9.496, 5.61, 9.548, 9.423, 9.496, 9.525, 9.57, 8.742,\n",
       "        9.714, 9.708, 9.456, 9.57, 9.735, 9.501, 9.693, 9.414, 9.551,\n",
       "        9.539, 9.59],\n",
       "       [9.372, 0.723, 2.49, 2.84, 2.846, 9.627, 9.538, 9.457, 9.597,\n",
       "        1.756, 0.719, 0.207, 0.843, 1.083, 2.718, 1.005, 1.841, 9.566,\n",
       "        9.525, 9.571],\n",
       "       [6.624, 9.582, 9.608, 9.515, 9.619, 9.494, 9.587, 9.519, 7.696,\n",
       "        9.61, 9.423, 9.017, 9.521, 9.604, 9.616, 9.606, 8.932, 9.497,\n",
       "        9.603, 9.66],\n",
       "       [5.058, 9.485, 9.527, 1.117, 9.554, 9.596, 1.13, 6.611, 5.044,\n",
       "        9.529, 9.625, 9.706, 9.624, 9.633, 9.643, 9.5, 0.285, 9.579,\n",
       "        9.499, 9.575],\n",
       "       [9.581, 4.244, 9.583, 9.575, 9.599, 9.498, 9.587, 9.564, 9.584,\n",
       "        9.584, 9.582, 9.512, 9.548, 9.608, 9.606, 9.566, 5.463, 9.608,\n",
       "        9.539, 9.536]], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_healthy_rs[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "02835f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.004, 0.008, 0.049, 0.099, 0.0, 0.056, 0.01, 0.004, 0.008,\n",
       "        0.015, 0.011, 0.009, 0.009, 0.003, 0.055, 0.029, 0.058, 0.0,\n",
       "        0.002, 0.124],\n",
       "       [0.142, 0.06, 0.059, 0.139, 0.137, 0.109, 0.143, 0.007, 0.141,\n",
       "        0.009, 0.008, 0.071, 0.064, 0.142, 0.136, 0.142, 0.147, 0.138,\n",
       "        0.129, 0.011],\n",
       "       [0.006, 0.007, 0.001, 0.051, 0.033, 0.013, 0.007, 0.029, 0.015,\n",
       "        0.03, 0.0, 0.008, 0.012, 0.022, 0.028, 0.028, 0.002, 0.018,\n",
       "        0.018, 0.018],\n",
       "       [0.017, 0.072, 0.008, 0.001, 0.12, 0.0, 0.011, 0.132, 0.02, 0.132,\n",
       "        0.073, 0.017, 0.009, 0.001, 0.044, 0.005, 0.043, 0.15, 0.0,\n",
       "        0.007],\n",
       "       [0.023, 0.015, 0.15, 0.15, 0.149, 0.036, 0.05, 0.058, 0.0, 0.15,\n",
       "        0.014, 0.08, 0.015, 0.15, 0.138, 0.144, 0.05, 0.15, 0.074, 0.15],\n",
       "       [0.075, 0.129, 0.123, 0.148, 0.15, 0.15, 0.006, 0.01, 0.061,\n",
       "        0.123, 0.117, 0.15, 0.007, 0.018, 0.02, 0.132, 0.009, 0.147,\n",
       "        0.124, 0.141],\n",
       "       [0.031, 0.045, 0.043, 0.044, 0.147, 0.026, 0.15, 0.15, 0.027,\n",
       "        0.149, 0.15, 0.15, 0.0, 0.147, 0.15, 0.15, 0.15, 0.146, 0.029,\n",
       "        0.15],\n",
       "       [0.02, 0.15, 0.047, 0.096, 0.015, 0.045, 0.027, 0.15, 0.031,\n",
       "        0.067, 0.15, 0.136, 0.052, 0.051, 0.101, 0.1, 0.107, 0.137, 0.15,\n",
       "        0.106],\n",
       "       [0.004, 0.021, 0.15, 0.038, 0.013, 0.013, 0.02, 0.021, 0.043,\n",
       "        0.15, 0.087, 0.098, 0.018, 0.012, 0.033, 0.036, 0.031, 0.145,\n",
       "        0.058, 0.146],\n",
       "       [0.15, 0.13, 0.072, 0.017, 0.102, 0.132, 0.038, 0.052, 0.15,\n",
       "        0.083, 0.09, 0.055, 0.0, 0.135, 0.107, 0.072, 0.138, 0.15, 0.15,\n",
       "        0.028],\n",
       "       [0.066, 0.15, 0.126, 0.134, 0.03, 0.054, 0.146, 0.121, 0.038,\n",
       "        0.072, 0.056, 0.129, 0.135, 0.021, 0.026, 0.014, 0.022, 0.0,\n",
       "        0.019, 0.007],\n",
       "       [0.128, 0.088, 0.13, 0.15, 0.036, 0.005, 0.129, 0.126, 0.138,\n",
       "        0.117, 0.112, 0.101, 0.113, 0.034, 0.0, 0.15, 0.066, 0.15, 0.032,\n",
       "        0.15],\n",
       "       [0.013, 0.139, 0.134, 0.028, 0.062, 0.017, 0.004, 0.106, 0.053,\n",
       "        0.135, 0.011, 0.046, 0.049, 0.06, 0.066, 0.017, 0.062, 0.026,\n",
       "        0.019, 0.015],\n",
       "       [0.139, 0.045, 0.085, 0.15, 0.15, 0.15, 0.088, 0.083, 0.017,\n",
       "        0.084, 0.037, 0.081, 0.084, 0.089, 0.15, 0.148, 0.136, 0.134,\n",
       "        0.1, 0.082],\n",
       "       [0.008, 0.088, 0.024, 0.15, 0.055, 0.007, 0.023, 0.082, 0.0, 0.15,\n",
       "        0.037, 0.103, 0.1, 0.108, 0.15, 0.15, 0.15, 0.022, 0.03, 0.15],\n",
       "       [0.15, 0.0, 0.002, 0.021, 0.009, 0.0, 0.008, 0.01, 0.102, 0.002,\n",
       "        0.0, 0.143, 0.036, 0.029, 0.008, 0.023, 0.029, 0.035, 0.12, 0.15],\n",
       "       [0.043, 0.131, 0.129, 0.15, 0.008, 0.005, 0.047, 0.044, 0.043,\n",
       "        0.093, 0.088, 0.045, 0.015, 0.045, 0.042, 0.004, 0.043, 0.15,\n",
       "        0.001, 0.15],\n",
       "       [0.045, 0.115, 0.035, 0.15, 0.049, 0.051, 0.049, 0.045, 0.044,\n",
       "        0.119, 0.108, 0.039, 0.072, 0.049, 0.049, 0.022, 0.027, 0.05,\n",
       "        0.051, 0.024],\n",
       "       [0.034, 0.0, 0.15, 0.15, 0.062, 0.15, 0.15, 0.15, 0.002, 0.146,\n",
       "        0.049, 0.044, 0.048, 0.029, 0.027, 0.056, 0.026, 0.146, 0.02,\n",
       "        0.149],\n",
       "       [0.046, 0.004, 0.15, 0.086, 0.141, 0.035, 0.15, 0.051, 0.032, 0.0,\n",
       "        0.0, 0.08, 0.15, 0.041, 0.039, 0.057, 0.048, 0.005, 0.008, 0.007],\n",
       "       [0.074, 0.15, 0.15, 0.0, 0.001, 0.145, 0.144, 0.0, 0.018, 0.052,\n",
       "        0.03, 0.144, 0.049, 0.016, 0.008, 0.002, 0.044, 0.079, 0.067,\n",
       "        0.146],\n",
       "       [0.013, 0.106, 0.04, 0.141, 0.011, 0.011, 0.0, 0.005, 0.006,\n",
       "        0.101, 0.006, 0.002, 0.04, 0.012, 0.123, 0.12, 0.028, 0.013,\n",
       "        0.119, 0.024],\n",
       "       [0.038, 0.146, 0.15, 0.0, 0.029, 0.046, 0.15, 0.15, 0.037, 0.002,\n",
       "        0.0, 0.148, 0.0, 0.132, 0.031, 0.045, 0.03, 0.0, 0.048, 0.015],\n",
       "       [0.019, 0.137, 0.15, 0.1, 0.104, 0.082, 0.15, 0.133, 0.082, 0.085,\n",
       "        0.119, 0.093, 0.006, 0.0, 0.0, 0.15, 0.063, 0.083, 0.083, 0.016],\n",
       "       [0.0, 0.15, 0.148, 0.126, 0.137, 0.091, 0.144, 0.148, 0.0, 0.15,\n",
       "        0.15, 0.045, 0.079, 0.128, 0.037, 0.123, 0.038, 0.135, 0.04,\n",
       "        0.132],\n",
       "       [0.0, 0.136, 0.025, 0.122, 0.061, 0.142, 0.024, 0.085, 0.042,\n",
       "        0.075, 0.004, 0.025, 0.014, 0.014, 0.014, 0.02, 0.137, 0.0,\n",
       "        0.118, 0.132],\n",
       "       [0.118, 0.0, 0.032, 0.027, 0.067, 0.044, 0.074, 0.049, 0.04, 0.0,\n",
       "        0.15, 0.0, 0.125, 0.008, 0.012, 0.013, 0.037, 0.065, 0.006,\n",
       "        0.073],\n",
       "       [0.0, 0.125, 0.139, 0.063, 0.024, 0.105, 0.128, 0.01, 0.027,\n",
       "        0.138, 0.035, 0.099, 0.041, 0.009, 0.01, 0.117, 0.022, 0.118,\n",
       "        0.118, 0.003],\n",
       "       [0.0, 0.15, 0.142, 0.138, 0.137, 0.057, 0.0, 0.141, 0.004, 0.133,\n",
       "        0.139, 0.139, 0.141, 0.016, 0.017, 0.138, 0.15, 0.141, 0.019,\n",
       "        0.0],\n",
       "       [0.101, 0.139, 0.075, 0.131, 0.123, 0.124, 0.079, 0.032, 0.15,\n",
       "        0.004, 0.139, 0.105, 0.125, 0.116, 0.121, 0.119, 0.118, 0.006,\n",
       "        0.15, 0.012],\n",
       "       [0.129, 0.057, 0.032, 0.15, 0.143, 0.066, 0.15, 0.076, 0.066,\n",
       "        0.15, 0.142, 0.003, 0.142, 0.044, 0.009, 0.006, 0.041, 0.15,\n",
       "        0.032, 0.05],\n",
       "       [0.098, 0.039, 0.042, 0.148, 0.148, 0.019, 0.037, 0.041, 0.138,\n",
       "        0.128, 0.15, 0.15, 0.15, 0.15, 0.147, 0.102, 0.044, 0.15, 0.039,\n",
       "        0.018]], dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_healthy_ts[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad175f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f70bd6b",
   "metadata": {},
   "source": [
    "# Anomaly detection: Eyes closed data \n",
    "trained on 10 healthy subjects; tested on (5 healthy + 5 MCI) using k-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "16aff626",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13ffeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_aud=list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7090f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9216671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected .mat files:\n",
      "PreProcessed_AD001_Preprocessed_EC.mat\n",
      "PreProcessed_AD002_Preprocessed_EC.mat\n",
      "PreProcessed_AD003_Preprocessed_EC.mat\n",
      "PreProcessed_AD004_Preprocessed_EC.mat\n",
      "PreProcessed_AD006_Preprocessed_EC.mat\n",
      "PreProcessed_AD008_Preprocessed_EC.mat\n",
      "PreProcessed_AD010_Preprocessed_EC.mat\n",
      "PreProcessed_AD011_Preprocessed_EC.mat\n",
      "PreProcessed_AD012_Preprocessed_EC.mat\n",
      "PreProcessed_AD013_Preprocessed_EC.mat\n",
      "PreProcessed_AD014_Preprocessed_EC.mat\n",
      "PreProcessed_AD015_Preprocessed_EC.mat\n",
      "PreProcessed_AD016_Preprocessed_EC.mat\n",
      "PreProcessed_AD017_Preprocessed_EC.mat\n",
      "PreProcessed_AD018_Preprocessed_EC.mat\n",
      "PreProcessed_AD020_Preprocessed_EC.mat\n",
      "PreProcessed_AD026_Preprocessed_EC.mat\n",
      "PreProcessed_AD027_Preprocessed_EC.mat\n",
      "PreProcessed_AD028_Preprocessed_EC.mat\n",
      "PreProcessed_AD030_Preprocessed_EC.mat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_eyes_closed\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_rsec = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_rsec:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de08a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcessed_AD001_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD002_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD003_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD004_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD006_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD008_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD010_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD011_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD012_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD013_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD014_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD015_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD016_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD017_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD018_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD020_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD027_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD028_Preprocessed_EC.mat\n",
      "16\n",
      "PreProcessed_AD030_Preprocessed_EC.mat\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "num_trials=0\n",
    "trial_counts_rsec=[]\n",
    "for subject in range(len(matfiles_rsec)):\n",
    "    subject_data = []\n",
    "    name=matfiles_rsec[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_rsec[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_rsec.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db77f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e446ee24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_counts_rsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d308b51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trial_counts_rsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4d1d8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEG0112+0113',\n",
       " 'MEG0122+0123',\n",
       " 'MEG0132+0133',\n",
       " 'MEG0142+0143',\n",
       " 'MEG0212+0213',\n",
       " 'MEG0222+0223',\n",
       " 'MEG0232+0233',\n",
       " 'MEG0242+0243',\n",
       " 'MEG0312+0313',\n",
       " 'MEG0322+0323',\n",
       " 'MEG0332+0333',\n",
       " 'MEG0342+0343',\n",
       " 'MEG0412+0413',\n",
       " 'MEG0422+0423',\n",
       " 'MEG0432+0433',\n",
       " 'MEG0442+0443',\n",
       " 'MEG0512+0513',\n",
       " 'MEG0522+0523',\n",
       " 'MEG0532+0533',\n",
       " 'MEG0542+0543',\n",
       " 'MEG0612+0613',\n",
       " 'MEG0622+0623',\n",
       " 'MEG0632+0633',\n",
       " 'MEG0642+0643',\n",
       " 'MEG0712+0713',\n",
       " 'MEG0722+0723',\n",
       " 'MEG0732+0733',\n",
       " 'MEG0742+0743',\n",
       " 'MEG0812+0813',\n",
       " 'MEG0822+0823',\n",
       " 'MEG0912+0913',\n",
       " 'MEG0922+0923',\n",
       " 'MEG0932+0933',\n",
       " 'MEG0942+0943',\n",
       " 'MEG1012+1013',\n",
       " 'MEG1022+1023',\n",
       " 'MEG1032+1033',\n",
       " 'MEG1042+1043',\n",
       " 'MEG1112+1113',\n",
       " 'MEG1122+1123',\n",
       " 'MEG1132+1133',\n",
       " 'MEG1142+1143',\n",
       " 'MEG1212+1213',\n",
       " 'MEG1222+1223',\n",
       " 'MEG1232+1233',\n",
       " 'MEG1242+1243',\n",
       " 'MEG1312+1313',\n",
       " 'MEG1322+1323',\n",
       " 'MEG1332+1333',\n",
       " 'MEG1342+1343',\n",
       " 'MEG1412+1413',\n",
       " 'MEG1422+1423',\n",
       " 'MEG1432+1433',\n",
       " 'MEG1442+1443',\n",
       " 'MEG1512+1513',\n",
       " 'MEG1522+1523',\n",
       " 'MEG1532+1533',\n",
       " 'MEG1542+1543',\n",
       " 'MEG1612+1613',\n",
       " 'MEG1622+1623',\n",
       " 'MEG1632+1633',\n",
       " 'MEG1642+1643',\n",
       " 'MEG1712+1713',\n",
       " 'MEG1722+1723',\n",
       " 'MEG1732+1733',\n",
       " 'MEG1742+1743',\n",
       " 'MEG1812+1813',\n",
       " 'MEG1822+1823',\n",
       " 'MEG1832+1833',\n",
       " 'MEG1842+1843',\n",
       " 'MEG1912+1913',\n",
       " 'MEG1922+1923',\n",
       " 'MEG1932+1933',\n",
       " 'MEG1942+1943',\n",
       " 'MEG2012+2013',\n",
       " 'MEG2022+2023',\n",
       " 'MEG2032+2033',\n",
       " 'MEG2042+2043',\n",
       " 'MEG2112+2113',\n",
       " 'MEG2122+2123',\n",
       " 'MEG2132+2133',\n",
       " 'MEG2142+2143',\n",
       " 'MEG2212+2213',\n",
       " 'MEG2222+2223',\n",
       " 'MEG2232+2233',\n",
       " 'MEG2242+2243',\n",
       " 'MEG2312+2313',\n",
       " 'MEG2322+2323',\n",
       " 'MEG2332+2333',\n",
       " 'MEG2342+2343',\n",
       " 'MEG2412+2413',\n",
       " 'MEG2422+2423',\n",
       " 'MEG2432+2433',\n",
       " 'MEG2442+2443',\n",
       " 'MEG2512+2513',\n",
       " 'MEG2522+2523',\n",
       " 'MEG2532+2533',\n",
       " 'MEG2542+2543',\n",
       " 'MEG2612+2613',\n",
       " 'MEG2622+2623',\n",
       " 'MEG2632+2633',\n",
       " 'MEG2642+2643']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bedf2371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d1bf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_channels = len(trials_sub[1,:,1])\n",
    "\n",
    "# Initialize an info structure\n",
    "info = mne.create_info(\n",
    "        ch_names = list_1,\n",
    "        ch_types = ['grad']*len(list_1),\n",
    "        sfreq    = sfreq \n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a50d6bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without grand averAGING FOR KANISKA SIR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_rsec = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_rsec):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_rsec[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_rsec[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "        print(trial_data)\n",
    "        trial=trial_data[0]\n",
    "        print(trial.shape)\n",
    "        raw = mne.io.RawArray(trial, info)\n",
    "        raw_list_mean_rsec.append(raw)\n",
    "    print(len(raw_list_mean_rsec))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_mci_ts = mne.concatenate_raws(raw_list_mean_mci_ts)\n",
    "\n",
    "# print(len(raw_combined_mean_mci_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cdb73df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_list_mean_rsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1958c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "alpha_band = (8, 13)  # Alpha band frequencies\n",
    "beta_band = (13, 30)  # Beta band frequencies\n",
    "\n",
    "features_psd_rsec = []\n",
    "for raw in raw_list_mean_rsec:\n",
    "    # Compute PSD\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
    "    #psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=0, fmax=40, tmin=None, tmax=None)\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    \n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(list_1):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "        print('current channel is')\n",
    "        print(ch_name)\n",
    "\n",
    "    # Statistical Features\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "    \n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        \n",
    "                    # Compute entropy for alpha band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Compute entropy for beta band\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        \n",
    " \n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        \n",
    "       \n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "    \n",
    "    features_psd_rsec.append(features)\n",
    "    \n",
    "features_psd_rsec = np.array(features_psd_rsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6052148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 102, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_psd_rsec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c17e5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_rsec = np.delete(features_psd_rsec, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e1f5d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 102, 8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features_psd_rsec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ebc9e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info['ch_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3394bda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "0\n",
      "PreProcessed_AD001_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "1\n",
      "PreProcessed_AD002_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "2\n",
      "PreProcessed_AD003_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "3\n",
      "PreProcessed_AD004_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "4\n",
      "PreProcessed_AD006_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "5\n",
      "PreProcessed_AD008_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "6\n",
      "PreProcessed_AD010_Preprocessed_EC.mat\n",
      "in if\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\299866631.py:125: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  aar = peak_to_peak_amplitude / mean_absolute_amplitude\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "7\n",
      "PreProcessed_AD011_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "8\n",
      "PreProcessed_AD012_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "9\n",
      "PreProcessed_AD013_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "10\n",
      "PreProcessed_AD014_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "11\n",
      "PreProcessed_AD015_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "12\n",
      "PreProcessed_AD016_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "13\n",
      "PreProcessed_AD017_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "14\n",
      "PreProcessed_AD018_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "15\n",
      "PreProcessed_AD020_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "17\n",
      "PreProcessed_AD027_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "18\n",
      "PreProcessed_AD028_Preprocessed_EC.mat\n",
      "in if\n",
      "subject idx is\n",
      "19\n",
      "PreProcessed_AD030_Preprocessed_EC.mat\n",
      "in if\n"
     ]
    }
   ],
   "source": [
    "#without grand averaging for kaniska sir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "features_erp_rsec = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_rsec):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_rsec[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_rsec[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "    end=num_trials\n",
    "\n",
    "    trial_data=[]\n",
    "    # Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "        trial=trial_data[0]\n",
    "\n",
    "        features=[]\n",
    "\n",
    "# Iterate through channels\n",
    "        for ch_idx in range(len(info['ch_names'])):\n",
    "        # Extract ERP data for the current channel\n",
    "            channel_data = trial[ch_idx,:]\n",
    "        \n",
    "            peak_amplitude = np.max(channel_data)\n",
    "            peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "            # Compute mean absolute amplitude\n",
    "            mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "            mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "                # Compute RMS amplitude\n",
    "            rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "            rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "            # Compute standard deviation\n",
    "            std_dev = np.std(channel_data)\n",
    "            std_devs.append(std_dev)\n",
    "\n",
    "            # Compute skewness\n",
    "            skewness = skew(channel_data)\n",
    "            skewness_values.append(skewness)\n",
    "\n",
    "            # Compute kurtosis\n",
    "            kurtosis_val = kurtosis(channel_data)\n",
    "            kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "            # Compute zero crossing rate\n",
    "            zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "            zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "            latency = times[np.argmax(channel_data)]\n",
    "\n",
    "        # Calculate area under the curve (AUC)\n",
    "            auc_value = simps(channel_data, times)\n",
    "\n",
    "        # Calculate slope (e.g., by fitting a linear regression model)\n",
    "        # You can use numpy's polyfit function for this purpose\n",
    "            slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "            slope = slope_coefficients[0]\n",
    "\n",
    "        \n",
    "            zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "            zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "            # Compute AAR\n",
    "            aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "            aar_values.append(aar)\n",
    "\n",
    "            # Compute ZORK\n",
    "            zork = zero_crossings / kurtosis_val\n",
    "            zork_values.append(zork)\n",
    "\n",
    "            peak_to_peak_amplitudes1=np.array(peak_to_peak_amplitudes)\n",
    "            channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                                peak_to_peak_amplitude, \n",
    "                                     mean_absolute_amplitude, \n",
    "                                     rms_amplitude, \n",
    "                                     std_dev, \n",
    "                                     skewness, \n",
    "                                     kurtosis_val, \n",
    "                                     zero_crossings,aar,zork]\n",
    "\n",
    "            features.append(channel_features)\n",
    "\n",
    "        features_erp_rsec.append(features)\n",
    "    \n",
    "features_erp_rsec = np.array(features_erp_rsec,dtype=object)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b7a8ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 102, 13)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_rsec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f9a3cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 102, 4)\n"
     ]
    }
   ],
   "source": [
    "usable_features_psd_rsec=new_features_psd_rsec[:,:,4:8]\n",
    "print(usable_features_psd_rsec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b344cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 102, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_features_psd_rsec[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bc57012",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa87cdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 102, 4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_features_psd_rsec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d880c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 16, 102, 4)\n",
      "(20, 16, 102, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "usable_features_psd_rsec_reshaped = usable_features_psd_rsec.reshape(20, 16, 102, 4)\n",
    "print(usable_features_psd_rsec_reshaped.shape)\n",
    "\n",
    "features_erp_rsec_reshaped = features_erp_rsec.reshape(20, 16, 102, 13)\n",
    "print(features_erp_rsec_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7259ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "# Specify the location to save the files\n",
    "save_path_psd = 'D:/internship_ulster_university/features without grand averaging/rsec/rsec_psd_without_grand_average.mat'\n",
    "save_path_erp = 'D:/internship_ulster_university/features without grand averaging/rsec/rsec_erp_without_grand_average.mat'\n",
    "\n",
    "# Save the reshaped PSD features\n",
    "sio.savemat(save_path_psd, {'usable_features_psd_rsec_reshaped': usable_features_psd_rsec_reshaped})\n",
    "\n",
    "# Save the reshaped ERP features\n",
    "sio.savemat(save_path_erp, {'features_erp_rsec_reshaped': features_erp_rsec_reshaped})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f99714",
   "metadata": {},
   "source": [
    "# uncomment 2 cells below to save features in local directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2dfa4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to save features in local directory\n",
    "\n",
    "# import pickle\n",
    "# with open('features_psd_rsec.pkl', 'wb') as file: \n",
    "#     pickle.dump(usable_features_psd_rsec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6bd55bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save features in local directory\n",
    "# import pickle\n",
    "# with open('features_erp_rsec.pkl', 'wb') as file: \n",
    "#     pickle.dump(features_erp_rsec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6635633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_psd_rsec.pkl','rb') as file:\n",
    "    usable_features_psd_rsec=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba3e0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_erp_rsec.pkl','rb') as file:\n",
    "    features_erp_rsec=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50c88da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 102, 4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_features_psd_rsec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7584368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 102, 13)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_rsec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da1434",
   "metadata": {},
   "source": [
    "## feature selection and anomaly detection pipeline for rsec data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np    \n",
    "def evaluate_performance(X_train, X_test, y_test):\n",
    "    size = X_train.shape[0]\n",
    "    y_train = np.ones(size)\n",
    "    one_class_svm = OneClassSVM()\n",
    "    loo = LeaveOneOut()\n",
    "    fold_accuracies = []\n",
    "    predictions = []\n",
    "    for train_index, test_index in loo.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        one_class_svm.fit(X_train_fold)\n",
    "        predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "        predictions.append(predictions_fold)\n",
    "            # Print classification report for the fold\n",
    "        print(f\"Classification Report - Fold:\")\n",
    "        print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test_fold, predictions_fold)\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "       # Evaluate the model on the entire test set\n",
    "   \n",
    "    # Combine predictions from all folds\n",
    "    predictions = np.concatenate(predictions)\n",
    "    print('concatenated predictions are')\n",
    "    print(predictions)\n",
    "\n",
    "    # Evaluate the model on the entire test set\n",
    "    test_predictions = one_class_svm.predict(X_test)\n",
    "    # Calculate accuracy for the entire test set\n",
    "    test_set_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    print(\"Final Classification Report:\")\n",
    "    print(classification_report(y_test, test_predictions, zero_division=0))  \n",
    " \n",
    "\n",
    "    # Calculate overall confusion matrix\n",
    "    cm = confusion_matrix(y_test, test_predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate overall sensitivity, specificity, and macro F1 score\n",
    "    overall_sensitivity = tp / (tp + fn)\n",
    "    overall_specificity = tn / (tn + fp)\n",
    "    overall_macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print(\"Overall Metrics:\")\n",
    "    print(f\"Overall Sensitivity: {overall_sensitivity}\")\n",
    "    print(f\"Overall Specificity: {overall_specificity}\")\n",
    "    print(f\"Overall Macro F1 Score: {overall_macro_f1}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return test_set_accuracy, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aaf4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the pipeline with SelectKBest and OneClassSVM\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM())\n",
    "])\n",
    "iterative_channel_selection_accuracies=[]\n",
    "channel_subsets_best_perform_rsec=[]\n",
    "# Initialize variables\n",
    "#selected_channels_rsec = []\n",
    "\n",
    "#selected_channels_rsec=['MEG0142+0143','MEG1512+1513','MEG1542+1543','MEG1812+1813','MEG1622+1623','MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243']\n",
    "\n",
    "#selected_channels_rsec=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643']\n",
    "\n",
    "\n",
    "##IMPORTANT-TO-DO----------------------> initially CHANGE selected_channels_indices to contain 10 channels in left cerebral hemisphere and 10 channels in right cerebral hemisphere that lie in the auditory processing region of the brain;\n",
    "##-------------------------------------> to do this change initialize ch_aud = ch_aud=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1812+1813', 'MEG1622+1623' ,'MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG2412+2413','MEG2222+2223','MEG2422+2423','MEG2442+2443','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643','MEG1332+1333','MEG1342+1343']\n",
    "##-------------------------------------> before running this cell\n",
    "##-------------------------------------> without doing so, all 102 channels will be considered for feature selection\n",
    "\n",
    "selected_channel_indices = [list_1.index(i) for i in ch_aud]\n",
    "print('selected channels indices')\n",
    "print(selected_channel_indices)\n",
    "\n",
    "\n",
    "\n",
    "train_healthy_psd_rsec = usable_features_psd_rsec[:11,selected_channel_indices,:]\n",
    "test_psd_rsec = usable_features_psd_rsec[11:,selected_channel_indices,:]\n",
    "\n",
    "train_healthy_erp_rsec = features_erp_rsec[:11,selected_channel_indices,:]\n",
    "test_erp_rsec = features_erp_rsec[11:,selected_channel_indices,:]\n",
    "\n",
    "\n",
    "print(train_healthy_psd_rsec.shape)\n",
    "print(train_healthy_erp_rsec.shape)\n",
    "\n",
    "# 2. Feature Extraction\n",
    "# Flatten the PSD and ERP features\n",
    "train_healthy_features_rsec = np.concatenate((train_healthy_psd_rsec.reshape(11, -1),\n",
    "                                                    train_healthy_erp_rsec.reshape(11, -1)), axis=1)\n",
    "print(train_healthy_features_rsec.shape)\n",
    "\n",
    "\n",
    "#removing constant features\n",
    "# Reshape the array to make it a 2D array where each row represents a feature\n",
    "reshaped_features = train_healthy_features_rsec.reshape(11, -1)\n",
    "\n",
    "# Calculate the variance along axis 0\n",
    "variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "# Find indices of constant features (where variance is zero)\n",
    "constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "print(\"Indices of constant features:\", constant_feature_indices)\n",
    "\n",
    "# Remove constant features\n",
    "usable_train_healthy_features_rsec= np.delete(train_healthy_features_rsec, constant_feature_indices, axis=1)\n",
    "\n",
    "# Verify the shape after removing constant features\n",
    "print(\"Shape after removing constant features:\", usable_train_healthy_features_rsec.shape)\n",
    "\n",
    "\n",
    "test_features_rsec = np.concatenate((test_psd_rsec.reshape(10, -1),\n",
    "                                           test_erp_rsec.reshape(10, -1)), axis=1)\n",
    "usable_test_features_rsec=np.delete(test_features_rsec, constant_feature_indices, axis=1)\n",
    "# Convert data to numerical type if necessary\n",
    "\n",
    "usable_train_healthy_features_rsec=usable_train_healthy_features_rsec.astype(float)\n",
    "\n",
    "# Find indices of columns with NaN values in train_healthy_selected_features_rseo\n",
    "nan_indices = np.isnan(usable_train_healthy_features_rsec).any(axis=0)\n",
    "# Remove columns with NaN values from train_healthy_selected_features_rseo\n",
    "usable_nonnan_train_healthy_features_rsec= usable_train_healthy_features_rsec[:, ~nan_indices]\n",
    "    # Print shape after removing NaN columns\n",
    "print(\"Shape of train_healthy_selected_features_rseo after removing NaN columns:\", usable_nonnan_train_healthy_features_rsec.shape)\n",
    "\n",
    "# Remove corresponding columns from X_test\n",
    "usable_nonnan_test_features_rsec  = usable_test_features_rsec[:, ~nan_indices]\n",
    "\n",
    "\n",
    "print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rsec.shape)\n",
    "\n",
    "    # Perform the grid search\n",
    "# Assuming y is the second dimension of usable_nonnan_train_healthy_features_rseo\n",
    "_, y = usable_nonnan_train_healthy_features_rsec.shape\n",
    "\n",
    "# Create a list of indices with step size 10\n",
    "indices = list(range(10, y+1, 10))\n",
    "print(indices)\n",
    "\n",
    "\n",
    "# Print the selected indices and corresponding values\n",
    "print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "# Define the range of k values to try\n",
    "param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Define a custom scoring function for anomaly detection\n",
    "Example: F1-score\n",
    "scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "grid_search.fit(usable_nonnan_train_healthy_features_rsec, [1] * usable_nonnan_train_healthy_features_rsec.shape[0])\n",
    "\n",
    "# Get the best value of k\n",
    "best_k = grid_search.best_params_['selector__k']\n",
    "print(\"Best value of k:\", best_k)\n",
    "\n",
    "# Select the best k features\n",
    "selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "train_healthy_selected_features_rsec = selector.fit_transform(usable_nonnan_train_healthy_features_rsec, [1] * usable_nonnan_train_healthy_features_rsec.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(selector.get_support()))\n",
    "# Use selected features for testing\n",
    "X_test = usable_nonnan_test_features_rsec[:, selector.get_support()]\n",
    "# X_test = usable_nonnan_test_features_rseo\n",
    "# Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "y_test = np.ones(X_test.shape[0])\n",
    "y_test[5:] = -1  # Labels for MCI subjects\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "test_set_accuracy, fold_accuracies = evaluate_performance(usable_nonnan_train_healthy_features_rsec, X_test, y_test)\n",
    "print(\"Test Set Accuracy:\", test_set_accuracy)\n",
    "print(\"Fold Accuracies:\", fold_accuracies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "896479d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features indices are\n",
      "[[ 9.53400000e+00  7.49839867e-11  5.73054679e-14  1.22910985e-11\n",
      "   7.57427175e-12  7.71000057e-12  1.44031812e-12  1.18637763e+00\n",
      "   3.19615838e+00  1.62274327e+00]\n",
      " [ 9.49900000e+00  6.99563983e-11  3.14008015e-14  7.02061708e-12\n",
      "   7.06642948e-12  7.13749436e-12  1.00468908e-12  3.46061020e-01\n",
      "   2.74263101e-01  9.93516895e-01]\n",
      " [ 9.58300000e+00  4.70181884e-11  3.49097377e-14  5.70735909e-12\n",
      "   4.74950787e-12  4.81193555e-12  7.72592244e-13  8.97093774e-01\n",
      "   1.94728311e+00  1.20167378e+00]\n",
      " [ 9.56800000e+00  5.14352066e-11  7.76830319e-14  6.42302278e-12\n",
      "   5.19556289e-12  5.26264876e-12  8.37614571e-13  9.01950234e-01\n",
      "   1.96753722e+00  1.23625157e+00]\n",
      " [ 5.37300000e+00  7.13184327e-11  3.36240440e-14  8.47417113e-12\n",
      "   7.20394898e-12  7.28861774e-12  1.10773082e-12  4.50951292e-01\n",
      "   5.62966642e-01  1.17632304e+00]\n",
      " [ 9.56400000e+00  1.25573949e-10  4.17150065e-14  1.13332597e-11\n",
      "   1.26843596e-11  1.27985913e-11  1.70615359e-12  1.40961743e-01\n",
      "   9.00698985e-03  8.93482999e-01]\n",
      " [ 2.02700000e+00  1.70424885e-10 -1.07320334e-13  1.96384338e-11\n",
      "   1.72147450e-11  1.74159970e-11  2.63998241e-12  3.09655204e-01\n",
      "   3.12282686e-01  1.14079144e+00]\n",
      " [ 8.36300000e+00  5.16054131e-11  4.92411937e-14  5.12463885e-12\n",
      "   5.21276966e-12  5.27108404e-12  7.81894742e-13  3.48787774e-01\n",
      "   2.93471959e-02  9.83093286e-01]\n",
      " [ 8.36300000e+00  5.16054131e-11  4.92411937e-14  5.12463885e-12\n",
      "   5.21276966e-12  5.27108404e-12  7.81894742e-13  3.48787774e-01\n",
      "   2.93471959e-02  9.83093286e-01]\n",
      " [ 1.39800000e+00  1.16107136e-10 -5.73128068e-14  1.22926991e-11\n",
      "   1.17281926e-11  1.18618015e-11  1.77533999e-12  2.84649233e-01\n",
      "   1.53269979e-01  1.04813243e+00]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [330]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Loop through selected indices to trace back channels and features\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m train_healthy_selected_features_rsec:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_healthy_psd_rsec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m:  \u001b[38;5;66;03m# Check if the index belongs to array1\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         channel \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m features_per_channel_array1\n\u001b[0;32m     16\u001b[0m         feature \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m%\u001b[39m features_per_channel_array1\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of features per channel for each array\n",
    "features_per_channel_array1 = 4\n",
    "features_per_channel_array2 = 13\n",
    "\n",
    "# Initialize lists to store channel and feature information\n",
    "channels = []\n",
    "features = []\n",
    "print('features indices are')\n",
    "print(train_healthy_selected_features_rsec)\n",
    "# Loop through selected indices to trace back channels and features\n",
    "for idx in train_healthy_selected_features_rsec:\n",
    "    if idx < train_healthy_psd_rsec.reshape(10, -1).shape[1]:  # Check if the index belongs to array1\n",
    "        channel = idx // features_per_channel_array1\n",
    "        feature = idx % features_per_channel_array1\n",
    "        print('channel is')\n",
    "        print(channel)\n",
    "        print('its feature is')\n",
    "        print(feature)\n",
    "        channels.append(channel)\n",
    "        features.append(feature)\n",
    "    else:  # The index belongs to array2\n",
    "        print('in else')\n",
    "        idx -= train_healthy_psd_rsec.reshape(10, -1).shape[1]\n",
    "        print('idx is')\n",
    "        print(idx)\n",
    "        channel = idx // features_per_channel_array2\n",
    "        feature = idx % features_per_channel_array2\n",
    "        print('channel is')\n",
    "        print(channel)\n",
    "        print('its feature is')\n",
    "        print(feature)\n",
    "        channels.append(channel)\n",
    "        features.append(feature)\n",
    "\n",
    "# Print the traced back information\n",
    "print(\"Selected Indices belong to Channels and Features:\")\n",
    "for i in range(len(train_healthy_selected_features_rsec)):\n",
    "    print(f\"Index {train_healthy_selected_features_rsec[i]}: Channel {channels[i] + 1}, Feature {features[i] + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "876a4302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813', 'MEG1622+1623', 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n"
     ]
    }
   ],
   "source": [
    "print(selected_channels_rsec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "95082702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.5, 0.9, 0.6, 0.5, 0.1, 0.7, 0.5, 0.6, 0.7, 0.6, 0.8, 0.6, 0.7, 0.3, 0.6, 0.7, 0.6, 0.6, 0.7, 0.5, 0.7, 0.6, 0.5, 0.6, 0.6, 0.3, 0.4, 0.5, 0.5, 0.8, 0.6, 0.8, 0.6, 0.6, 0.4, 0.5, 0.3, 0.5, 0.6, 0.6, 0.6, 0.8, 0.5, 0.5, 0.7, 0.8, 0.9, 1.0, 1.0, 0.5, 0.5, 1.0, 0.9, 0.6, 0.5, 0.7, 0.4, 0.8, 0.9, 0.4, 0.8, 0.9, 1.0, 1.0, 0.8, 0.9, 0.5, 0.5, 0.4, 0.5, 0.8, 0.7, 0.3, 0.7, 0.6, 0.9, 0.9, 0.6, 0.9, 0.4, 0.4, 0.7, 0.4, 0.6, 1.0, 0.2, 0.7, 0.7, 0.5, 0.8, 0.4, 0.4, 0.6, 0.7]\n"
     ]
    }
   ],
   "source": [
    "# print(iterative_channel_selection_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "06a36468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# print(best_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184188bb",
   "metadata": {},
   "source": [
    "# Anomaly detection: Eyes open data \n",
    "trained on 11 healthy subjects; tested on (5 healthy + 5 MCI) using k-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf6e9bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected .mat files:\n",
      "PreProcessed_AD001_Preprocessed_EO.mat\n",
      "PreProcessed_AD002_Preprocessed_EO.mat\n",
      "PreProcessed_AD003_Preprocessed_EO.mat\n",
      "PreProcessed_AD004_Preprocessed_EO.mat\n",
      "PreProcessed_AD006_Preprocessed_EO.mat\n",
      "PreProcessed_AD008_Preprocessed_EO.mat\n",
      "PreProcessed_AD010_Preprocessed_EO.mat\n",
      "PreProcessed_AD011_Preprocessed_EO.mat\n",
      "PreProcessed_AD012_Preprocessed_EO.mat\n",
      "PreProcessed_AD013_Preprocessed_EO.mat\n",
      "PreProcessed_AD014_Preprocessed_EO.mat\n",
      "PreProcessed_AD015_Preprocessed_EO.mat\n",
      "PreProcessed_AD016_Preprocessed_EO.mat\n",
      "PreProcessed_AD017_Preprocessed_EO.mat\n",
      "PreProcessed_AD018_Preprocessed_EO.mat\n",
      "PreProcessed_AD020_Preprocessed_EO.mat\n",
      "PreProcessed_AD026_Preprocessed_EO.mat\n",
      "PreProcessed_AD027_Preprocessed_EO.mat\n",
      "PreProcessed_AD028_Preprocessed_EO.mat\n",
      "PreProcessed_AD030_Preprocessed_EO.mat\n",
      "PreProcessed_AD031_Preprocessed_EO.mat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_eyes_open\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_rseo = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_rseo:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b5ec2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcessed_AD001_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD002_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD003_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD004_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD006_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD008_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD010_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD011_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD012_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD013_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD014_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD015_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD016_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD017_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD018_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD020_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_EO.mat\n",
      "15\n",
      "PreProcessed_AD027_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD028_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD030_Preprocessed_EO.mat\n",
      "16\n",
      "PreProcessed_AD031_Preprocessed_EO.mat\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "num_trials=0\n",
    "trial_counts_rseo=[]\n",
    "for subject in range(len(matfiles_rseo)):\n",
    "    subject_data = []\n",
    "    name=matfiles_rseo[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_rseo[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_rseo.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4093a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_counts_rseo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "066dec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trial_counts_rseo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df497732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "0\n",
      "PreProcessed_AD001_Preprocessed_EO.mat\n",
      "0\n",
      "16\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "16\n",
      "subject idx is\n",
      "1\n",
      "PreProcessed_AD002_Preprocessed_EO.mat\n",
      "0\n",
      "32\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "32\n",
      "subject idx is\n",
      "2\n",
      "PreProcessed_AD003_Preprocessed_EO.mat\n",
      "0\n",
      "48\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "48\n",
      "subject idx is\n",
      "3\n",
      "PreProcessed_AD004_Preprocessed_EO.mat\n",
      "0\n",
      "64\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "64\n",
      "subject idx is\n",
      "4\n",
      "PreProcessed_AD006_Preprocessed_EO.mat\n",
      "0\n",
      "80\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "80\n",
      "subject idx is\n",
      "5\n",
      "PreProcessed_AD008_Preprocessed_EO.mat\n",
      "0\n",
      "96\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "96\n",
      "subject idx is\n",
      "6\n",
      "PreProcessed_AD010_Preprocessed_EO.mat\n",
      "0\n",
      "112\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "112\n",
      "subject idx is\n",
      "7\n",
      "PreProcessed_AD011_Preprocessed_EO.mat\n",
      "0\n",
      "128\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "128\n",
      "subject idx is\n",
      "8\n",
      "PreProcessed_AD012_Preprocessed_EO.mat\n",
      "0\n",
      "144\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "144\n",
      "subject idx is\n",
      "9\n",
      "PreProcessed_AD013_Preprocessed_EO.mat\n",
      "0\n",
      "160\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "160\n",
      "subject idx is\n",
      "10\n",
      "PreProcessed_AD014_Preprocessed_EO.mat\n",
      "0\n",
      "176\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "176\n",
      "subject idx is\n",
      "11\n",
      "PreProcessed_AD015_Preprocessed_EO.mat\n",
      "0\n",
      "192\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "192\n",
      "subject idx is\n",
      "12\n",
      "PreProcessed_AD016_Preprocessed_EO.mat\n",
      "0\n",
      "208\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "208\n",
      "subject idx is\n",
      "13\n",
      "PreProcessed_AD017_Preprocessed_EO.mat\n",
      "0\n",
      "224\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "224\n",
      "subject idx is\n",
      "14\n",
      "PreProcessed_AD018_Preprocessed_EO.mat\n",
      "0\n",
      "240\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "240\n",
      "subject idx is\n",
      "15\n",
      "PreProcessed_AD020_Preprocessed_EO.mat\n",
      "0\n",
      "256\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "256\n",
      "subject idx is\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_EO.mat\n",
      "0\n",
      "271\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "271\n",
      "subject idx is\n",
      "17\n",
      "PreProcessed_AD027_Preprocessed_EO.mat\n",
      "0\n",
      "287\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "287\n",
      "subject idx is\n",
      "18\n",
      "PreProcessed_AD028_Preprocessed_EO.mat\n",
      "0\n",
      "303\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "303\n",
      "subject idx is\n",
      "19\n",
      "PreProcessed_AD030_Preprocessed_EO.mat\n",
      "0\n",
      "319\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "319\n",
      "subject idx is\n",
      "20\n",
      "PreProcessed_AD031_Preprocessed_EO.mat\n",
      "0\n",
      "335\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=9901\n",
      "    Range : 0 ... 9900 =      0.000 ...     9.900 secs\n",
      "Ready.\n",
      "335\n"
     ]
    }
   ],
   "source": [
    "#without grand averaging for kaniska sir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_rseo = []\n",
    "    \n",
    "\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_rseo):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_rseo[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_rseo[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "\n",
    "            \n",
    "# # print(len(raw_combined_mean_mci_ts))\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "        trial=trial_data[0]\n",
    "        raw = mne.io.RawArray(trial, info)\n",
    "        raw_list_mean_rseo.append(raw)\n",
    "    print(len(raw_list_mean_rseo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72b36542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>,\n",
       " <RawArray | 102 x 9901 (9.9 s), ~7.8 MB, data loaded>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_list_mean_rseo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b81d135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:36: RuntimeWarning: invalid value encountered in true_divide\n",
      "  beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\586420793.py:53: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features_psd_rseo = np.array(features_psd_rseo)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "features_psd_rseo = []\n",
    "for raw in raw_list_mean_rseo:\n",
    "    # Compute PSD\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
    "    #psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=0, fmax=40, tmin=None, tmax=None)\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    \n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(list_1):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "        \n",
    "        \n",
    "\n",
    "    # Statistical Features\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "    \n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        \n",
    "                    # Compute entropy for alpha band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Compute entropy for beta band\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        \n",
    " \n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        \n",
    "       \n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "    \n",
    "    features_psd_rseo.append(features)\n",
    "    \n",
    "features_psd_rseo = np.array(features_psd_rseo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cabf813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.2276929087765274e-25, 3.998988659264755e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.3130365421082524e-25,\n",
       "         0.5212658277168896, 0.9696345451375732],\n",
       "        [1.300991034604867e-25, 2.990595473218604e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.5552444787380087e-25,\n",
       "         0.5294233532717435, 0.9797109892542122],\n",
       "        [1.3102693044174005e-25, 5.0216227427464215e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.5679607917467266e-25,\n",
       "         0.5248530797442795, 0.9463264537379514],\n",
       "        ...,\n",
       "        [6.652454190924905e-26, 1.074032270988968e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 1.2717382347575834e-25,\n",
       "         0.5244376137837149, 0.9694418967468352],\n",
       "        [5.9727437599771e-26, 6.390097480428914e-52,\n",
       "         array([nan, nan, nan, nan]), ..., 1.2769025707808533e-25,\n",
       "         0.5307311278410398, 1.001022599473779],\n",
       "        [1.119869190820366e-25, 1.6963812375755624e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.3838770641921116e-25,\n",
       "         0.5305021374083777, 1.0096885428717728]],\n",
       "\n",
       "       [[1.2276929087765274e-25, 3.998988659264755e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.3130365421082524e-25,\n",
       "         0.5212658277168896, 0.9696345451375732],\n",
       "        [1.300991034604867e-25, 2.990595473218604e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.5552444787380087e-25,\n",
       "         0.5294233532717435, 0.9797109892542122],\n",
       "        [1.3102693044174005e-25, 5.0216227427464215e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.5679607917467266e-25,\n",
       "         0.5248530797442795, 0.9463264537379514],\n",
       "        ...,\n",
       "        [6.652454190924905e-26, 1.074032270988968e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 1.2717382347575834e-25,\n",
       "         0.5244376137837149, 0.9694418967468352],\n",
       "        [5.9727437599771e-26, 6.390097480428914e-52,\n",
       "         array([nan, nan, nan, nan]), ..., 1.2769025707808533e-25,\n",
       "         0.5307311278410398, 1.001022599473779],\n",
       "        [1.119869190820366e-25, 1.6963812375755624e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.3838770641921116e-25,\n",
       "         0.5305021374083777, 1.0096885428717728]],\n",
       "\n",
       "       [[1.2276929087765274e-25, 3.998988659264755e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.3130365421082524e-25,\n",
       "         0.5212658277168896, 0.9696345451375732],\n",
       "        [1.300991034604867e-25, 2.990595473218604e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.5552444787380087e-25,\n",
       "         0.5294233532717435, 0.9797109892542122],\n",
       "        [1.3102693044174005e-25, 5.0216227427464215e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.5679607917467266e-25,\n",
       "         0.5248530797442795, 0.9463264537379514],\n",
       "        ...,\n",
       "        [6.652454190924905e-26, 1.074032270988968e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 1.2717382347575834e-25,\n",
       "         0.5244376137837149, 0.9694418967468352],\n",
       "        [5.9727437599771e-26, 6.390097480428914e-52,\n",
       "         array([nan, nan, nan, nan]), ..., 1.2769025707808533e-25,\n",
       "         0.5307311278410398, 1.001022599473779],\n",
       "        [1.119869190820366e-25, 1.6963812375755624e-51,\n",
       "         array([nan, nan, nan, nan]), ..., 2.3838770641921116e-25,\n",
       "         0.5305021374083777, 1.0096885428717728]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.8880935220351703e-25, 1.4315256396321054e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 3.2683174253820773e-25,\n",
       "         0.5044023934563856, 0.9185153598169336],\n",
       "        [1.4142794334782001e-24, 2.2400568361779445e-48,\n",
       "         array([nan, nan, nan, nan]), ..., 1.6465193028317896e-24,\n",
       "         0.3724238263658415, 0.725988860140693],\n",
       "        [6.015861110912123e-25, 2.779990133588335e-49,\n",
       "         array([nan, nan, nan, nan]), ..., 8.402997279642028e-25,\n",
       "         0.4377139438557262, 0.8299738971001771],\n",
       "        ...,\n",
       "        [4.871497205367268e-25, 1.995610709159312e-49,\n",
       "         array([nan, nan, nan, nan]), ..., 6.966239196845542e-25,\n",
       "         0.4331175901248443, 0.801627667795048],\n",
       "        [2.3539104366665904e-25, 3.9629572991738953e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 3.534129050564298e-25,\n",
       "         0.45353340894222693, 0.8408133837434247],\n",
       "        [2.391650693102695e-25, 3.1528339950394487e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 4.0470422402977936e-25,\n",
       "         0.48837631454117425, 0.8748447320512183]],\n",
       "\n",
       "       [[1.8880935220351703e-25, 1.4315256396321054e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 3.2683174253820773e-25,\n",
       "         0.5044023934563856, 0.9185153598169336],\n",
       "        [1.4142794334782001e-24, 2.2400568361779445e-48,\n",
       "         array([nan, nan, nan, nan]), ..., 1.6465193028317896e-24,\n",
       "         0.3724238263658415, 0.725988860140693],\n",
       "        [6.015861110912123e-25, 2.779990133588335e-49,\n",
       "         array([nan, nan, nan, nan]), ..., 8.402997279642028e-25,\n",
       "         0.4377139438557262, 0.8299738971001771],\n",
       "        ...,\n",
       "        [4.871497205367268e-25, 1.995610709159312e-49,\n",
       "         array([nan, nan, nan, nan]), ..., 6.966239196845542e-25,\n",
       "         0.4331175901248443, 0.801627667795048],\n",
       "        [2.3539104366665904e-25, 3.9629572991738953e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 3.534129050564298e-25,\n",
       "         0.45353340894222693, 0.8408133837434247],\n",
       "        [2.391650693102695e-25, 3.1528339950394487e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 4.0470422402977936e-25,\n",
       "         0.48837631454117425, 0.8748447320512183]],\n",
       "\n",
       "       [[1.8880935220351703e-25, 1.4315256396321054e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 3.2683174253820773e-25,\n",
       "         0.5044023934563856, 0.9185153598169336],\n",
       "        [1.4142794334782001e-24, 2.2400568361779445e-48,\n",
       "         array([nan, nan, nan, nan]), ..., 1.6465193028317896e-24,\n",
       "         0.3724238263658415, 0.725988860140693],\n",
       "        [6.015861110912123e-25, 2.779990133588335e-49,\n",
       "         array([nan, nan, nan, nan]), ..., 8.402997279642028e-25,\n",
       "         0.4377139438557262, 0.8299738971001771],\n",
       "        ...,\n",
       "        [4.871497205367268e-25, 1.995610709159312e-49,\n",
       "         array([nan, nan, nan, nan]), ..., 6.966239196845542e-25,\n",
       "         0.4331175901248443, 0.801627667795048],\n",
       "        [2.3539104366665904e-25, 3.9629572991738953e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 3.534129050564298e-25,\n",
       "         0.45353340894222693, 0.8408133837434247],\n",
       "        [2.391650693102695e-25, 3.1528339950394487e-50,\n",
       "         array([nan, nan, nan, nan]), ..., 4.0470422402977936e-25,\n",
       "         0.48837631454117425, 0.8748447320512183]]], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_psd_rseo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b86fe9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 102, 10)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_psd_rseo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c8626dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_rseo = np.delete(features_psd_rseo, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c900da21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 102, 8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features_psd_rseo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5459c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "0\n",
      "PreProcessed_AD001_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "16\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "1\n",
      "PreProcessed_AD002_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "32\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "2\n",
      "PreProcessed_AD003_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "48\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "3\n",
      "PreProcessed_AD004_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "64\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "4\n",
      "PreProcessed_AD006_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "80\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "5\n",
      "PreProcessed_AD008_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "96\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "6\n",
      "PreProcessed_AD010_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "112\n",
      "(204, 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\2597447109.py:123: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  aar = peak_to_peak_amplitude / mean_absolute_amplitude\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "7\n",
      "PreProcessed_AD011_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "128\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "8\n",
      "PreProcessed_AD012_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "144\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "9\n",
      "PreProcessed_AD013_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "160\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "10\n",
      "PreProcessed_AD014_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "176\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "11\n",
      "PreProcessed_AD015_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "192\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "12\n",
      "PreProcessed_AD016_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "208\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "13\n",
      "PreProcessed_AD017_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "224\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "14\n",
      "PreProcessed_AD018_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "240\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "15\n",
      "PreProcessed_AD020_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "256\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "271\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "17\n",
      "PreProcessed_AD027_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "287\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "18\n",
      "PreProcessed_AD028_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "303\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "19\n",
      "PreProcessed_AD030_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "319\n",
      "(204, 10001)\n",
      "subject idx is\n",
      "20\n",
      "PreProcessed_AD031_Preprocessed_EO.mat\n",
      "in if\n",
      "0\n",
      "335\n",
      "(204, 10001)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "evoked_list = []\n",
    "features_erp_rseo = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_rseo):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_rseo[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_rseo[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end) \n",
    "    print(new[0].shape)\n",
    "    trial_data=[]\n",
    "    # Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "        trial=trial_data[0]\n",
    "        features=[]\n",
    "        for ch_idx in range(len(info['ch_names'])):\n",
    "            # Extract ERP data for the current channel\n",
    "            channel_data = trial[ch_idx,:]\n",
    "\n",
    "\n",
    "        # Compute peak amplitude and latency\n",
    "            peak_amplitude = np.max(channel_data)\n",
    "             # Compute peak-to-peak amplitude\n",
    "            peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "            # Compute mean absolute amplitude\n",
    "            mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "            mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "                # Compute RMS amplitude\n",
    "            rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "            rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "            # Compute standard deviation\n",
    "            std_dev = np.std(channel_data)\n",
    "            std_devs.append(std_dev)\n",
    "\n",
    "            # Compute skewness\n",
    "            skewness = skew(channel_data)\n",
    "            skewness_values.append(skewness)\n",
    "\n",
    "            # Compute kurtosis\n",
    "            kurtosis_val = kurtosis(channel_data)\n",
    "            kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "            # Compute zero crossing rate\n",
    "            zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "            zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "            latency = times[np.argmax(channel_data)]\n",
    "\n",
    "        # Calculate area under the curve (AUC)\n",
    "            auc_value = simps(channel_data, times)\n",
    "\n",
    "        # Calculate slope (e.g., by fitting a linear regression model)\n",
    "        # You can use numpy's polyfit function for this purpose\n",
    "            slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "            slope = slope_coefficients[0]\n",
    "\n",
    "\n",
    "            zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "            zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "            # Compute AAR\n",
    "            aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "            aar_values.append(aar)\n",
    "\n",
    "            # Compute ZORK\n",
    "            zork = zero_crossings / kurtosis_val\n",
    "            zork_values.append(zork)\n",
    "\n",
    "            peak_to_peak_amplitudes1=np.array(peak_to_peak_amplitudes)\n",
    "            channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                                peak_to_peak_amplitude, \n",
    "                                     mean_absolute_amplitude, \n",
    "                                     rms_amplitude, \n",
    "                                     std_dev, \n",
    "                                     skewness, \n",
    "                                     kurtosis_val, \n",
    "                                     zero_crossings,aar,zork]\n",
    "\n",
    "            features.append(channel_features)\n",
    "\n",
    "        features_erp_rseo.append(features)\n",
    "    \n",
    "features_erp_rseo = np.array(features_erp_rseo,dtype=object)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef430bb",
   "metadata": {},
   "source": [
    "## Alternate code for extracting ERP features from grand averaged data; can be used for other classes (rsec,1st click, 2nd click) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19e4b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "    \n",
    "# # Import necessary libraries\n",
    "# from scipy.stats import skew, kurtosis\n",
    "# from scipy.signal import find_peaks\n",
    "# from numpy import diff\n",
    "# # Initialize an empty list to store subject data\n",
    "# subject_data_list = []\n",
    "# evoked_list = []\n",
    "# features_erp_rseo = []\n",
    "\n",
    "# # Size of each array\n",
    "# array_size = (102, 201)\n",
    "# num_trials=0\n",
    "# start=0\n",
    "# raw_list = []\n",
    "# # Simulating data for demonstration purposes\n",
    "# # Replace this part with your actual data retrieval process in the nested loops\n",
    "# for subject, trials in enumerate(trial_counts_rseo):\n",
    "#     subject_data = []\n",
    "#     print('subject idx is')\n",
    "#     print(subject)\n",
    "    \n",
    "#     name=matfiles_rseo[subject]\n",
    "#     print(name)\n",
    "#     dat = mat73.loadmat(matfiles_rseo[subject])\n",
    "#     data = pd.DataFrame.from_dict(dat)\n",
    "#     if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "#         print('in if')\n",
    "#         new=data.iloc[6,0]\n",
    "#     else:\n",
    "#         new=data.iloc[7,0]\n",
    "    \n",
    "#     num_trials+=len(new)\n",
    "\n",
    "#     print(start)\n",
    "#     end=num_trials\n",
    "#     print(end) \n",
    "#     print(new[0].shape)\n",
    "#     trial_data=[]\n",
    "# # Loop through subjects\n",
    "#     for trial in range(trials):\n",
    "#         #print(new[0].shape[1])\n",
    "#         if new[0].shape[1] == 10001:\n",
    "#             trial_data.append(new[trial][:102,:9901])\n",
    "#             times = grand_average_rsec_healthy.times\n",
    "            \n",
    "#         else:\n",
    "#             trial_data.append(new[trial][:102,200:351])\n",
    "#             times = grand_average_healthy.times\n",
    "            \n",
    "#     # Compute the average across trials for the current subject\n",
    "#     average_data_healthy = np.mean(trial_data, axis=0)\n",
    "#     print(average_data_healthy.shape)\n",
    "    \n",
    "# # Create empty lists to store features\n",
    "#     peak_amplitudes = []\n",
    "#     latencies = []\n",
    "#     auc_values = []\n",
    "#     slopes = []\n",
    "#     features_erp_1st_click_healthy=[]\n",
    "#     features=[]\n",
    "#     from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "#     # Initialize empty lists to store features\n",
    "#     peak_to_peak_amplitudes = []\n",
    "#     mean_absolute_amplitudes = []\n",
    "#     rms_amplitudes = []\n",
    "#     std_devs = []\n",
    "#     skewness_values = []\n",
    "#     kurtosis_values = []\n",
    "#     zero_crossing_rates = []\n",
    "#     aar_values=[]\n",
    "#     zork_values=[]\n",
    "\n",
    "\n",
    "# # Iterate through channels\n",
    "#     for ch_idx in range(len(info['ch_names'])):\n",
    "#         # Extract ERP data for the current channel\n",
    "#         channel_data = average_data_healthy[ch_idx,:]\n",
    "        \n",
    "    \n",
    "#     # Compute peak amplitude and latency\n",
    "#         peak_amplitude = np.max(channel_data)\n",
    "#          # Compute peak-to-peak amplitude\n",
    "#         peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "#         peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "#         # Compute mean absolute amplitude\n",
    "#         mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "#         mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "#             # Compute RMS amplitude\n",
    "#         rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "#         rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "#         # Compute standard deviation\n",
    "#         std_dev = np.std(channel_data)\n",
    "#         std_devs.append(std_dev)\n",
    "\n",
    "#         # Compute skewness\n",
    "#         skewness = skew(channel_data)\n",
    "#         skewness_values.append(skewness)\n",
    "\n",
    "#         # Compute kurtosis\n",
    "#         kurtosis_val = kurtosis(channel_data)\n",
    "#         kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "#         # Compute zero crossing rate\n",
    "#         zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "#         zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "#         latency = times[np.argmax(channel_data)]\n",
    "    \n",
    "#     # Calculate area under the curve (AUC)\n",
    "#         auc_value = simps(channel_data, times)\n",
    "    \n",
    "#     # Calculate slope (e.g., by fitting a linear regression model)\n",
    "#     # You can use numpy's polyfit function for this purpose\n",
    "#         slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "#         slope = slope_coefficients[0]\n",
    "        \n",
    "        \n",
    "#         zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "#         zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "#         # Compute AAR\n",
    "#         aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "#         aar_values.append(aar)\n",
    "\n",
    "#         # Compute ZORK\n",
    "#         zork = zero_crossings / kurtosis_val\n",
    "#         zork_values.append(zork)\n",
    "        \n",
    "#         peak_to_peak_amplitudes1=np.array(peak_to_peak_amplitudes)\n",
    "#         channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "#                             peak_to_peak_amplitude, \n",
    "#                                  mean_absolute_amplitude, \n",
    "#                                  rms_amplitude, \n",
    "#                                  std_dev, \n",
    "#                                  skewness, \n",
    "#                                  kurtosis_val, \n",
    "#                                  zero_crossings,aar,zork]\n",
    "\n",
    "#         features.append(channel_features)\n",
    "\n",
    "#     features_erp_rseo.append(features)\n",
    "    \n",
    "# features_erp_rseo = np.array(features_erp_rseo,dtype=object)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "416c3c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 102, 13)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_rseo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98529948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 102, 4)\n"
     ]
    }
   ],
   "source": [
    "usable_features_psd_rseo=new_features_psd_rseo[:,:,4:8]\n",
    "print(usable_features_psd_rseo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5f2d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSD shape: (21,)\n",
      "ERP shape: (21,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\3312667585.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  reshaped_psd = np.array(reshaped_psd)\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_12476\\3312667585.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  reshaped_erp = np.array(reshaped_erp)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize empty lists to store reshaped data\n",
    "reshaped_psd = []\n",
    "reshaped_erp = []\n",
    "\n",
    "# Initialize start index\n",
    "start_idx = 0\n",
    "\n",
    "# Loop through each subject\n",
    "for i, count in enumerate(trial_counts_rseo):\n",
    "    # End index for the current subject\n",
    "    end_idx = start_idx + count\n",
    "    \n",
    "    # Reshape PSD data for the current subject\n",
    "    subject_psd = usable_features_psd_rsec[start_idx:end_idx, :, :]\n",
    "    reshaped_psd.append(subject_psd)\n",
    "    \n",
    "    # Reshape ERP data for the current subject\n",
    "    subject_erp = features_erp_rsec[start_idx:end_idx, :, :]\n",
    "    reshaped_erp.append(subject_erp)\n",
    "    \n",
    "    # Update start index for the next subject\n",
    "    start_idx = end_idx\n",
    "\n",
    "# Convert the lists to arrays\n",
    "reshaped_psd = np.array(reshaped_psd)\n",
    "reshaped_erp = np.array(reshaped_erp)\n",
    "\n",
    "# Check the shapes\n",
    "print(\"PSD shape:\", reshaped_psd.shape)  # Should be (21, trials_per_subject, 102, 4)\n",
    "print(\"ERP shape:\", reshaped_erp.shape)  # Should be (21, trials_per_subject, 102, 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "030d1747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 102, 4)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_psd[16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "# Specify the location to save the files\n",
    "save_path_psd = 'C:/path_to_save_location/usable_features_psd_rseo_reshaped.mat'\n",
    "save_path_erp = 'C:/path_to_save_location/features_erp_rseo_reshaped.mat'\n",
    "\n",
    "# Save the reshaped PSD features\n",
    "sio.savemat(save_path_psd, {'usable_features_psd_rsec_reshaped': usable_features_psd_rsec_reshaped})\n",
    "\n",
    "# Save the reshaped ERP features\n",
    "sio.savemat(save_path_erp, {'features_erp_rsec_reshaped': features_erp_rsec_reshaped})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c41ce",
   "metadata": {},
   "source": [
    "# uncomment 2 cells below to save extracted features in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5ce40396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pickle\n",
    "# with open('features_psd_rseo.pkl', 'wb') as file: \n",
    "#     pickle.dump(usable_features_psd_rseo, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a3e8317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('features_erp_rseo.pkl', 'wb') as file: \n",
    "#     pickle.dump(features_erp_rseo, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "80b56c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_psd_rseo.pkl','rb') as file:\n",
    "    usable_features_psd_rseo=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e383ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_erp_rseo.pkl','rb') as file:\n",
    "    features_erp_rseo=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5ea21",
   "metadata": {},
   "source": [
    "## feature selection and anomaly detection pipeline on rseo data: what channel subset and what corresponding features of selected channel subset work best for rseo data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4ef38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np    \n",
    "def evaluate_performance(X_train, X_test, y_test):\n",
    "    size = X_train.shape[0]\n",
    "    y_train = np.ones(size)\n",
    "    one_class_svm = OneClassSVM()\n",
    "    loo = LeaveOneOut()\n",
    "    fold_accuracies = []\n",
    "    predictions = []\n",
    "    for train_index, test_index in loo.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        one_class_svm.fit(X_train_fold)\n",
    "        predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "        predictions.append(predictions_fold)\n",
    "            # Print classification report for the fold\n",
    "        print(f\"Classification Report - Fold:\")\n",
    "        print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test_fold, predictions_fold)\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "       # Evaluate the model on the entire test set\n",
    "   \n",
    "    # Combine predictions from all folds\n",
    "    predictions = np.concatenate(predictions)\n",
    "    print('concatenated predictions are')\n",
    "    print(predictions)\n",
    "\n",
    "    # Evaluate the model on the entire test set\n",
    "    test_predictions = one_class_svm.predict(X_test)\n",
    "    # Calculate accuracy for the entire test set\n",
    "    test_set_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    print(\"Final Classification Report:\")\n",
    "    print(classification_report(y_test, test_predictions, zero_division=0))  \n",
    " \n",
    "\n",
    "    # Calculate overall confusion matrix\n",
    "    cm = confusion_matrix(y_test, test_predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate overall sensitivity, specificity, and macro F1 score\n",
    "    overall_sensitivity = tp / (tp + fn)\n",
    "    overall_specificity = tn / (tn + fp)\n",
    "    overall_macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print(\"Overall Metrics:\")\n",
    "    print(f\"Overall Sensitivity: {overall_sensitivity}\")\n",
    "    print(f\"Overall Specificity: {overall_specificity}\")\n",
    "    print(f\"Overall Macro F1 Score: {overall_macro_f1}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return test_set_accuracy, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "46bb3a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ch_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5601a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected channels indices\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101]\n",
      "(11, 102, 4)\n",
      "(11, 102, 13)\n",
      "(11, 1734)\n",
      "Indices of constant features: [ 418  420  431  433  444  446  457  459  470  472  483  485  496  498\n",
      "  509  511  522  524  535  537  548  550  561  563  574  576  587  589\n",
      "  600  602  613  615  626  628  639  641  652  654  665  667  678  680\n",
      "  691  693  704  706  717  719  730  732  743  745  756  758  769  771\n",
      "  782  784  795  797  808  810  821  823  834  836  847  849  860  862\n",
      "  873  875  886  888  899  901  912  914  925  927  938  940  951  953\n",
      "  964  966  977  979  990  992 1003 1005 1016 1018 1029 1031 1042 1044\n",
      " 1055 1057 1068 1070 1081 1083 1094 1096 1107 1109 1120 1122 1133 1135\n",
      " 1146 1148 1159 1161 1172 1174 1185 1187 1198 1200 1211 1213 1224 1226\n",
      " 1237 1239 1250 1252 1263 1265 1276 1278 1289 1291 1302 1304 1315 1317\n",
      " 1328 1330 1341 1343 1354 1356 1367 1369 1380 1382 1393 1395 1406 1408\n",
      " 1419 1421 1432 1434 1445 1447 1458 1460 1471 1473 1484 1486 1497 1499\n",
      " 1510 1512 1523 1525 1536 1538 1549 1551 1562 1564 1575 1577 1588 1590\n",
      " 1601 1603 1614 1616 1627 1629 1640 1642 1653 1655 1666 1668 1679 1692\n",
      " 1694 1705 1707 1718 1720 1731 1733]\n",
      "Shape after removing constant features: (11, 1531)\n",
      "Shape of train_healthy_selected_features_rseo after removing NaN columns: (11, 1525)\n",
      "Shape of X_test after removing NaN columns: (10, 1525)\n",
      "[ 1.  1.  1.  1.  1. -1. -1. -1. -1. -1.]\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       0.0\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\n",
      "\n",
      "Classification Report - Fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\n",
      "\n",
      "concatenated predictions are\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1  1  1]\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.80      0.80      0.80         5\n",
      "         1.0       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.80      0.80      0.80        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Sensitivity: 0.8\n",
      "Overall Specificity: 0.8\n",
      "Overall Macro F1 Score: 0.8000000000000002\n",
      "\n",
      "\n",
      "Test Set Accuracy: 0.8\n",
      "Fold Accuracies: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the pipeline with SelectKBest and OneClassSVM\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM())\n",
    "])\n",
    "iterative_channel_selection_accuracies=[]\n",
    "channel_subsets_best_perform_rseo=[]\n",
    "# Initialize variables\n",
    "#selected_channels_rseo = []\n",
    "\n",
    "#selected_channels_rseo=['MEG0142+0143','MEG1512+1513','MEG1542+1543','MEG1812+1813','MEG1622+1623','MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243']\n",
    "\n",
    "#selected_channels_rseo=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643']\n",
    "\n",
    "\n",
    "##IMPORTANT-TO-DO----------------------> initially CHANGE selected_channels_indices to contain 10 channels in left cerebral hemisphere and 10 channels in right cerebral hemisphere that lie in the auditory processing region of the brain;\n",
    "##-------------------------------------> to do this change initialize ch_aud = ch_aud=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1812+1813', 'MEG1622+1623' ,'MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG2412+2413','MEG2222+2223','MEG2422+2423','MEG2442+2443','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643','MEG1332+1333','MEG1342+1343']\n",
    "##-------------------------------------> before running this cell\n",
    "##-------------------------------------> without doing so, all 102 channels will be considered for feature selection\n",
    "\n",
    "selected_channel_indices = [list_1.index(i) for i in ch_aud]\n",
    "print('selected channels indices')\n",
    "print(selected_channel_indices)\n",
    "\n",
    "\n",
    "\n",
    "train_healthy_psd_rseo = usable_features_psd_rseo[:11,selected_channel_indices,:]\n",
    "test_psd_rseo = usable_features_psd_rseo[11:,selected_channel_indices,:]\n",
    "\n",
    "train_healthy_erp_rseo = features_erp_rseo[:11,selected_channel_indices,:]\n",
    "test_erp_rseo = features_erp_rseo[11:,selected_channel_indices,:]\n",
    "\n",
    "\n",
    "print(train_healthy_psd_rseo.shape)\n",
    "print(train_healthy_erp_rseo.shape)\n",
    "\n",
    "# 2. Feature Extraction\n",
    "# Flatten the PSD and ERP features\n",
    "train_healthy_features_rseo = np.concatenate((train_healthy_psd_rseo.reshape(11, -1),\n",
    "                                                    train_healthy_erp_rseo.reshape(11, -1)), axis=1)\n",
    "print(train_healthy_features_rseo.shape)\n",
    "\n",
    "\n",
    "#removing constant features\n",
    "# Reshape the array to make it a 2D array where each row represents a feature\n",
    "reshaped_features = train_healthy_features_rseo.reshape(11, -1)\n",
    "\n",
    "# Calculate the variance along axis 0\n",
    "variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "# Find indices of constant features (where variance is zero)\n",
    "constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "print(\"Indices of constant features:\", constant_feature_indices)\n",
    "\n",
    "# Remove constant features\n",
    "usable_train_healthy_features_rseo= np.delete(train_healthy_features_rseo, constant_feature_indices, axis=1)\n",
    "\n",
    "# Verify the shape after removing constant features\n",
    "print(\"Shape after removing constant features:\", usable_train_healthy_features_rseo.shape)\n",
    "\n",
    "\n",
    "test_features_rseo = np.concatenate((test_psd_rseo.reshape(10, -1),\n",
    "                                           test_erp_rseo.reshape(10, -1)), axis=1)\n",
    "usable_test_features_rseo=np.delete(test_features_rseo, constant_feature_indices, axis=1)\n",
    "# Convert data to numerical type if necessary\n",
    "\n",
    "usable_train_healthy_features_rseo=usable_train_healthy_features_rseo.astype(float)\n",
    "\n",
    "# Find indices of columns with NaN values in train_healthy_selected_features_rseo\n",
    "nan_indices = np.isnan(usable_train_healthy_features_rseo).any(axis=0)\n",
    "# Remove columns with NaN values from train_healthy_selected_features_rseo\n",
    "usable_nonnan_train_healthy_features_rseo = usable_train_healthy_features_rseo[:, ~nan_indices]\n",
    "    # Print shape after removing NaN columns\n",
    "print(\"Shape of train_healthy_selected_features_rseo after removing NaN columns:\", usable_nonnan_train_healthy_features_rseo.shape)\n",
    "\n",
    "# Remove corresponding columns from X_test\n",
    "usable_nonnan_test_features_rseo  = usable_test_features_rseo[:, ~nan_indices]\n",
    "\n",
    "\n",
    "print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rseo.shape)\n",
    "\n",
    "    # Perform the grid search\n",
    "# Assuming y is the second dimension of usable_nonnan_train_healthy_features_rseo\n",
    "_, y = usable_nonnan_train_healthy_features_rseo.shape\n",
    "\n",
    "# Create a list of indices with step size 10\n",
    "indices = list(range(10, y+1, 10))\n",
    "print(indices)\n",
    "\n",
    "\n",
    "# Print the selected indices and corresponding values\n",
    "print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "# Define the range of k values to try\n",
    "param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Define a custom scoring function for anomaly detection\n",
    "Example: F1-score\n",
    "scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "grid_search.fit(usable_nonnan_train_healthy_features_rseo, [1] * usable_nonnan_train_healthy_features_rseo.shape[0])\n",
    "\n",
    "# Get the best value of k\n",
    "best_k = grid_search.best_params_['selector__k']\n",
    "print(\"Best value of k:\", best_k)\n",
    "\n",
    "# Select the best k features\n",
    "selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "train_healthy_selected_features_rseo = selector.fit_transform(usable_nonnan_train_healthy_features_rseo, [1] * usable_nonnan_train_healthy_features_rseo.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(selector.get_support()))\n",
    "# Use selected features for testing\n",
    "X_test = usable_nonnan_test_features_rseo[:, selector.get_support()]\n",
    "# X_test = usable_nonnan_test_features_rseo\n",
    "# Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "y_test = np.ones(X_test.shape[0])\n",
    "y_test[5:] = -1  # Labels for MCI subjects\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "test_set_accuracy, fold_accuracies = evaluate_performance(usable_nonnan_train_healthy_features_rseo, X_test, y_test)\n",
    "print(\"Test Set Accuracy:\", test_set_accuracy)\n",
    "print(\"Fold Accuracies:\", fold_accuracies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1eb58fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1432+1433', 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG0112+0113', 'MEG0212+0213', 'MEG0312+0313', 'MEG0342+0343', 'MEG0442+0443', 'MEG0612+0613', 'MEG0622+0623', 'MEG0632+0633', 'MEG0922+0923', 'MEG1012+1013', 'MEG1322+1323', 'MEG2232+2233']\n"
     ]
    }
   ],
   "source": [
    "print(selected_channels_rseo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2946a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels_rseo=['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1432+1433', 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG0112+0113', 'MEG0212+0213', 'MEG0312+0313', 'MEG0342+0343', 'MEG0442+0443', 'MEG0612+0613', 'MEG0622+0623', 'MEG0632+0633', 'MEG0922+0923', 'MEG1012+1013', 'MEG1322+1323', 'MEG2232+2233']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "01e5ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.6, 0.6, 0.8, 0.7, 0.5, 0.5, 0.8, 0.5, 0.7, 0.8, 0.5, 0.7, 0.4, 0.8, 0.7, 0.6, 0.7, 0.7, 0.8, 0.8, 0.8, 0.5, 0.7, 0.7, 0.5, 0.6, 0.5, 0.6, 0.4, 0.8, 0.7, 0.6, 0.8, 0.7, 0.6, 0.6, 0.7, 0.6, 0.5, 0.6, 0.5, 0.7, 0.7, 0.5, 0.6, 0.9, 0.7, 0.2, 0.7, 0.6, 0.7, 0.8, 0.5, 0.3, 0.3, 0.4, 0.6, 0.5, 0.5, 0.5, 0.6, 0.8, 0.6, 0.5, 0.4, 0.2, 0.5, 0.6, 0.8, 0.1, 0.5, 0.7, 0.4, 0.7, 0.7, 0.6, 0.6, 0.4, 0.3, 1.0, 0.8, 0.8, 0.5, 0.8, 0.8, 0.4, 0.5, 0.5, 0.7, 0.9, 0.6, 0.2, 0.5, 0.6]\n"
     ]
    }
   ],
   "source": [
    "print(iterative_channel_selection_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c895601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(best_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d6fa86a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 54, 57, 52, 98, 99, 101, 0, 4, 8, 11, 15, 20, 21, 22, 31, 34, 47, 84]]\n"
     ]
    }
   ],
   "source": [
    "print(channel_subsets_best_perform_rseo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f98eec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels_minimal_rseo=channel_subsets_best_perform_rseo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "287e41b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 54, 57, 52, 98, 99, 101, 0, 4, 8, 11, 15, 20, 21, 22, 31, 34, 47, 84]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_channels_minimal_rseo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddabc3c1",
   "metadata": {},
   "source": [
    "# Anomaly detection: 1st click data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_1st_click\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_1st_click = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_1st_click:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a8ebd847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcessed_AD001_Preprocessed_FirstClick.mat\n",
      "31\n",
      "PreProcessed_AD002_Preprocessed_FirstClick.mat\n",
      "61\n",
      "PreProcessed_AD003_Preprocessed_FirstClick.mat\n",
      "21\n",
      "PreProcessed_AD004_Preprocessed_FirstClick.mat\n",
      "32\n",
      "PreProcessed_AD006_Preprocessed_FirstClick.mat\n",
      "35\n",
      "PreProcessed_AD008_Preprocessed_FirstClick.mat\n",
      "28\n",
      "PreProcessed_AD010_Preprocessed_FirstClick.mat\n",
      "35\n",
      "PreProcessed_AD011_Preprocessed_FirstClick.mat\n",
      "28\n",
      "PreProcessed_AD012_Preprocessed_FirstClick.mat\n",
      "44\n",
      "PreProcessed_AD013_Preprocessed_FirstClick.mat\n",
      "40\n",
      "PreProcessed_AD014_Preprocessed_FirstClick.mat\n",
      "34\n",
      "PreProcessed_AD015_Preprocessed_FirstClick.mat\n",
      "26\n",
      "PreProcessed_AD016_Preprocessed_FirstClick.mat\n",
      "26\n",
      "PreProcessed_AD017_Preprocessed_FirstClick.mat\n",
      "26\n",
      "PreProcessed_AD018_Preprocessed_FirstClick.mat\n",
      "33\n",
      "PreProcessed_AD020_Preprocessed_FirstClick.mat\n",
      "25\n",
      "PreProcessed_AD026_Preprocessed_FirstClick.mat\n",
      "45\n",
      "PreProcessed_AD027_Preprocessed_FirstClick.mat\n",
      "34\n",
      "PreProcessed_AD028_Preprocessed_FirstClick.mat\n",
      "39\n",
      "PreProcessed_AD030_Preprocessed_FirstClick.mat\n",
      "44\n",
      "PreProcessed_AD031_Preprocessed_FirstClick.mat\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "num_trials=0\n",
    "trial_counts_1st_click=[]\n",
    "for subject in range(len(matfiles_1st_click)):\n",
    "    subject_data = []\n",
    "    name=matfiles_1st_click[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_1st_click[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_1st_click.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "95d8c58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31,\n",
       " 61,\n",
       " 21,\n",
       " 32,\n",
       " 35,\n",
       " 28,\n",
       " 35,\n",
       " 28,\n",
       " 44,\n",
       " 40,\n",
       " 34,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 33,\n",
       " 25,\n",
       " 45,\n",
       " 34,\n",
       " 39,\n",
       " 44,\n",
       " 44]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_counts_1st_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3845d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "0\n",
      "PreProcessed_AD001_Preprocessed_FirstClick.mat\n",
      "0\n",
      "31\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "1\n",
      "subject idx is\n",
      "1\n",
      "PreProcessed_AD002_Preprocessed_FirstClick.mat\n",
      "0\n",
      "92\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "2\n",
      "subject idx is\n",
      "2\n",
      "PreProcessed_AD003_Preprocessed_FirstClick.mat\n",
      "0\n",
      "113\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "3\n",
      "subject idx is\n",
      "3\n",
      "PreProcessed_AD004_Preprocessed_FirstClick.mat\n",
      "0\n",
      "145\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "4\n",
      "subject idx is\n",
      "4\n",
      "PreProcessed_AD006_Preprocessed_FirstClick.mat\n",
      "0\n",
      "180\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "5\n",
      "subject idx is\n",
      "5\n",
      "PreProcessed_AD008_Preprocessed_FirstClick.mat\n",
      "0\n",
      "208\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "6\n",
      "subject idx is\n",
      "6\n",
      "PreProcessed_AD010_Preprocessed_FirstClick.mat\n",
      "0\n",
      "243\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "7\n",
      "subject idx is\n",
      "7\n",
      "PreProcessed_AD011_Preprocessed_FirstClick.mat\n",
      "0\n",
      "271\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "8\n",
      "subject idx is\n",
      "8\n",
      "PreProcessed_AD012_Preprocessed_FirstClick.mat\n",
      "0\n",
      "315\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "9\n",
      "subject idx is\n",
      "9\n",
      "PreProcessed_AD013_Preprocessed_FirstClick.mat\n",
      "0\n",
      "355\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "10\n",
      "subject idx is\n",
      "10\n",
      "PreProcessed_AD014_Preprocessed_FirstClick.mat\n",
      "0\n",
      "389\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "11\n",
      "subject idx is\n",
      "11\n",
      "PreProcessed_AD015_Preprocessed_FirstClick.mat\n",
      "0\n",
      "415\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "12\n",
      "subject idx is\n",
      "12\n",
      "PreProcessed_AD016_Preprocessed_FirstClick.mat\n",
      "0\n",
      "441\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "13\n",
      "subject idx is\n",
      "13\n",
      "PreProcessed_AD017_Preprocessed_FirstClick.mat\n",
      "0\n",
      "467\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "14\n",
      "subject idx is\n",
      "14\n",
      "PreProcessed_AD018_Preprocessed_FirstClick.mat\n",
      "0\n",
      "500\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "15\n",
      "subject idx is\n",
      "15\n",
      "PreProcessed_AD020_Preprocessed_FirstClick.mat\n",
      "0\n",
      "525\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "16\n",
      "subject idx is\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_FirstClick.mat\n",
      "0\n",
      "570\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "17\n",
      "subject idx is\n",
      "17\n",
      "PreProcessed_AD027_Preprocessed_FirstClick.mat\n",
      "0\n",
      "604\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "18\n",
      "subject idx is\n",
      "18\n",
      "PreProcessed_AD028_Preprocessed_FirstClick.mat\n",
      "0\n",
      "643\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "19\n",
      "subject idx is\n",
      "19\n",
      "PreProcessed_AD030_Preprocessed_FirstClick.mat\n",
      "0\n",
      "687\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "20\n",
      "subject idx is\n",
      "20\n",
      "PreProcessed_AD031_Preprocessed_FirstClick.mat\n",
      "0\n",
      "731\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_1st_click = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_1st_click):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_1st_click[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_1st_click[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "   # Create RawArray object for the current trial\n",
    "    raw = mne.io.RawArray(average_data_healthy, info)\n",
    "\n",
    "    # Append the Raw object to the list\n",
    "    raw_list_mean_1st_click.append(raw)\n",
    "    print(len(raw_list_mean_1st_click))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_mci_ts = mne.concatenate_raws(raw_list_mean_mci_ts)\n",
    "\n",
    "# print(len(raw_combined_mean_mci_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "35bc487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_list_mean_1st_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "01ba438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\251301982.py:13: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\251301982.py:35: RuntimeWarning: invalid value encountered in true_divide\n",
      "  alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\251301982.py:39: RuntimeWarning: invalid value encountered in true_divide\n",
      "  beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\251301982.py:13: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\251301982.py:13: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\251301982.py:13: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "[ 9.09090909 18.18181818 27.27272727 36.36363636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\251301982.py:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features_psd_1st_click = np.array(features_psd_1st_click)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# Define frequency bands\n",
    "alpha_band = (8, 13)  # Alpha band frequencies\n",
    "beta_band = (13, 30)  # Beta band frequencies\n",
    "\n",
    "features_psd_1st_click = []\n",
    "for raw in raw_list_mean_1st_click:\n",
    "    # Compute PSD\n",
    " #   psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=4, fmax=40, tmin=None, tmax=None )\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    print(psd_spectrum_healthy.freqs)\n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(list_1):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "        \n",
    "\n",
    "    # Statistical Features\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "    \n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        \n",
    "                    # Compute entropy for alpha band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Compute entropy for beta band\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        \n",
    " \n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        \n",
    "       \n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "    \n",
    "    features_psd_1st_click.append(features)\n",
    "    \n",
    "features_psd_1st_click = np.array(features_psd_1st_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "adc4ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9ed64ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 102, 10)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_psd_1st_click.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "60c22842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.723344387917146e-27, 1.8655940929494685e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 4.041111185775686e-27, 4.041111185775686e-27,\n",
       "        1.4701839811538767e-27, 0.4516668951295441, 0.6857699816319955],\n",
       "       [3.968569702582087e-27, 9.962444582184566e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 9.11044371488503e-27, 9.11044371488503e-27,\n",
       "        6.147847834534874e-27, 0.4597598872088259, 0.9088219520803753],\n",
       "       [3.1608739798373903e-27, 6.329950807609744e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        36.36363636363637, 6.4408835702086356e-27, 6.736086788439773e-28,\n",
       "        5.5290036702969484e-27, 0.22538025509194093, 0.7737477950132668],\n",
       "       [2.1887551794988954e-26, 8.216782864115798e-52,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 7.124099959769309e-26, 7.124099959769309e-26,\n",
       "        1.3440475722971063e-26, 0.24200142766114316, 0.5306060596611897],\n",
       "       [4.620682810340631e-27, 1.8871235681484024e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        18.181818181818183, 6.899131176379505e-27, 4.506313330175338e-27,\n",
       "        1.0472904486518844e-26, 0.49644004174195605, 0.9890653628244663],\n",
       "       [7.776795884767196e-27, 1.6813944519677897e-53,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        27.272727272727273, 1.1882970352241473e-26,\n",
       "        1.1060955495857439e-26, 1.8444607874511782e-26,\n",
       "        0.5304376410725621, 1.0039292789171448],\n",
       "       [3.534621228119496e-26, 2.6537415159609053e-51,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 1.2450527981544619e-25,\n",
       "        1.2450527981544619e-25, 1.0127808725845707e-26,\n",
       "        0.16152249653775566, 0.3292984742541172],\n",
       "       [2.0451863677758237e-26, 1.442079695549349e-52,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        27.272727272727273, 3.100459869580588e-26,\n",
       "        2.3076741768621546e-26, 5.850138115818317e-26,\n",
       "        0.5150306714339592, 1.0591979745872586],\n",
       "       [1.5210946585832465e-26, 2.0179186010107156e-53,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 2.0901373643953255e-26,\n",
       "        2.0901373643953255e-26, 3.0960693966571904e-26,\n",
       "        0.5295482727249435, 0.997609706189929],\n",
       "       [3.839302644569363e-27, 5.68059025316718e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        36.36363636363637, 7.564753394809158e-27, 3.628257947144035e-27,\n",
       "        4.1641992363242575e-27, 0.4917861174189285, 0.7190910298723397],\n",
       "       [4.599915746362958e-27, 1.5266811723881014e-53,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 1.0514084840052895e-26,\n",
       "        1.0514084840052895e-26, 7.448290311597867e-27,\n",
       "        0.4613459561541677, 0.8531538462866002],\n",
       "       [1.470520973566575e-26, 1.9355535781181083e-52,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 3.096632489661405e-26, 3.096632489661405e-26,\n",
       "        2.77597601179631e-26, 0.487297915974982, 0.6704820704540734],\n",
       "       [4.5475644694219416e-27, 1.5172453937851434e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        18.181818181818183, 5.816078881969818e-27,\n",
       "        5.2322650802884206e-27, 1.0407700664671754e-26,\n",
       "        0.5170803864034542, 1.0273136375978473],\n",
       "       [1.69138055570511e-27, 1.146860025464763e-55,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        18.181818181818183, 2.134275404518814e-27,\n",
       "        1.6970003000338864e-27, 3.316816591639189e-27, 0.500460933706714,\n",
       "        0.9648991279339495],\n",
       "       [9.717961060012959e-27, 6.839135258243456e-53,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        18.181818181818183, 2.2035681997090422e-26,\n",
       "        1.0095746091395919e-27, 3.439248337850574e-26,\n",
       "        0.1367914178221657, 0.9898077525386225],\n",
       "       [7.269919303542499e-27, 3.0360317900942564e-53,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 1.4319695485659833e-26,\n",
       "        1.4319695485659833e-26, 1.4265413982160247e-26,\n",
       "        0.5032682517088659, 0.900650626353592],\n",
       "       [8.35247864689981e-27, 2.3641417738555894e-53,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 1.472431082127329e-26, 1.472431082127329e-26,\n",
       "        1.4094188051444714e-26, 0.5209608397699583, 0.827511775499642],\n",
       "       [8.519533527651599e-27, 3.9240710253180767e-53,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        18.181818181818183, 1.933262052465985e-26,\n",
       "        5.7519016407733295e-27, 2.3741306176007835e-26,\n",
       "        0.43322823107784225, 0.8456417726982213],\n",
       "       [3.38337750501942e-27, 8.972032204511682e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        27.272727272727273, 8.226638773663622e-27,\n",
       "        2.2288116859178226e-29, 1.1002366624446079e-26,\n",
       "        0.01522716168405693, 0.9053268306513529],\n",
       "       [1.1776637776738948e-27, 1.381348476547522e-54,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        27.272727272727273, 3.2121713466126975e-27,\n",
       "        4.471219336061784e-28, 3.7718975725976276e-27,\n",
       "        0.3224513366945727, 0.7418181561155165],\n",
       "       [3.6281457467980805e-26, 5.671962032800363e-52,\n",
       "        array([nan, nan, nan, nan]), array([nan, nan, nan, nan]),\n",
       "        9.090909090909092, 7.467482033949043e-26, 7.467482033949043e-26,\n",
       "        5.1304015735212423e-26, 0.49325520256958, 0.8284887612157172]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_psd_1st_click[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ca2813d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_1st_click = np.delete(features_psd_1st_click, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e512f518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 102, 8)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features_psd_1st_click.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86375795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3f3c7725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "0\n",
      "PreProcessed_AD001_Preprocessed_FirstClick.mat\n",
      "0\n",
      "31\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "1\n",
      "PreProcessed_AD002_Preprocessed_FirstClick.mat\n",
      "0\n",
      "92\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "2\n",
      "PreProcessed_AD003_Preprocessed_FirstClick.mat\n",
      "0\n",
      "113\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "3\n",
      "PreProcessed_AD004_Preprocessed_FirstClick.mat\n",
      "0\n",
      "145\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "4\n",
      "PreProcessed_AD006_Preprocessed_FirstClick.mat\n",
      "0\n",
      "180\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "5\n",
      "PreProcessed_AD008_Preprocessed_FirstClick.mat\n",
      "0\n",
      "208\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "6\n",
      "PreProcessed_AD010_Preprocessed_FirstClick.mat\n",
      "0\n",
      "243\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "7\n",
      "PreProcessed_AD011_Preprocessed_FirstClick.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2372655356.py:133: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  aar = peak_to_peak_amplitude / mean_absolute_amplitude\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "271\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "8\n",
      "PreProcessed_AD012_Preprocessed_FirstClick.mat\n",
      "0\n",
      "315\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "9\n",
      "PreProcessed_AD013_Preprocessed_FirstClick.mat\n",
      "0\n",
      "355\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "10\n",
      "PreProcessed_AD014_Preprocessed_FirstClick.mat\n",
      "0\n",
      "389\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "11\n",
      "PreProcessed_AD015_Preprocessed_FirstClick.mat\n",
      "0\n",
      "415\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "12\n",
      "PreProcessed_AD016_Preprocessed_FirstClick.mat\n",
      "0\n",
      "441\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "13\n",
      "PreProcessed_AD017_Preprocessed_FirstClick.mat\n",
      "0\n",
      "467\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "14\n",
      "PreProcessed_AD018_Preprocessed_FirstClick.mat\n",
      "0\n",
      "500\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "15\n",
      "PreProcessed_AD020_Preprocessed_FirstClick.mat\n",
      "0\n",
      "525\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_FirstClick.mat\n",
      "0\n",
      "570\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "17\n",
      "PreProcessed_AD027_Preprocessed_FirstClick.mat\n",
      "0\n",
      "604\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "18\n",
      "PreProcessed_AD028_Preprocessed_FirstClick.mat\n",
      "0\n",
      "643\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "19\n",
      "PreProcessed_AD030_Preprocessed_FirstClick.mat\n",
      "0\n",
      "687\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "20\n",
      "PreProcessed_AD031_Preprocessed_FirstClick.mat\n",
      "0\n",
      "731\n",
      "(204, 401)\n",
      "(102, 151)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "features_erp_1st_click = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_1st_click):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_1st_click[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_1st_click[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end) \n",
    "    print(new[0].shape)\n",
    "    trial_data=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "    \n",
    "# Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "\n",
    "\n",
    "# Iterate through channels\n",
    "    for ch_idx in range(len(info['ch_names'])):\n",
    "        # Extract ERP data for the current channel\n",
    "        channel_data = average_data_healthy[ch_idx,:]\n",
    "        \n",
    "    \n",
    "    # Compute peak amplitude and latency\n",
    "        peak_amplitude = np.max(channel_data)\n",
    "         # Compute peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "        # Compute mean absolute amplitude\n",
    "        mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "        mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "            # Compute RMS amplitude\n",
    "        rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "        rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "        # Compute standard deviation\n",
    "        std_dev = np.std(channel_data)\n",
    "        std_devs.append(std_dev)\n",
    "\n",
    "        # Compute skewness\n",
    "        skewness = skew(channel_data)\n",
    "        skewness_values.append(skewness)\n",
    "\n",
    "        # Compute kurtosis\n",
    "        kurtosis_val = kurtosis(channel_data)\n",
    "        kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "        # Compute zero crossing rate\n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        latency = times[np.argmax(channel_data)]\n",
    "    \n",
    "    # Calculate area under the curve (AUC)\n",
    "        auc_value = simps(channel_data, times)\n",
    "    \n",
    "    # Calculate slope (e.g., by fitting a linear regression model)\n",
    "    # You can use numpy's polyfit function for this purpose\n",
    "        slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "        slope = slope_coefficients[0]\n",
    "        \n",
    "        \n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        # Compute AAR\n",
    "        aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "        aar_values.append(aar)\n",
    "\n",
    "        # Compute ZORK\n",
    "        zork = zero_crossings / kurtosis_val\n",
    "        zork_values.append(zork)\n",
    "        \n",
    "        peak_to_peak_amplitudes1=np.array(peak_to_peak_amplitudes)\n",
    "        channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                            peak_to_peak_amplitude, \n",
    "                                 mean_absolute_amplitude, \n",
    "                                 rms_amplitude, \n",
    "                                 std_dev, \n",
    "                                 skewness, \n",
    "                                 kurtosis_val, \n",
    "                                 zero_crossings,aar,zork]\n",
    "\n",
    "        features.append(channel_features)\n",
    "\n",
    "    features_erp_1st_click.append(features)\n",
    "    \n",
    "features_erp_1st_click= np.array(features_erp_1st_click,dtype=object)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b7667c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 102, 13)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_1st_click.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9a369b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 102, 4)\n"
     ]
    }
   ],
   "source": [
    "usable_features_psd_1st_click=new_features_psd_1st_click[:,:,4:8]\n",
    "print(usable_features_psd_1st_click.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fe64cc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.041111185775686e-27, 6.239964682520042e-27,\n",
       "        1.7111846900765843e-26, ..., 9.740854444274231e-27,\n",
       "        6.3800760307827554e-27, 1.2918100424254332e-26],\n",
       "       [9.11044371488503e-27, 2.269848625687112e-27,\n",
       "        8.210823025883911e-27, ..., 4.488234091460084e-27,\n",
       "        1.1418761274185479e-26, 2.49043583368132e-26],\n",
       "       [6.736086788439773e-28, 7.462940579989942e-27,\n",
       "        9.377770883953483e-27, ..., 1.6042284468814117e-27,\n",
       "        1.0719617586164818e-26, 1.821983285649863e-26],\n",
       "       ...,\n",
       "       [2.2288116859178226e-29, 1.953406488830792e-26,\n",
       "        2.287316352276944e-26, ..., 7.359311163856847e-28,\n",
       "        3.822292110191051e-27, 2.3879855470057934e-26],\n",
       "       [4.471219336061784e-28, 2.8747261149198225e-27,\n",
       "        4.799534111375093e-27, ..., 2.942390714531733e-26,\n",
       "        3.5772858595493154e-27, 1.9265900810460057e-26],\n",
       "       [7.467482033949043e-26, 7.968911502403246e-28,\n",
       "        2.852160984978075e-29, ..., 1.1195437004335977e-26,\n",
       "        9.392452886689355e-27, 3.925664808393357e-27]], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_features_psd_1st_click[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1b5212f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4701839811538767e-27, 4.369017007612471e-27,\n",
       "        2.449822005515292e-27, ..., 4.5298971093539155e-27,\n",
       "        1.0143628235339576e-26, 2.7936497032578626e-27],\n",
       "       [6.147847834534874e-27, 2.0067348251479095e-27,\n",
       "        7.474586189539147e-27, ..., 3.640633055067016e-27,\n",
       "        5.661733286786515e-27, 8.602617243028475e-27],\n",
       "       [5.5290036702969484e-27, 2.3925866532634712e-27,\n",
       "        2.7147562452415622e-27, ..., 1.177066123376675e-26,\n",
       "        9.373627643328695e-27, 5.758972438455935e-27],\n",
       "       ...,\n",
       "       [1.1002366624446079e-26, 8.126401961765343e-27,\n",
       "        1.0894746977223656e-26, ..., 3.837809698471992e-27,\n",
       "        1.4214862403002566e-27, 1.0693760647598263e-26],\n",
       "       [3.7718975725976276e-27, 3.8378305000397875e-27,\n",
       "        3.8672439559099544e-27, ..., 3.5012138267869496e-27,\n",
       "        3.840026831498091e-27, 9.948433158032124e-27],\n",
       "       [5.1304015735212423e-26, 1.7425880090517157e-26,\n",
       "        8.972081718208556e-27, ..., 1.0295108688142931e-26,\n",
       "        1.233837469925236e-26, 7.424114124713682e-27]], dtype=object)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_features_psd_1st_click[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24669fdd",
   "metadata": {},
   "source": [
    "## uncomment 2 cells below to save extracted features in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3633be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('features_psd_1st_click.pkl', 'wb') as file: \n",
    "#     pickle.dump(usable_features_psd_1st_click, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "498576a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('features_erp_1st_click.pkl', 'wb') as file: \n",
    "#     pickle.dump(features_erp_1st_click, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204147c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_psd_1st_click.pkl','rb') as file:\n",
    "    usable_features_psd_1st_click=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_erp_1st_click.pkl','rb') as file:\n",
    "    features_erp_1st_click=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38238e",
   "metadata": {},
   "source": [
    "## feature selection and anomaly detection pipeline on 1st click data: what channel subset and what corresponding features of selected channel subset work best for rseo data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "feb03e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "# from sklearn.svm import OneClassSVM\n",
    "# import numpy as np    \n",
    "# def evaluate_performance(X_train, X_test, y_test):\n",
    "#     size = X_train.shape[0]\n",
    "#     y_train = np.ones(size)\n",
    "#     one_class_svm = OneClassSVM()\n",
    "#     loo = LeaveOneOut()\n",
    "#     fold_accuracies = []\n",
    "#     predictions = []\n",
    "#     for train_index, test_index in loo.split(X_train):\n",
    "#         X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "#         y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "#         one_class_svm.fit(X_train_fold)\n",
    "#         predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "#         predictions.append(predictions_fold)\n",
    "#             # Print classification report for the fold\n",
    "#         print(f\"Classification Report - Fold:\")\n",
    "#         print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "#         print(\"\\n\")\n",
    "        \n",
    "\n",
    "#         fold_accuracy = accuracy_score(y_test_fold, predictions_fold)\n",
    "#         fold_accuracies.append(fold_accuracy)\n",
    "#        # Evaluate the model on the entire test set\n",
    "   \n",
    "#     # Combine predictions from all folds\n",
    "#     predictions = np.concatenate(predictions)\n",
    "#     print('concatenated predictions are')\n",
    "#     print(predictions)\n",
    "\n",
    "#     # Evaluate the model on the entire test set\n",
    "#     test_predictions = one_class_svm.predict(X_test)\n",
    "#     # Calculate accuracy for the entire test set\n",
    "#     test_set_accuracy = accuracy_score(y_test, test_predictions)\n",
    "#     print(\"Final Classification Report:\")\n",
    "#     print(classification_report(y_test, test_predictions, zero_division=0))  \n",
    " \n",
    "\n",
    "#     # Calculate overall confusion matrix\n",
    "#     cm = confusion_matrix(y_test, test_predictions)\n",
    "#     tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "#     # Calculate overall sensitivity, specificity, and macro F1 score\n",
    "#     overall_sensitivity = tp / (tp + fn)\n",
    "#     overall_specificity = tn / (tn + fp)\n",
    "#     overall_macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "    \n",
    "#     # Print overall metrics\n",
    "#     print(\"Overall Metrics:\")\n",
    "#     print(f\"Overall Sensitivity: {overall_sensitivity}\")\n",
    "#     print(f\"Overall Specificity: {overall_specificity}\")\n",
    "#     print(f\"Overall Macro F1 Score: {overall_macro_f1}\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "#     return test_set_accuracy, fold_accuracies\n",
    "# ----------------------\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "def evaluate_performance(X_train, X_test, y_test):\n",
    "    size=X_train.shape[0]\n",
    "    y_train=np.ones(size)\n",
    "    one_class_svm= OneClassSVM()\n",
    "    kf = KFold(n_splits=5, shuffle=True,random_state=42)  # Define k-fold cross-validation with 5 folds\n",
    "    fold_accuracies = []\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        print(train_index, test_index)\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "        print('y test fold')\n",
    "        print(y_test_fold) \n",
    "        one_class_svm.fit(X_train_fold)\n",
    "        # Predict anomalies\n",
    "        predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "        print('pred for fold')\n",
    "        print(predictions_fold)\n",
    "        y_pred_fold = np.zeros_like(y_test_fold)\n",
    "        y_pred_fold[predictions_fold == 1] = 0\n",
    "        y_pred_fold[predictions_fold == -1] = 1\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"Classification Report - Fold {fold + 1}:\")\n",
    "        print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Calculate accuracy for this fold\n",
    "        fold_accuracy = accuracy_score(y_test_fold, predictions_fold)\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "    # Evaluate the model on the entire test set\n",
    "    predictions = one_class_svm.predict(X_test)\n",
    "    print(\"results\")\n",
    "    print('true')\n",
    "    print(y_test)\n",
    "       \n",
    "    print(predictions)\n",
    "\n",
    "    # Convert predictions to match labels (0 for healthy, 1 for anomaly)\n",
    "    y_pred = np.zeros_like(y_test)\n",
    "    y_pred[predictions == 1] = 0\n",
    "    y_pred[predictions == -1] = 1\n",
    "    # Calculate accuracy for the entire test set\n",
    "    test_set_accuracy = accuracy_score(y_test, predictions)\n",
    "    # Print final classification report\n",
    "    print(\"Final Classification Report:\")\n",
    "    print(classification_report(y_test, predictions, zero_division=0))  \n",
    " \n",
    "    # Calculate overall confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate overall sensitivity, specificity, and macro F1 score\n",
    "    overall_sensitivity = tp / (tp + fn)\n",
    "    overall_specificity = tn / (tn + fp)\n",
    "    overall_macro_f1 = f1_score(y_test, predictions, average='macro')\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print(\"Overall Metrics:\")\n",
    "    print(f\"Overall Sensitivity: {overall_sensitivity}\")\n",
    "    print(f\"Overall Specificity: {overall_specificity}\")\n",
    "    print(f\"Overall Macro F1 Score: {overall_macro_f1}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return test_set_accuracy, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the pipeline with SelectKBest and OneClassSVM\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM())\n",
    "])\n",
    "iterative_channel_selection_accuracies_1st_click_svm=[]\n",
    "channel_subsets_best_perform_1st_click=[]\n",
    "# Initialize variables\n",
    "selected_channels_1st_click = []\n",
    "\n",
    "#selected_channels_rseo=['MEG0142+0143','MEG1512+1513','MEG1542+1543','MEG1812+1813','MEG1622+1623','MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243']\n",
    "\n",
    "#selected_channels_rseo=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643']\n",
    "##IMPORTANT-TO-DO----------------------> initially CHANGE selected_channels_indices to contain 10 channels in left cerebral hemisphere and 10 channels in right cerebral hemisphere that lie in the auditory processing region of the brain;\n",
    "##-------------------------------------> to do this change initialize ch_aud = ch_aud=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1812+1813', 'MEG1622+1623' ,'MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG2412+2413','MEG2222+2223','MEG2422+2423','MEG2442+2443','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643','MEG1332+1333','MEG1342+1343']\n",
    "##-------------------------------------> before running this cell\n",
    "##-------------------------------------> without doing so, all 102 channels will be considered for feature selection\n",
    "\n",
    "selected_channel_indices = [list_1.index(i) for i in ch_aud]\n",
    "selected_channels_1st_click= ['MEG0142+0143' ,'MEG1512+1513', 'MEG1542+1543','MEG1812+1813' , 'MEG1622+1623' , 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "\n",
    "# both left and right channel: [ 'MEG2412+2413' , 'MEG2222+2223','MEG2422+2423','MEG2442+2443' , 'MEG1432+1433' , 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343' , 'MEG0142+0143' , 'MEG1512+1513', 'MEG1542+1543' ,'MEG1812+1813', 'MEG1622+1623' , 'MEG1522+1523' , 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "print(\"------------------\")\n",
    "print(len(selected_channels_1st_click))\n",
    "\n",
    "best_performance = 0.0  # Initialize with the worst performance\n",
    "\n",
    "# Iterate through channels\n",
    "for channel in list_1:\n",
    "    \n",
    "    if channel in selected_channels_1st_click:\n",
    "        continue  # Skip if channel already selected\n",
    "\n",
    "    # Add the current channel to selected channels\n",
    "    selected_channels_1st_click.append(channel)\n",
    "    print('selected channels')\n",
    "    print(selected_channels_1st_click)\n",
    "    selected_channel_indices = [list_1.index(i) for i in selected_channels_1st_click]\n",
    "    print('selected channels indices')\n",
    "    print(selected_channel_indices)\n",
    "\n",
    "    \n",
    "    \n",
    "    train_healthy_psd_1st_click = usable_features_psd_1st_click[:11,selected_channel_indices,:]\n",
    "    test_psd_1st_click = usable_features_psd_1st_click[11:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_1st_click = features_erp_1st_click[:11,selected_channel_indices,:]\n",
    "    test_erp_1st_click = features_erp_1st_click[11:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_1st_click.shape)\n",
    "    print(train_healthy_erp_1st_click.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_1st_click = np.concatenate((train_healthy_psd_1st_click.reshape(11, -1),\n",
    "                                                        train_healthy_erp_1st_click.reshape(11, -1)), axis=1)\n",
    "    print(train_healthy_features_1st_click.shape)\n",
    "    \n",
    "    \n",
    "  #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_1st_click.reshape(11, -1)\n",
    "\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "\n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_1st_click= np.delete(train_healthy_features_1st_click, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_1st_click.shape)\n",
    "\n",
    "\n",
    "    test_features_1st_click = np.concatenate((test_psd_1st_click.reshape(10, -1),\n",
    "                                               test_erp_1st_click.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_1st_click=np.delete(test_features_1st_click, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_1st_click=usable_train_healthy_features_1st_click.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_1st_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_1st_click).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_1st_click\n",
    "    usable_nonnan_train_healthy_features_1st_click = usable_train_healthy_features_1st_click[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_1st_click after removing NaN columns:\", usable_nonnan_train_healthy_features_1st_click.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_1st_click  = usable_test_features_1st_click[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_1st_click.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_1st_click\n",
    "    _, y = usable_nonnan_train_healthy_features_1st_click.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_1st_click, [1] * usable_nonnan_train_healthy_features_1st_click.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_1st_click = selector.fit_transform(usable_nonnan_train_healthy_features_1st_click, [1] * usable_nonnan_train_healthy_features_1st_click.shape[0])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    print(len(selector.get_support()))\n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_1st_click[:, selector.get_support()]\n",
    "#     X_test = usable_nonnan_test_features_1st_click\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy, fold_accuracies = evaluate_performance(train_healthy_selected_features_1st_click, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies)\n",
    "\n",
    "     # Evaluate performance\n",
    "    performance = test_set_accuracy\n",
    "    if test_set_accuracy == 0.9:\n",
    "        print(\"test set accuracy 1\")\n",
    "        print('selected channels are')\n",
    "        print(selected_channel_indices)\n",
    "        channel_subsets_best_perform_1st_click.append(selected_channel_indices)\n",
    "        \n",
    "    iterative_channel_selection_accuracies_1st_click_svm.append(performance)\n",
    "\n",
    "    # Check if performance improved\n",
    "    if performance > best_performance or performance == best_performance:\n",
    "        best_performance = performance\n",
    "    else:\n",
    "        # Remove the last added channel if no improvement\n",
    "        selected_channels_1st_click.pop()\n",
    "\n",
    "# Print selected channels and best performance\n",
    "print(\"Selected Channels:\", selected_channels_1st_click)\n",
    "print(\"Best Performance:\")\n",
    "print(best_performance)\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0e563794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813', 'MEG1622+1623', 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243', 'MEG0112+0113', 'MEG0122+0123', 'MEG0132+0133', 'MEG0222+0223', 'MEG0322+0323', 'MEG0332+0333', 'MEG0412+0413', 'MEG0442+0443', 'MEG0622+0623', 'MEG0632+0633', 'MEG0642+0643', 'MEG0722+0723', 'MEG0732+0733', 'MEG0922+0923', 'MEG0932+0933', 'MEG1142+1143', 'MEG1232+1233', 'MEG2122+2123', 'MEG2312+2313', 'MEG2322+2323', 'MEG2422+2423', 'MEG2432+2433']\n",
      "[0.6, 0.6, 0.6, 0.4, 0.6, 0.5, 0.6, 0.6, 0.4, 0.6, 0.3, 0.3, 0.6, 0.4, 0.4, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.5, 0.7, 0.7, 0.6, 0.5, 0.4, 0.5, 0.7, 0.7, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.7, 0.6, 0.5, 0.8, 0.6, 0.6, 0.5, 0.7, 0.2, 0.5, 0.6, 0.6, 0.6, 0.5, 0.4, 0.6, 0.6, 0.6, 0.7, 0.6, 0.3, 0.4, 0.6, 0.7, 0.5, 0.4, 0.5, 0.7, 0.7, 0.6, 0.4, 0.8, 0.4, 0.6, 0.7, 0.7, 0.7, 0.6, 0.8, 0.9, 0.7, 0.5, 0.7, 0.9, 1.0, 0.7, 0.1, 0.4, 0.6, 0.7, 0.6, 0.7, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(selected_channels_1st_click)\n",
    "print(iterative_channel_selection_accuracies_1st_click_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8831919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print(best_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c194bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels selected by the above method: applying iterative channel selection on 1st click data, starting with 20 auditory left and right channels with feature selection are:\n",
    "\n",
    "#Selected Channels: ['MEG2412+2413', 'MEG2222+2223', 'MEG2422+2423', 'MEG2442+2443', 'MEG1432+1433', 'MEG2612+2613', \n",
    "#'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343', 'MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813',\n",
    "#'MEG1622+1623', 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243', 'MEG0112+0113', 'MEG0432+0433',\n",
    "#'MEG0442+0443', 'MEG0632+0633', 'MEG0922+0923', 'MEG0932+0933', 'MEG1142+1143', 'MEG1232+1233', 'MEG1442+1443', 'MEG1822+1823',\n",
    "#'MEG2342+2343', 'MEG2542+2543']\n",
    "#Best Performance:\n",
    "#0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7aa93f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # result using above selected channel with FS in bottom part titled: 1st click using results of ICS B\n",
    "# Final Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         -1.0       0.83      1.00      0.91         5\n",
    "#          1.0       1.00      0.80      0.89         5\n",
    "\n",
    "#     accuracy                           0.90        10\n",
    "#    macro avg       0.92      0.90      0.90        10\n",
    "# weighted avg       0.92      0.90      0.90        10\n",
    "\n",
    "# Overall Metrics:\n",
    "# Overall Sensitivity: 0.8\n",
    "# Overall Specificity: 1.0\n",
    "# Overall Macro F1 Score: 0.898989898989899\n",
    "\n",
    "\n",
    "# Test Set Accuracy: 0.9\n",
    "# Fold Accuracies: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d3f6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result using above selected channels with FS in bottom part titled: 1st click using results of ICS B\n",
    "#channels further selected: \n",
    "#144\n",
    "#182\n",
    "#234\n",
    "#254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4f59e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels selected by the above method: applying iterative channel selection on 1st click data, starting with 10 auditory left channels with feature selection are:\n",
    "\n",
    "#Selected Channels: ['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813', 'MEG1622+1623', 'MEG1522+1523', \n",
    "#'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243', 'MEG0112+0113', 'MEG0122+0123', 'MEG0132+0133', 'MEG0442+0443',\n",
    "#'MEG0632+0633', 'MEG0922+0923', 'MEG0932+0933', 'MEG0942+0943', 'MEG1222+1223', 'MEG1322+1323', 'MEG1442+1443', 'MEG1722+1723']\n",
    "#Best Performance:\n",
    "#0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a2034ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # result using above selected channel with FS in bottom part titled: 1st click using results of ICS B\n",
    "# Final Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         -1.0       0.83      1.00      0.91         5\n",
    "#          1.0       1.00      0.80      0.89         5\n",
    "\n",
    "#     accuracy                           0.90        10\n",
    "#    macro avg       0.92      0.90      0.90        10\n",
    "# weighted avg       0.92      0.90      0.90        10\n",
    "\n",
    "# Overall Metrics:\n",
    "# Overall Sensitivity: 0.8\n",
    "# Overall Specificity: 1.0\n",
    "# Overall Macro F1 Score: 0.898989898989899\n",
    "\n",
    "\n",
    "# Test Set Accuracy: 0.9\n",
    "# Fold Accuracies: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "511b2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result using above selected channels with FS in bottom part titled: 1st click using results of ICS B\n",
    "#channels further selected: \n",
    "#MEG1442+1443\n",
    "#MEG1722+1723"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e238637",
   "metadata": {},
   "source": [
    "# Anomaly detection: 2nd click data \n",
    "trained on 11 healthy subjects; tested on (5 healthy + 5 MCI) using k-fold cross validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a2952e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected .mat files:\n",
      "PreProcessed_AD001_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD002_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD003_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD004_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD006_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD008_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD010_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD011_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD012_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD013_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD014_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD015_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD016_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD017_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD018_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD020_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD026_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD027_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD028_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD030_Preprocessed_SecondClick.mat\n",
      "PreProcessed_AD031_Preprocessed_SecondClick.mat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# Construct the path to the target folder\n",
    "folder_path = \"D:\\internship_ulster_university\\preprocessed_filtered_2nd_click\"\n",
    "\n",
    "# Move into the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# Select all files ending with \".mat\"\n",
    "matfiles_2nd_click = glob.glob(\"*.mat\")\n",
    "\n",
    "# Print the list of selected files\n",
    "print(\"Selected .mat files:\")\n",
    "for file in matfiles_2nd_click:\n",
    "    print(file)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3e26f37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProcessed_AD001_Preprocessed_SecondClick.mat\n",
      "34\n",
      "PreProcessed_AD002_Preprocessed_SecondClick.mat\n",
      "59\n",
      "PreProcessed_AD003_Preprocessed_SecondClick.mat\n",
      "26\n",
      "PreProcessed_AD004_Preprocessed_SecondClick.mat\n",
      "34\n",
      "PreProcessed_AD006_Preprocessed_SecondClick.mat\n",
      "35\n",
      "PreProcessed_AD008_Preprocessed_SecondClick.mat\n",
      "31\n",
      "PreProcessed_AD010_Preprocessed_SecondClick.mat\n",
      "30\n",
      "PreProcessed_AD011_Preprocessed_SecondClick.mat\n",
      "21\n",
      "PreProcessed_AD012_Preprocessed_SecondClick.mat\n",
      "40\n",
      "PreProcessed_AD013_Preprocessed_SecondClick.mat\n",
      "40\n",
      "PreProcessed_AD014_Preprocessed_SecondClick.mat\n",
      "34\n",
      "PreProcessed_AD015_Preprocessed_SecondClick.mat\n",
      "30\n",
      "PreProcessed_AD016_Preprocessed_SecondClick.mat\n",
      "31\n",
      "PreProcessed_AD017_Preprocessed_SecondClick.mat\n",
      "28\n",
      "PreProcessed_AD018_Preprocessed_SecondClick.mat\n",
      "36\n",
      "PreProcessed_AD020_Preprocessed_SecondClick.mat\n",
      "39\n",
      "PreProcessed_AD026_Preprocessed_SecondClick.mat\n",
      "40\n",
      "PreProcessed_AD027_Preprocessed_SecondClick.mat\n",
      "33\n",
      "PreProcessed_AD028_Preprocessed_SecondClick.mat\n",
      "32\n",
      "PreProcessed_AD030_Preprocessed_SecondClick.mat\n",
      "43\n",
      "PreProcessed_AD031_Preprocessed_SecondClick.mat\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "num_trials=0\n",
    "trial_counts_2nd_click=[]\n",
    "for subject in range(len(matfiles_2nd_click)):\n",
    "    subject_data = []\n",
    "    name=matfiles_2nd_click[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_2nd_click[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "#     print(new)\n",
    "    trial_counts_2nd_click.append(len(new))\n",
    "    print(len(new))\n",
    "    num_trials+=len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d7a4f6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34,\n",
       " 59,\n",
       " 26,\n",
       " 34,\n",
       " 35,\n",
       " 31,\n",
       " 30,\n",
       " 21,\n",
       " 40,\n",
       " 40,\n",
       " 34,\n",
       " 30,\n",
       " 31,\n",
       " 28,\n",
       " 36,\n",
       " 39,\n",
       " 40,\n",
       " 33,\n",
       " 32,\n",
       " 43,\n",
       " 46]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_counts_2nd_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ed1d436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "0\n",
      "PreProcessed_AD001_Preprocessed_SecondClick.mat\n",
      "0\n",
      "34\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "1\n",
      "subject idx is\n",
      "1\n",
      "PreProcessed_AD002_Preprocessed_SecondClick.mat\n",
      "0\n",
      "93\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "2\n",
      "subject idx is\n",
      "2\n",
      "PreProcessed_AD003_Preprocessed_SecondClick.mat\n",
      "0\n",
      "119\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "3\n",
      "subject idx is\n",
      "3\n",
      "PreProcessed_AD004_Preprocessed_SecondClick.mat\n",
      "0\n",
      "153\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "4\n",
      "subject idx is\n",
      "4\n",
      "PreProcessed_AD006_Preprocessed_SecondClick.mat\n",
      "0\n",
      "188\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "5\n",
      "subject idx is\n",
      "5\n",
      "PreProcessed_AD008_Preprocessed_SecondClick.mat\n",
      "0\n",
      "219\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "6\n",
      "subject idx is\n",
      "6\n",
      "PreProcessed_AD010_Preprocessed_SecondClick.mat\n",
      "0\n",
      "249\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "7\n",
      "subject idx is\n",
      "7\n",
      "PreProcessed_AD011_Preprocessed_SecondClick.mat\n",
      "0\n",
      "270\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "8\n",
      "subject idx is\n",
      "8\n",
      "PreProcessed_AD012_Preprocessed_SecondClick.mat\n",
      "0\n",
      "310\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "9\n",
      "subject idx is\n",
      "9\n",
      "PreProcessed_AD013_Preprocessed_SecondClick.mat\n",
      "0\n",
      "350\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "10\n",
      "subject idx is\n",
      "10\n",
      "PreProcessed_AD014_Preprocessed_SecondClick.mat\n",
      "0\n",
      "384\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "11\n",
      "subject idx is\n",
      "11\n",
      "PreProcessed_AD015_Preprocessed_SecondClick.mat\n",
      "0\n",
      "414\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "12\n",
      "subject idx is\n",
      "12\n",
      "PreProcessed_AD016_Preprocessed_SecondClick.mat\n",
      "0\n",
      "445\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "13\n",
      "subject idx is\n",
      "13\n",
      "PreProcessed_AD017_Preprocessed_SecondClick.mat\n",
      "0\n",
      "473\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "14\n",
      "subject idx is\n",
      "14\n",
      "PreProcessed_AD018_Preprocessed_SecondClick.mat\n",
      "0\n",
      "509\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "15\n",
      "subject idx is\n",
      "15\n",
      "PreProcessed_AD020_Preprocessed_SecondClick.mat\n",
      "0\n",
      "548\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "16\n",
      "subject idx is\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_SecondClick.mat\n",
      "0\n",
      "588\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "17\n",
      "subject idx is\n",
      "17\n",
      "PreProcessed_AD027_Preprocessed_SecondClick.mat\n",
      "0\n",
      "621\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "18\n",
      "subject idx is\n",
      "18\n",
      "PreProcessed_AD028_Preprocessed_SecondClick.mat\n",
      "0\n",
      "653\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "19\n",
      "subject idx is\n",
      "19\n",
      "PreProcessed_AD030_Preprocessed_SecondClick.mat\n",
      "0\n",
      "696\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "20\n",
      "subject idx is\n",
      "20\n",
      "PreProcessed_AD031_Preprocessed_SecondClick.mat\n",
      "0\n",
      "742\n",
      "(102, 151)\n",
      "Creating RawArray with float64 data, n_channels=102, n_times=151\n",
      "    Range : 0 ... 150 =      0.000 ...     0.150 secs\n",
      "Ready.\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list_mean_2nd_click = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_2nd_click):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_2nd_click[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_2nd_click[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end)\n",
    "    trial_data=[]\n",
    "    \n",
    "\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "   # Create RawArray object for the current trial\n",
    "    raw = mne.io.RawArray(average_data_healthy, info)\n",
    "\n",
    "    # Append the Raw object to the list\n",
    "    raw_list_mean_2nd_click.append(raw)\n",
    "    print(len(raw_list_mean_2nd_click))\n",
    "# #Concatenate Raw objects if needed\n",
    "# raw_combined_mean_mci_ts = mne.concatenate_raws(raw_list_mean_mci_ts)\n",
    "\n",
    "# print(len(raw_combined_mean_mci_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e9215c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>,\n",
       " <RawArray | 102 x 151 (0.1 s), ~221 kB, data loaded>]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_list_mean_2nd_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "36336d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2441752013.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2441752013.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "  alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2441752013.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2441752013.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2441752013.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2441752013.py:8: UserWarning: Zero value in spectrum for channel MEG2542+2543\n",
      "  psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n",
      "Effective window size : 0.110 (s)\n",
      "(102, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\2441752013.py:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  features_psd_2nd_click = np.array(features_psd_2nd_click)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "features_psd_2nd_click = []\n",
    "for raw in raw_list_mean_2nd_click:\n",
    "    # Compute PSD\n",
    "    psd_spectrum_healthy = raw.compute_psd(method='welch', fmin=4, fmax=40, tmin=None, tmax=None,n_fft=110 )\n",
    "    #psd_spectrum_healthy = raw.compute_psd(method='multitaper', fmin=0, fmax=40, tmin=None, tmax=None)\n",
    "    print(psd_spectrum_healthy.shape)\n",
    "    \n",
    "    \n",
    "    features=[]\n",
    "    for idx, ch_name in enumerate(list_1):\n",
    "        psd_data = psd_spectrum_healthy[idx]  # PSD data for the current channel\n",
    "\n",
    "    # Statistical Features\n",
    "        mean_power = np.mean(psd_data)\n",
    "        variance_power = np.var(psd_data)\n",
    "    \n",
    "        skewness_power = stats.skew(psd_data)\n",
    "        kurtosis_power = stats.kurtosis(psd_data)\n",
    "        freqs = psd_spectrum_healthy.freqs  # Frequency values\n",
    "        max_power_freq = freqs[np.argmax(psd_data)]\n",
    "        max_power = np.max(psd_data)\n",
    "        band_power_alpha = np.sum(psd_data[:,(freqs >= 8) & (freqs <= 13)])  # Alpha band\n",
    "        band_power_beta = np.sum(psd_data[:,(freqs >= 13) & (freqs <= 30)])  # Beta band\n",
    "        \n",
    "                    # Compute entropy for alpha band\n",
    "        alpha_prob = psd_data[:,(freqs >= alpha_band[0]) & (freqs <= alpha_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_alpha = -np.sum(alpha_prob * np.log2(alpha_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        # Compute entropy for beta band\n",
    "        beta_prob = psd_data[:,(freqs >= beta_band[0]) & (freqs <= beta_band[1])] / np.sum(psd_data)\n",
    "        spectral_entropy_beta = -np.sum(beta_prob * np.log2(beta_prob + 1e-12))  # Add a small value to avoid log(0)\n",
    "\n",
    "        \n",
    " \n",
    "        # Append features for the current channel\n",
    "        channel_features = [mean_power, variance_power, skewness_power, kurtosis_power,\n",
    "                            max_power_freq, max_power, band_power_alpha, band_power_beta,\n",
    "                            spectral_entropy_alpha, spectral_entropy_beta]\n",
    "        \n",
    "       \n",
    "        features.append(channel_features)\n",
    "\n",
    "# Convert features to numpy array\n",
    "    \n",
    "    features_psd_2nd_click.append(features)\n",
    "    \n",
    "features_psd_2nd_click = np.array(features_psd_2nd_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2ad7537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 102, 10)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_psd_2nd_click.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bc9d28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 2nd and 3rd columns in the third dimension\n",
    "new_features_psd_2nd_click = np.delete(features_psd_2nd_click, [2, 3], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "40650e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 102, 8)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features_psd_2nd_click.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b0d7f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject idx is\n",
      "0\n",
      "PreProcessed_AD001_Preprocessed_SecondClick.mat\n",
      "0\n",
      "34\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "1\n",
      "PreProcessed_AD002_Preprocessed_SecondClick.mat\n",
      "0\n",
      "93\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "2\n",
      "PreProcessed_AD003_Preprocessed_SecondClick.mat\n",
      "0\n",
      "119\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "3\n",
      "PreProcessed_AD004_Preprocessed_SecondClick.mat\n",
      "0\n",
      "153\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "4\n",
      "PreProcessed_AD006_Preprocessed_SecondClick.mat\n",
      "0\n",
      "188\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "5\n",
      "PreProcessed_AD008_Preprocessed_SecondClick.mat\n",
      "0\n",
      "219\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "6\n",
      "PreProcessed_AD010_Preprocessed_SecondClick.mat\n",
      "0\n",
      "249\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "7\n",
      "PreProcessed_AD011_Preprocessed_SecondClick.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stuti\\AppData\\Local\\Temp\\ipykernel_20568\\1705030678.py:133: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  aar = peak_to_peak_amplitude / mean_absolute_amplitude\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "270\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "8\n",
      "PreProcessed_AD012_Preprocessed_SecondClick.mat\n",
      "0\n",
      "310\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "9\n",
      "PreProcessed_AD013_Preprocessed_SecondClick.mat\n",
      "0\n",
      "350\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "10\n",
      "PreProcessed_AD014_Preprocessed_SecondClick.mat\n",
      "0\n",
      "384\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "11\n",
      "PreProcessed_AD015_Preprocessed_SecondClick.mat\n",
      "0\n",
      "414\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "12\n",
      "PreProcessed_AD016_Preprocessed_SecondClick.mat\n",
      "0\n",
      "445\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "13\n",
      "PreProcessed_AD017_Preprocessed_SecondClick.mat\n",
      "0\n",
      "473\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "14\n",
      "PreProcessed_AD018_Preprocessed_SecondClick.mat\n",
      "0\n",
      "509\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "15\n",
      "PreProcessed_AD020_Preprocessed_SecondClick.mat\n",
      "0\n",
      "548\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "16\n",
      "PreProcessed_AD026_Preprocessed_SecondClick.mat\n",
      "0\n",
      "588\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "17\n",
      "PreProcessed_AD027_Preprocessed_SecondClick.mat\n",
      "0\n",
      "621\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "18\n",
      "PreProcessed_AD028_Preprocessed_SecondClick.mat\n",
      "0\n",
      "653\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "19\n",
      "PreProcessed_AD030_Preprocessed_SecondClick.mat\n",
      "0\n",
      "696\n",
      "(204, 401)\n",
      "(102, 151)\n",
      "subject idx is\n",
      "20\n",
      "PreProcessed_AD031_Preprocessed_SecondClick.mat\n",
      "0\n",
      "742\n",
      "(204, 401)\n",
      "(102, 151)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "# Import necessary libraries\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import diff\n",
    "\n",
    "# Initialize an empty list to store subject data\n",
    "subject_data_list = []\n",
    "\n",
    "# Number of subjects\n",
    "#num_subjects = 5\n",
    "# Create an empty list to store evoked objects for each subject\n",
    "evoked_list = []\n",
    "features_erp_2nd_click = []\n",
    "\n",
    "# Size of each array\n",
    "array_size = (102, 201)\n",
    "num_trials=0\n",
    "start=0\n",
    "raw_list = []\n",
    "# Simulating data for demonstration purposes\n",
    "# Replace this part with your actual data retrieval process in the nested loops\n",
    "for subject, trials in enumerate(trial_counts_2nd_click):\n",
    "    subject_data = []\n",
    "    print('subject idx is')\n",
    "    print(subject)\n",
    "    \n",
    "    name=matfiles_2nd_click[subject]\n",
    "    print(name)\n",
    "    dat = mat73.loadmat(matfiles_2nd_click[subject])\n",
    "    data = pd.DataFrame.from_dict(dat)\n",
    "    if name.endswith('EC.mat') == True or name.endswith('EO.mat')==True:\n",
    "        print('in if')\n",
    "        new=data.iloc[6,0]\n",
    "    else:\n",
    "        new=data.iloc[7,0]\n",
    "    \n",
    "    num_trials+=len(new)\n",
    "\n",
    "    print(start)\n",
    "    end=num_trials\n",
    "    print(end) \n",
    "    print(new[0].shape)\n",
    "    trial_data=[]\n",
    "# Loop through subjects\n",
    "    for trial in range(trials):\n",
    "        #print(new[0].shape[1])\n",
    "        if new[0].shape[1] == 10001:\n",
    "            trial_data.append(new[trial][:102,:9901])\n",
    "            times = grand_average_rsec_healthy.times\n",
    "            \n",
    "        else:\n",
    "            trial_data.append(new[trial][:102,200:351])\n",
    "            times = grand_average_healthy.times\n",
    "            \n",
    "    # Compute the average across trials for the current subject\n",
    "    average_data_healthy = np.mean(trial_data, axis=0)\n",
    "    print(average_data_healthy.shape)\n",
    "    \n",
    "# Create empty lists to store features\n",
    "    peak_amplitudes = []\n",
    "    latencies = []\n",
    "    auc_values = []\n",
    "    slopes = []\n",
    "    features_erp_1st_click_healthy=[]\n",
    "    features=[]\n",
    "    from scipy.integrate import simps\n",
    "    \n",
    "\n",
    "    # Initialize empty lists to store features\n",
    "    peak_to_peak_amplitudes = []\n",
    "    mean_absolute_amplitudes = []\n",
    "    rms_amplitudes = []\n",
    "    std_devs = []\n",
    "    skewness_values = []\n",
    "    kurtosis_values = []\n",
    "    zero_crossing_rates = []\n",
    "    aar_values=[]\n",
    "    zork_values=[]\n",
    "\n",
    "\n",
    "# Iterate through channels\n",
    "    for ch_idx in range(len(info['ch_names'])):\n",
    "        # Extract ERP data for the current channel\n",
    "        channel_data = average_data_healthy[ch_idx,:]\n",
    "        \n",
    "    \n",
    "    # Compute peak amplitude and latency\n",
    "        peak_amplitude = np.max(channel_data)\n",
    "         # Compute peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = np.max(channel_data) - np.min(channel_data)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "        # Compute mean absolute amplitude\n",
    "        mean_absolute_amplitude = np.mean(np.abs(channel_data))\n",
    "        mean_absolute_amplitudes.append(mean_absolute_amplitude)\n",
    "            # Compute RMS amplitude\n",
    "        rms_amplitude = np.sqrt(np.mean(channel_data**2))\n",
    "        rms_amplitudes.append(rms_amplitude)\n",
    "\n",
    "        # Compute standard deviation\n",
    "        std_dev = np.std(channel_data)\n",
    "        std_devs.append(std_dev)\n",
    "\n",
    "        # Compute skewness\n",
    "        skewness = skew(channel_data)\n",
    "        skewness_values.append(skewness)\n",
    "\n",
    "        # Compute kurtosis\n",
    "        kurtosis_val = kurtosis(channel_data)\n",
    "        kurtosis_values.append(kurtosis_val)\n",
    "\n",
    "        # Compute zero crossing rate\n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        latency = times[np.argmax(channel_data)]\n",
    "    \n",
    "    # Calculate area under the curve (AUC)\n",
    "        auc_value = simps(channel_data, times)\n",
    "    \n",
    "    # Calculate slope (e.g., by fitting a linear regression model)\n",
    "    # You can use numpy's polyfit function for this purpose\n",
    "        slope_coefficients = np.polyfit(times, channel_data, 1)\n",
    "        slope = slope_coefficients[0]\n",
    "        \n",
    "        \n",
    "        zero_crossings = len(np.where(np.diff(np.sign(channel_data)))[0])\n",
    "        zero_crossing_rates.append(zero_crossings)\n",
    "\n",
    "        # Compute AAR\n",
    "        aar = peak_to_peak_amplitude / mean_absolute_amplitude\n",
    "        aar_values.append(aar)\n",
    "\n",
    "        # Compute ZORK\n",
    "        zork = zero_crossings / kurtosis_val\n",
    "        zork_values.append(zork)\n",
    "        \n",
    "        peak_to_peak_amplitudes1=np.array(peak_to_peak_amplitudes)\n",
    "        channel_features = [peak_amplitude,latency,auc_value,slope,\n",
    "                            peak_to_peak_amplitude, \n",
    "                                 mean_absolute_amplitude, \n",
    "                                 rms_amplitude, \n",
    "                                 std_dev, \n",
    "                                 skewness, \n",
    "                                 kurtosis_val, \n",
    "                                 zero_crossings,aar,zork]\n",
    "\n",
    "        features.append(channel_features)\n",
    "\n",
    "    features_erp_2nd_click.append(features)\n",
    "    \n",
    "features_erp_2nd_click= np.array(features_erp_2nd_click,dtype=object)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "eecd21ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 102, 13)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_erp_2nd_click.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bf12a395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 102, 4)\n"
     ]
    }
   ],
   "source": [
    "usable_features_psd_2nd_click=new_features_psd_2nd_click[:,:,4:8]\n",
    "print(usable_features_psd_2nd_click.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f8e98eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_erp_2nd_click.pkl', 'wb') as file: \n",
    "    pickle.dump(features_erp_2nd_click, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f07d0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_psd_2nd_click.pkl', 'wb') as file: \n",
    "    pickle.dump(usable_features_psd_2nd_click, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c3ff9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 8.304642973618545e-31, 3.822977291131625e-30, ...,\n",
       "       2.348604537076593e-25, 2.607202809181623e-25,\n",
       "       3.209288444642926e-25], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(usable_features_psd_2nd_click[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5db28b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.021408914392201e-27, 4.7745619371200155e-27,\n",
       "        5.596671880010679e-27, ..., 5.890676671032748e-28,\n",
       "        2.8266491412984935e-27, 3.386048192391236e-27],\n",
       "       [2.0973230572536142e-27, 2.0496264350627344e-27,\n",
       "        5.504045655589728e-27, ..., 8.0192767612982655e-28,\n",
       "        2.303257851488859e-27, 5.413724283531348e-27],\n",
       "       [1.5563777915178015e-27, 8.061899444390701e-28,\n",
       "        1.5624380169696928e-27, ..., 5.227776937601324e-27,\n",
       "        1.5048529968776172e-26, 1.8511838629457842e-27],\n",
       "       ...,\n",
       "       [1.0022073425123307e-26, 4.0663173422229e-27,\n",
       "        2.485049205384635e-26, ..., 6.579583964299551e-27,\n",
       "        2.677434018934316e-27, 1.057384530133792e-26],\n",
       "       [1.1109984046560919e-26, 4.07134935508545e-27,\n",
       "        5.470335118751755e-27, ..., 1.3303334082358816e-26,\n",
       "        1.4232255755547273e-26, 2.3632685629498575e-27],\n",
       "       [8.279604748991951e-27, 4.433970469109649e-26,\n",
       "        2.004811412591878e-26, ..., 3.099013828408162e-26,\n",
       "        2.320592469356405e-26, 1.6240549949430863e-26]], dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_features_psd_2nd_click[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4f59e",
   "metadata": {},
   "source": [
    "## feature selection and anomaly detection pipeline for 2nd click data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4003d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np    \n",
    "def evaluate_performance(X_train, X_test, y_test):\n",
    "    size = X_train.shape[0]\n",
    "    y_train = np.ones(size)\n",
    "    one_class_svm = OneClassSVM()\n",
    "    loo = LeaveOneOut()\n",
    "    fold_accuracies = []\n",
    "    predictions = []\n",
    "    for train_index, test_index in loo.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        one_class_svm.fit(X_train_fold)\n",
    "        predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "        predictions.append(predictions_fold)\n",
    "            # Print classification report for the fold\n",
    "        print(f\"Classification Report - Fold:\")\n",
    "        print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "        fold_accuracy = accuracy_score(y_test_fold, predictions_fold)\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "       # Evaluate the model on the entire test set\n",
    "   \n",
    "    # Combine predictions from all folds\n",
    "    predictions = np.concatenate(predictions)\n",
    "    print('concatenated predictions are')\n",
    "    print(predictions)\n",
    "\n",
    "    # Evaluate the model on the entire test set\n",
    "    test_predictions = one_class_svm.predict(X_test)\n",
    "    # Calculate accuracy for the entire test set\n",
    "    test_set_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    print(\"Final Classification Report:\")\n",
    "    print(classification_report(y_test, test_predictions, zero_division=0))  \n",
    " \n",
    "\n",
    "    # Calculate overall confusion matrix\n",
    "    cm = confusion_matrix(y_test, test_predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate overall sensitivity, specificity, and macro F1 score\n",
    "    overall_sensitivity = tp / (tp + fn)\n",
    "    overall_specificity = tn / (tn + fp)\n",
    "    overall_macro_f1 = f1_score(y_test, test_predictions, average='macro')\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print(\"Overall Metrics:\")\n",
    "    print(f\"Overall Sensitivity: {overall_sensitivity}\")\n",
    "    print(f\"Overall Specificity: {overall_specificity}\")\n",
    "    print(f\"Overall Macro F1 Score: {overall_macro_f1}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return test_set_accuracy, fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab757c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the pipeline with SelectKBest and OneClassSVM\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM())\n",
    "])\n",
    "iterative_channel_selection_accuracies_2nd_click_svm=[]\n",
    "channel_subsets_best_perform_2nd_click=[]\n",
    "# Initialize variables\n",
    "selected_channels_2nd_click = []\n",
    "selected_channels_2nd_click= ['MEG0142+0143' ,'MEG1512+1513', 'MEG1542+1543','MEG1812+1813' , 'MEG1622+1623' , 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "\n",
    "#only left side channels: ['MEG0142+0143' ,'MEG1512+1513', 'MEG1542+1543','MEG1812+1813' , 'MEG1622+1623' , 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "##IMPORTANT-TO-DO----------------------> initially CHANGE selected_channels_2nd_click to contain 10 channels in left cerebral hemisphere and 10 channels in right cerebral hemisphere that lie in the auditory processing region of the brain;\n",
    "##-------------------------------------> to do this change initialize ch_aud = ch_aud=['MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1812+1813', 'MEG1622+1623' ,'MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG2412+2413','MEG2222+2223','MEG2422+2423','MEG2442+2443','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643','MEG1332+1333','MEG1342+1343']\n",
    "##-------------------------------------> before running this cell\n",
    "##-------------------------------------> without doing so, all 102 channels will be considered for feature selection\n",
    "\n",
    "# both left and right channel: [ 'MEG2412+2413' , 'MEG2222+2223','MEG2422+2423','MEG2442+2443' , 'MEG1432+1433' , 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343' , 'MEG0142+0143' , 'MEG1512+1513', 'MEG1542+1543' ,'MEG1812+1813', 'MEG1622+1623' , 'MEG1522+1523' , 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "\n",
    "print(\"------------------\")\n",
    "print(len(selected_channels_2nd_click))\n",
    "\n",
    "best_performance = 0.0  # Initialize with the worst performance\n",
    "\n",
    "# Iterate through channels\n",
    "for channel in list_1:\n",
    "    \n",
    "    if channel in selected_channels_2nd_click:\n",
    "        continue  # Skip if channel already selected\n",
    "\n",
    "    # Add the current channel to selected channels\n",
    "    selected_channels_2nd_click.append(channel)\n",
    "    print('selected channels')\n",
    "    print(selected_channels_2nd_click)\n",
    "    selected_channel_indices = [list_1.index(i) for i in selected_channels_2nd_click]\n",
    "    print('selected channels indices')\n",
    "    print(selected_channel_indices)\n",
    "\n",
    "    \n",
    "    \n",
    "    train_healthy_psd_2nd_click = usable_features_psd_2nd_click[:11,selected_channel_indices,:]\n",
    "    test_psd_2nd_click = usable_features_psd_2nd_click[11:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_2nd_click = features_erp_2nd_click[:11,selected_channel_indices,:]\n",
    "    test_erp_2nd_click = features_erp_2nd_click[11:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_2nd_click.shape)\n",
    "    print(train_healthy_erp_2nd_click.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_2nd_click = np.concatenate((train_healthy_psd_2nd_click.reshape(11, -1),\n",
    "                                                        train_healthy_erp_2nd_click.reshape(11, -1)), axis=1)\n",
    "    print(train_healthy_features_2nd_click.shape)\n",
    "    \n",
    "    \n",
    "  #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_2nd_click.reshape(11, -1)\n",
    "\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "\n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_2nd_click= np.delete(train_healthy_features_2nd_click, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_2nd_click.shape)\n",
    "\n",
    "\n",
    "    test_features_2nd_click = np.concatenate((test_psd_2nd_click.reshape(10, -1),\n",
    "                                               test_erp_2nd_click.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_2nd_click=np.delete(test_features_2nd_click, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_2nd_click=usable_train_healthy_features_2nd_click.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_2nd_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_2nd_click).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_2nd_click\n",
    "    usable_nonnan_train_healthy_features_2nd_click = usable_train_healthy_features_2nd_click[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_2nd_click.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_2nd_click  = usable_test_features_2nd_click[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_2nd_click.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_2nd_click\n",
    "    _, y = usable_nonnan_train_healthy_features_2nd_click.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_2nd_click, [1] * usable_nonnan_train_healthy_features_2nd_click.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_2nd_click = selector.fit_transform(usable_nonnan_train_healthy_features_2nd_click, [1] * usable_nonnan_train_healthy_features_2nd_click.shape[0])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    print(len(selector.get_support()))\n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_2nd_click[:, selector.get_support()]\n",
    "\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy, fold_accuracies = evaluate_performance(train_healthy_selected_features_2nd_click, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies)\n",
    "\n",
    "     # Evaluate performance\n",
    "    performance = test_set_accuracy\n",
    "    if test_set_accuracy == 0.9:\n",
    "        print(\"test set accuracy 1\")\n",
    "        print('selected channels are')\n",
    "        print(selected_channel_indices)\n",
    "        channel_subsets_best_perform_2nd_click.append(selected_channel_indices)\n",
    "        \n",
    "    iterative_channel_selection_accuracies_2nd_click_svm.append(performance)\n",
    "\n",
    "    # Check if performance improved\n",
    "    if performance > best_performance or performance == best_performance:\n",
    "        best_performance = performance\n",
    "    else:\n",
    "        # Remove the last added channel if no improvement\n",
    "        selected_channels_2nd_click.pop()\n",
    "\n",
    "# Print selected channels and best performance\n",
    "print(\"Selected Channels:\", selected_channels_2nd_click)\n",
    "print(\"Best Performance:\")\n",
    "print(best_performance)\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a04d5dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813', 'MEG1622+1623', 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243', 'MEG0112+0113', 'MEG0122+0123', 'MEG0332+0333', 'MEG0342+0343', 'MEG0412+0413', 'MEG0432+0433', 'MEG0512+0513', 'MEG0722+0723', 'MEG0922+0923', 'MEG1242+1243', 'MEG1742+1743', 'MEG2542+2543']\n",
      "[0.4, 0.6, 0.2, 0.3, 0.4, 0.5, 0.5, 0.6, 0.6, 0.6, 0.5, 0.6, 0.5, 0.7, 0.6, 0.4, 0.4, 0.5, 0.6, 0.3, 0.5, 0.5, 0.8, 0.6, 0.5, 0.6, 0.3, 0.6, 0.8, 0.5, 0.4, 0.5, 0.5, 0.2, 0.6, 0.5, 0.6, 0.5, 0.6, 0.3, 0.6, 0.5, 0.8, 0.7, 0.6, 0.3, 0.5, 0.6, 0.5, 0.6, 0.5, 0.7, 0.6, 0.5, 0.6, 0.5, 0.9, 0.6, 0.8, 0.6, 0.6, 0.4, 0.7, 0.6, 0.8, 0.7, 0.4, 0.6, 0.7, 0.8, 0.6, 0.5, 0.5, 0.6, 0.6, 0.6, 0.7, 0.4, 0.5, 0.5, 0.7, 0.5, 0.5, 0.7, 0.7, 0.6, 0.6, 0.9, 0.4, 0.8, 0.7, 0.7]\n"
     ]
    }
   ],
   "source": [
    "print(selected_channels_2nd_click)\n",
    "print(iterative_channel_selection_accuracies_2nd_click_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d4c6c40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(best_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e093db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels selected by the above method: applying iterative channel selection on 1st click data, starting with 20 auditory left and right channels with feature selection are:\n",
    "\n",
    "#Selected Channels: ['MEG2412+2413', 'MEG2222+2223', 'MEG2422+2423', 'MEG2442+2443', 'MEG1432+1433', 'MEG2612+2613',\n",
    "# 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343', 'MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813',\n",
    "# 'MEG1622+1623', 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243', 'MEG0112+0113', 'MEG0122+0123',\n",
    "# 'MEG0332+0333', 'MEG0342+0343', 'MEG0412+0413', 'MEG0432+0433', 'MEG0512+0513', 'MEG0722+0723', 'MEG0922+0923', 'MEG1242+1243', \n",
    "# 'MEG1742+1743', 'MEG2542+2543']\n",
    "#Best Performance:\n",
    "#0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result using above selected channels with FS in bottom part titled: 2nd click using results of ICS B\n",
    "# Final Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         -1.0       0.83      1.00      0.91         5\n",
    "#          1.0       1.00      0.80      0.89         5\n",
    "\n",
    "#     accuracy                           0.90        10\n",
    "#    macro avg       0.92      0.90      0.90        10\n",
    "# weighted avg       0.92      0.90      0.90        10\n",
    "\n",
    "# Overall Metrics:\n",
    "# Overall Sensitivity: 0.8\n",
    "# Overall Specificity: 1.0\n",
    "# Overall Macro F1 Score: 0.898989898989899\n",
    "\n",
    "\n",
    "# Test Set Accuracy: 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c45130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result using above selected channels with FS in bottom part titled: 2nd click using results of ICS B\n",
    "#channels further selected: \n",
    "# MEG1242+1243\n",
    "# MEG1742+1743\n",
    "# MEG2542+2543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels selected by the above method: applying iterative channel selection on 1st click data, starting with 20 auditory left and right channels with feature selection are:\n",
    "\n",
    "#Selected Channels: ['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1812+1813', 'MEG1622+1623', 'MEG1522+1523',\n",
    "#'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243', 'MEG0112+0113', 'MEG0122+0123', 'MEG0332+0333', 'MEG0342+0343',\n",
    "#'MEG0412+0413', 'MEG0432+0433', 'MEG0512+0513', 'MEG0722+0723', 'MEG0922+0923', 'MEG1242+1243', 'MEG1742+1743', 'MEG2542+2543']\n",
    "#Best Performance:\n",
    "#0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bdd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # result using above selected channels with FS in bottom part titled: 2nd click using results of ICS B\n",
    "# Final Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#         -1.0       0.83      1.00      0.91         5\n",
    "#          1.0       1.00      0.80      0.89         5\n",
    "\n",
    "#     accuracy                           0.90        10\n",
    "#    macro avg       0.92      0.90      0.90        10\n",
    "# weighted avg       0.92      0.90      0.90        10\n",
    "\n",
    "# Overall Metrics:\n",
    "# Overall Sensitivity: 0.8\n",
    "# Overall Specificity: 1.0\n",
    "# Overall Macro F1 Score: 0.898989898989899\n",
    "\n",
    "\n",
    "# Test Set Accuracy: 0.9\n",
    "# Fold Accuracies: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fef764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result using above selected channels with FS in bottom part titled: 2nd click using results of ICS B\n",
    "#channels further selected: \n",
    "# MEG1242+1243\n",
    "# MEG1742+1743\n",
    "# MEG2542+2543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb80c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d842aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea27d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca791426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fdb9a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"PSD Features for Resting State data type:\", usable_features_psd_2nd_click.dtype)\n",
    "# print(\"ERP Features for Resting State data type:\", features_erp_2nd_click.dtype)\n",
    "# print(\"PSD Features for Task State data type:\", usable_features_psd_2nd_click.dtype)\n",
    "# print(\"ERP Features for Task State data type:\", features_erp_2nd_click.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "46f5f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert variables to NumPy arrays\n",
    "# usable_features_psd_2nd_click = np.array(usable_features_psd_2nd_click)\n",
    "# features_erp_2nd_click = np.array(features_erp_2nd_click)\n",
    "# usable_features_psd_2nd_click = np.array(usable_features_psd_2nd_click)\n",
    "# features_erp_2nd_click = np.array(features_erp_2nd_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "13ba2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(usable_features_psd_2nd_click.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f7b5f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"PSD Features for Resting State data type:\", usable_features_psd_2nd_click.dtype)\n",
    "# print(\"ERP Features for Resting State data type:\", features_erp_2nd_click.dtype)\n",
    "# print(\"PSD Features for Task State data type:\", usable_features_psd_2nd_click.dtype)\n",
    "# print(\"ERP Features for Task State data type:\", features_erp_2nd_click.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e2fab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_psd_2nd_click.pkl','rb') as file:\n",
    "    usable_features_psd_2nd_click=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "40973eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('features_erp_2nd_click.pkl','rb') as file:\n",
    "    features_erp_2nd_click=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886eaefc",
   "metadata": {},
   "source": [
    "# channel selection strategies for resting state data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9edd4a",
   "metadata": {},
   "source": [
    "## iterative channel elimination for resting state data: removing a channel if it decrease mean classification accuracy of eyes closed and eyes open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f904ab98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the pipeline with SelectKBest and OneClassSVM\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM())\n",
    "])\n",
    "iterative_channel_selection_accuracies_rs=[]\n",
    "j=0\n",
    "# Initialize variables\n",
    "selected_channels = []\n",
    "selected_channels=list_1.copy()\n",
    "\n",
    "best_performance = 0.0  \n",
    "# Initialize with the worst performance\n",
    "\n",
    "selected_features33=[]\n",
    "selected_features44=[]\n",
    "\n",
    "# Iterate through channels\n",
    "for abc in range(len(list_1)):\n",
    "    selected_features3=[]\n",
    "    selected_features4=[]\n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "#     if channel in selected_channels:\n",
    "#         continue  # Skip if channel already selected\n",
    "\n",
    "    # Add the current channel to selected channels\n",
    "    #selected_channels.append(channel)\n",
    "    #print('selected channels')\n",
    "    print(selected_channels)\n",
    "    selected_channel_indices = [list_1.index(i) for i in selected_channels]\n",
    "    print('selected channels indices')\n",
    "    print(selected_channel_indices)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "  \n",
    "    print('rseo performance now')\n",
    "    train_healthy_psd_rseo = usable_features_psd_rseo[:11,selected_channel_indices,:]\n",
    "    test_psd_rseo = usable_features_psd_rseo[11:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_rseo = features_erp_rseo[:11,selected_channel_indices,:]\n",
    "    test_erp_rseo = features_erp_rseo[11:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_rseo.shape)\n",
    "    print(train_healthy_erp_rseo.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_rseo = np.concatenate((train_healthy_psd_rseo.reshape(11, -1),\n",
    "                                                        train_healthy_erp_rseo.reshape(11, -1)), axis=1)\n",
    "    print(train_healthy_features_rseo.shape)\n",
    "    \n",
    "    chosen_indices3=[]\n",
    "    #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_rseo.reshape(11, -1)\n",
    "\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "    for i in range(reshaped_features.shape[1]):\n",
    "    #     print(i)\n",
    "        if i in constant_feature_indices:\n",
    "    #         print('true')\n",
    "            continue\n",
    "        else:\n",
    "            chosen_indices3.append(i)\n",
    "    print('remaining indices')\n",
    "    print(chosen_indices3)\n",
    "  \n",
    "\n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_rseo= np.delete(train_healthy_features_rseo, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_rseo.shape)\n",
    "\n",
    "\n",
    "    test_features_rseo = np.concatenate((test_psd_rseo.reshape(10, -1),\n",
    "                                               test_erp_rseo.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_rseo=np.delete(test_features_rseo, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_rseo=usable_train_healthy_features_rseo.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_2nd_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_rseo).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_2nd_click\n",
    "    usable_nonnan_train_healthy_features_rseo = usable_train_healthy_features_rseo[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_rseo.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_rseo  = usable_test_features_rseo[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rseo.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_2nd_click\n",
    "    _, y = usable_nonnan_train_healthy_features_rseo.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_rseo, [1] * usable_nonnan_train_healthy_features_rseo.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_rseo = selector.fit_transform(usable_nonnan_train_healthy_features_rseo, [1] * usable_nonnan_train_healthy_features_rseo.shape[0])\n",
    "\n",
    " \n",
    "    print(len(selector.get_support()))\n",
    "    print(selector.get_support())\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        # Check if x value is True\n",
    "        if val:\n",
    "            # Append the corresponding y value to selected_y\n",
    "            selected_features3.append(chosen_indices3[idx])\n",
    "    print('remaining feature indices selected after grid search ')\n",
    "    print(selected_features3)\n",
    "    \n",
    "    selected_features33.append(selected_features3)\n",
    "    print('iteration j')\n",
    "    print(j)\n",
    "    print('selected features 33')\n",
    "    print(selected_features33)\n",
    "    print(len(selected_features33))\n",
    " \n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_rseo[:, selector.get_support()]\n",
    "\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy_rseo, fold_accuracies_rseo = evaluate_performance(train_healthy_selected_features_rseo, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy_rseo)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies_rseo)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------\")\n",
    "    print('rsec performance now')\n",
    "    train_healthy_psd_rsec = usable_features_psd_rsec[:10,selected_channel_indices,:]\n",
    "    test_psd_rsec = usable_features_psd_rsec[10:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_rsec = features_erp_rsec[:10,selected_channel_indices,:]\n",
    "    test_erp_rsec = features_erp_rsec[10:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_rsec.shape)\n",
    "    print(train_healthy_erp_rsec.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_rsec = np.concatenate((train_healthy_psd_rsec.reshape(10, -1),\n",
    "                                                        train_healthy_erp_rsec.reshape(10, -1)), axis=1)\n",
    "    print(train_healthy_features_rsec.shape)\n",
    "    \n",
    "    chosen_indices4=[]\n",
    "   #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_rsec.reshape(10, -1)\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "    for i in range(reshaped_features.shape[1]):\n",
    "    #     print(i)\n",
    "        if i in constant_feature_indices:\n",
    "    #         print('true')\n",
    "            continue\n",
    "        else:\n",
    "            chosen_indices4.append(i)\n",
    "    print('remaining indices')\n",
    "    print(chosen_indices4)\n",
    "  \n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_rsec= np.delete(train_healthy_features_rsec, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_rsec.shape)\n",
    "\n",
    "\n",
    "    test_features_rsec = np.concatenate((test_psd_rsec.reshape(10, -1),\n",
    "                                               test_erp_rsec.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_rsec=np.delete(test_features_rsec, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_rsec=usable_train_healthy_features_rsec.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_2nd_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_rsec).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_2nd_click\n",
    "    usable_nonnan_train_healthy_features_rsec = usable_train_healthy_features_rsec[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_rsec.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_rsec  = usable_test_features_rsec[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rsec.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_2nd_click\n",
    "    _, y = usable_nonnan_train_healthy_features_rsec.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_rsec, [1] * usable_nonnan_train_healthy_features_rsec.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_rsec = selector.fit_transform(usable_nonnan_train_healthy_features_rsec, [1] * usable_nonnan_train_healthy_features_rsec.shape[0])\n",
    "\n",
    "    print(len(selector.get_support()))\n",
    "    print(selector.get_support())\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        # Check if x value is True\n",
    "        if val:\n",
    "            # Append the corresponding y value to selected_y\n",
    "            selected_features4.append(chosen_indices4[idx])\n",
    "    print('remaining feature indices selected after grid search ')\n",
    "    print(selected_features4)\n",
    "    \n",
    "    \n",
    "    selected_features44.append(selected_features4)\n",
    "    print('iteration j')\n",
    "    print(j)\n",
    "    j=j+1\n",
    " \n",
    "  \n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_rsec[:, selector.get_support()]\n",
    "\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy_rsec, fold_accuracies_rsec = evaluate_performance(train_healthy_selected_features_rsec, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy_rsec)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies_rsec)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    print('--------------------------------------------------------------------------------')\n",
    "\n",
    "    print('END OF 2 CLASSSIFICS')\n",
    "    print('rseo accuracy')\n",
    "    print(test_set_accuracy_rseo)\n",
    "    print('rsec accuracy')\n",
    "    print(test_set_accuracy_rsec)\n",
    "\n",
    "     # Evaluate performance\n",
    "#     accuracies= [test_set_accuracy_2nd_click,test_set_accuracy_1st_click,test_set_accuracy_rseo, test_set_accuracy_rsec]\n",
    "    accuracies= [test_set_accuracy_rseo, test_set_accuracy_rsec]\n",
    "    performance=sum(accuracies) / len(accuracies)\n",
    "    print('MEAN ACCURACY OF 4 CLASSIFS')\n",
    "    print(performance)\n",
    "    iterative_channel_selection_accuracies_rs.append(performance)\n",
    "    print('abc is')\n",
    "    print(abc)\n",
    "    if abc==0:\n",
    "        best_performance = performance\n",
    "        element = selected_channels.pop()  # pop from the copy list\n",
    "        print(\"Element popped in 1st iteration:\", element)   \n",
    "    else:\n",
    "        # Check if performance improved\n",
    "        if performance > best_performance or performance == best_performance:\n",
    "            best_performance = performance\n",
    "            print(\"sccccccccc\")\n",
    "            print(selected_channels)\n",
    "            element = selected_channels.pop()\n",
    "#             list_with_string = [element]\n",
    "#             selected_channels=list_with_string+selected_channels# pop from the copy list\n",
    "#             element = selected_channels.pop()\n",
    "            print(\"Element popped :\", element)  \n",
    "            print('length of selected channels now')\n",
    "            print(len(selected_channels))\n",
    "        else:\n",
    "            print(\"Using the element in the second iteration:\", element)\n",
    "            # Remove the last added channel if no improvement\n",
    "            list_with_string = [element]\n",
    "            selected_channels=list_with_string+selected_channels\n",
    "            element = selected_channels.pop()  # pop from the copy list\n",
    "            print(\"Element popped in 1st iteration:\", element)  \n",
    "            print('length of selected channels now')\n",
    "            print(len(selected_channels))\n",
    "\n",
    "# Print selected channels and best performance\n",
    "print(\"Selected Channels:\", selected_channels)\n",
    "print(\"Best Performance:\")\n",
    "print(best_performance)\n",
    "print('mean accuracies each time')\n",
    "print(iterative_channel_selection_accuracies_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b23126cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_with_string = [element]\n",
    "selected_channels=list_with_string+selected_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1a583784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEG0112+0113'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "2a9deb9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEG0112+0113',\n",
       " 'MEG0122+0123',\n",
       " 'MEG0132+0133',\n",
       " 'MEG0142+0143',\n",
       " 'MEG0212+0213',\n",
       " 'MEG0222+0223',\n",
       " 'MEG0232+0233',\n",
       " 'MEG0242+0243',\n",
       " 'MEG0312+0313',\n",
       " 'MEG0322+0323',\n",
       " 'MEG0332+0333',\n",
       " 'MEG0342+0343',\n",
       " 'MEG0412+0413',\n",
       " 'MEG0422+0423',\n",
       " 'MEG0432+0433',\n",
       " 'MEG0442+0443',\n",
       " 'MEG0512+0513',\n",
       " 'MEG0522+0523',\n",
       " 'MEG0532+0533',\n",
       " 'MEG0542+0543',\n",
       " 'MEG0612+0613',\n",
       " 'MEG0622+0623',\n",
       " 'MEG0632+0633',\n",
       " 'MEG0642+0643',\n",
       " 'MEG0712+0713',\n",
       " 'MEG0722+0723',\n",
       " 'MEG0732+0733',\n",
       " 'MEG0742+0743',\n",
       " 'MEG0812+0813',\n",
       " 'MEG0822+0823',\n",
       " 'MEG0912+0913',\n",
       " 'MEG0922+0923',\n",
       " 'MEG0932+0933',\n",
       " 'MEG0942+0943',\n",
       " 'MEG1012+1013',\n",
       " 'MEG1022+1023',\n",
       " 'MEG1032+1033',\n",
       " 'MEG1042+1043',\n",
       " 'MEG1112+1113',\n",
       " 'MEG1122+1123',\n",
       " 'MEG1132+1133',\n",
       " 'MEG1142+1143',\n",
       " 'MEG1212+1213',\n",
       " 'MEG1222+1223',\n",
       " 'MEG1232+1233',\n",
       " 'MEG1242+1243',\n",
       " 'MEG1312+1313',\n",
       " 'MEG1322+1323',\n",
       " 'MEG1332+1333',\n",
       " 'MEG1342+1343',\n",
       " 'MEG1412+1413',\n",
       " 'MEG1422+1423',\n",
       " 'MEG1432+1433',\n",
       " 'MEG1442+1443',\n",
       " 'MEG1512+1513',\n",
       " 'MEG1522+1523',\n",
       " 'MEG1542+1543',\n",
       " 'MEG1612+1613',\n",
       " 'MEG1622+1623',\n",
       " 'MEG1632+1633',\n",
       " 'MEG1642+1643',\n",
       " 'MEG1712+1713',\n",
       " 'MEG1722+1723',\n",
       " 'MEG1732+1733',\n",
       " 'MEG1742+1743',\n",
       " 'MEG1822+1823',\n",
       " 'MEG1842+1843',\n",
       " 'MEG1922+1923',\n",
       " 'MEG1932+1933',\n",
       " 'MEG1942+1943',\n",
       " 'MEG2012+2013',\n",
       " 'MEG2022+2023',\n",
       " 'MEG2032+2033',\n",
       " 'MEG2042+2043',\n",
       " 'MEG2112+2113',\n",
       " 'MEG2122+2123',\n",
       " 'MEG2132+2133',\n",
       " 'MEG2142+2143',\n",
       " 'MEG2212+2213',\n",
       " 'MEG2222+2223',\n",
       " 'MEG2232+2233',\n",
       " 'MEG2312+2313',\n",
       " 'MEG2332+2333',\n",
       " 'MEG2412+2413',\n",
       " 'MEG2422+2423',\n",
       " 'MEG2432+2433',\n",
       " 'MEG2442+2443',\n",
       " 'MEG2512+2513',\n",
       " 'MEG2522+2523',\n",
       " 'MEG2532+2533',\n",
       " 'MEG2542+2543',\n",
       " 'MEG2612+2613',\n",
       " 'MEG2622+2623',\n",
       " 'MEG2642+2643']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7ffa5145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460e4ad",
   "metadata": {},
   "source": [
    "## another variation of channel selection for resting state data: starting with 20 auditory channels, add a channel, if it increases avg. performance on both rseo and rsec, keep it, otherwise eliminate it\n",
    "(not used in final project methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the pipeline with SelectKBest and OneClassSVM\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM())\n",
    "])\n",
    "iterative_channel_selection_accuracies_rs=[]\n",
    "j=0\n",
    "# Initialize variables\n",
    "selected_channels = []\n",
    "selected_channels=['MEG2412+2413','MEG2222+2223','MEG2422+2423','MEG2442+2443','MEG1432+1433','MEG2612+2613','MEG2622+2623','MEG2642+2643','MEG1332+1333','MEG1342+1343','MEG0142+0143', 'MEG1512+1513','MEG1542+1543','MEG1812+1813', 'MEG1622+1623' ,'MEG1522+1523','MEG1612+1613','MEG1632+1633','MEG0232+0233','MEG0242+0243']\n",
    "\n",
    "\n",
    "best_performance = 0.0  \n",
    "# Initialize with the worst performance\n",
    "\n",
    "selected_features33=[]\n",
    "selected_features44=[]\n",
    "\n",
    "# Iterate through channels\n",
    "for channel in list_1:\n",
    "    selected_features3=[]\n",
    "    selected_features4=[]\n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    if channel in selected_channels:\n",
    "        continue  # Skip if channel already selected\n",
    "\n",
    "    # Add the current channel to selected channels\n",
    "    selected_channels.append(channel)\n",
    "    print('selected channels')\n",
    "    print(selected_channels)\n",
    "    selected_channel_indices = [list_1.index(i) for i in selected_channels]\n",
    "    print('selected channels indices')\n",
    "    print(selected_channel_indices)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "  \n",
    "    print('rseo performance now')\n",
    "    train_healthy_psd_rseo = usable_features_psd_rseo[:11,selected_channel_indices,:]\n",
    "    test_psd_rseo = usable_features_psd_rseo[11:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_rseo = features_erp_rseo[:11,selected_channel_indices,:]\n",
    "    test_erp_rseo = features_erp_rseo[11:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_rseo.shape)\n",
    "    print(train_healthy_erp_rseo.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_rseo = np.concatenate((train_healthy_psd_rseo.reshape(11, -1),\n",
    "                                                        train_healthy_erp_rseo.reshape(11, -1)), axis=1)\n",
    "    print(train_healthy_features_rseo.shape)\n",
    "    \n",
    "    chosen_indices3=[]\n",
    "    #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_rseo.reshape(11, -1)\n",
    "\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "    for i in range(reshaped_features.shape[1]):\n",
    "    #     print(i)\n",
    "        if i in constant_feature_indices:\n",
    "    #         print('true')\n",
    "            continue\n",
    "        else:\n",
    "            chosen_indices3.append(i)\n",
    "    print('remaining indices')\n",
    "    print(chosen_indices3)\n",
    "  \n",
    "\n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_rseo= np.delete(train_healthy_features_rseo, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_rseo.shape)\n",
    "\n",
    "\n",
    "    test_features_rseo = np.concatenate((test_psd_rseo.reshape(10, -1),\n",
    "                                               test_erp_rseo.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_rseo=np.delete(test_features_rseo, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_rseo=usable_train_healthy_features_rseo.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_2nd_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_rseo).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_2nd_click\n",
    "    usable_nonnan_train_healthy_features_rseo = usable_train_healthy_features_rseo[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_rseo.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_rseo  = usable_test_features_rseo[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rseo.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_2nd_click\n",
    "    _, y = usable_nonnan_train_healthy_features_rseo.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_rseo, [1] * usable_nonnan_train_healthy_features_rseo.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_rseo = selector.fit_transform(usable_nonnan_train_healthy_features_rseo, [1] * usable_nonnan_train_healthy_features_rseo.shape[0])\n",
    "\n",
    " \n",
    "    print(len(selector.get_support()))\n",
    "    print(selector.get_support())\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        # Check if x value is True\n",
    "        if val:\n",
    "            # Append the corresponding y value to selected_y\n",
    "            selected_features3.append(chosen_indices3[idx])\n",
    "    print('remaining feature indices selected after grid search ')\n",
    "    print(selected_features3)\n",
    "    \n",
    "    selected_features33.append(selected_features3)\n",
    "    print('iteration j')\n",
    "    print(j)\n",
    "    print('selected features 33')\n",
    "    print( selected_features33)\n",
    "    print(len(selected_features33))\n",
    " \n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_rseo[:, selector.get_support()]\n",
    "\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy_rseo, fold_accuracies_rseo = evaluate_performance(train_healthy_selected_features_rseo, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy_rseo)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies_rseo)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------\")\n",
    "    print('rsec performance now')\n",
    "    train_healthy_psd_rsec = usable_features_psd_rsec[:10,selected_channel_indices,:]\n",
    "    test_psd_rsec = usable_features_psd_rsec[10:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_rsec = features_erp_rsec[:10,selected_channel_indices,:]\n",
    "    test_erp_rsec = features_erp_rsec[10:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_rsec.shape)\n",
    "    print(train_healthy_erp_rsec.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_rsec = np.concatenate((train_healthy_psd_rsec.reshape(10, -1),\n",
    "                                                        train_healthy_erp_rsec.reshape(10, -1)), axis=1)\n",
    "    print(train_healthy_features_rsec.shape)\n",
    "    \n",
    "    chosen_indices4=[]\n",
    "   #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_rsec.reshape(10, -1)\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "    for i in range(reshaped_features.shape[1]):\n",
    "    #     print(i)\n",
    "        if i in constant_feature_indices:\n",
    "    #         print('true')\n",
    "            continue\n",
    "        else:\n",
    "            chosen_indices4.append(i)\n",
    "    print('remaining indices')\n",
    "    print(chosen_indices4)\n",
    "  \n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_rsec= np.delete(train_healthy_features_rsec, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_rsec.shape)\n",
    "\n",
    "\n",
    "    test_features_rsec = np.concatenate((test_psd_rsec.reshape(10, -1),\n",
    "                                               test_erp_rsec.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_rsec=np.delete(test_features_rsec, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_rsec=usable_train_healthy_features_rsec.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_2nd_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_rsec).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_2nd_click\n",
    "    usable_nonnan_train_healthy_features_rsec = usable_train_healthy_features_rsec[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_rsec.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_rsec  = usable_test_features_rsec[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rsec.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_2nd_click\n",
    "    _, y = usable_nonnan_train_healthy_features_rsec.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_rsec, [1] * usable_nonnan_train_healthy_features_rsec.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_rsec = selector.fit_transform(usable_nonnan_train_healthy_features_rsec, [1] * usable_nonnan_train_healthy_features_rsec.shape[0])\n",
    "\n",
    "    print(len(selector.get_support()))\n",
    "    print(selector.get_support())\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        # Check if x value is True\n",
    "        if val:\n",
    "            # Append the corresponding y value to selected_y\n",
    "            selected_features4.append(chosen_indices4[idx])\n",
    "    print('remaining feature indices selected after grid search ')\n",
    "    print(selected_features4)\n",
    "    \n",
    "    \n",
    "    selected_features44.append(selected_features4)\n",
    "    print('iteration j')\n",
    "    print(j)\n",
    "    j=j+1\n",
    " \n",
    "  \n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_rsec[:, selector.get_support()]\n",
    "\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy_rsec, fold_accuracies_rsec = evaluate_performance(train_healthy_selected_features_rsec, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy_rsec)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies_rsec)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    print('--------------------------------------------------------------------------------')\n",
    "\n",
    "    print('END OF 2 CLASSSIFICS')\n",
    "#     print('2nd click accuracy')\n",
    "#     print(test_set_accuracy_2nd_click)\n",
    "#     print('1st click accuracy')\n",
    "#     print(test_set_accuracy_1st_click)\n",
    "    print('rseo accuracy')\n",
    "    print(test_set_accuracy_rseo)\n",
    "    print('rsec accuracy')\n",
    "    print(test_set_accuracy_rsec)\n",
    "\n",
    "     # Evaluate performance\n",
    "#     accuracies= [test_set_accuracy_2nd_click,test_set_accuracy_1st_click,test_set_accuracy_rseo, test_set_accuracy_rsec]\n",
    "    accuracies= [test_set_accuracy_rseo, test_set_accuracy_rsec]\n",
    "    performance=sum(accuracies) / len(accuracies)\n",
    "    print('MEAN ACCURACY OF 2 CLASSIFS')\n",
    "    print(performance)\n",
    "    iterative_channel_selection_accuracies_rs.append(performance)\n",
    "\n",
    "    # Check if performance improved\n",
    "    if performance > best_performance or performance == best_performance:\n",
    "        best_performance = performance\n",
    "        print(\"sccccccccc\")\n",
    "        print(selected_channels)\n",
    "    else:\n",
    "        # Remove the last added channel if no improvement\n",
    "        selected_channels.pop()\n",
    "\n",
    "# Print selected channels and best performance\n",
    "print(\"Selected Channels:\", selected_channels)\n",
    "print(\"Best Performance:\")\n",
    "print(best_performance)\n",
    "print('mean accuracies each time')\n",
    "print(iterative_channel_selection_accuracies_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "11b75ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(95):\n",
    "#     if i == 46:\n",
    "#         print(selected_features33[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a2d26bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3, 54, 57, 52, 98, 99, 101, 0, 2, 43, 47]\n",
    "# ['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1432+1433', 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG0112+0113', 'MEG0132+0133', 'MEG1222+1223', 'MEG1322+1323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "806a1453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45, 0.6, 0.75, 0.7, 0.6, 0.55, 0.55, 0.6499999999999999, 0.6, 0.75, 0.6, 0.6, 0.6000000000000001, 0.7, 0.6, 0.6499999999999999, 0.6499999999999999, 0.8, 0.65, 0.55, 0.7, 0.6, 0.55, 0.8500000000000001, 0.8, 0.55, 0.5, 0.7, 0.8, 0.7, 0.6499999999999999, 0.6499999999999999, 0.7, 0.5, 0.6, 0.4, 0.55, 0.5, 0.6, 0.55, 0.75, 0.8, 0.5, 0.6499999999999999, 0.65, 0.75, 0.7, 0.6, 0.65, 0.8500000000000001, 0.8, 0.8, 0.6000000000000001, 0.7, 0.6499999999999999, 0.8, 0.75, 0.45, 0.65, 0.7, 0.75, 0.7, 0.7, 0.75, 0.35, 0.55, 0.75, 0.6, 0.9, 0.7, 0.65, 0.6000000000000001, 0.65, 0.65, 0.7, 0.7, 0.8, 0.8500000000000001, 0.65, 0.55, 0.55, 0.55]\n"
     ]
    }
   ],
   "source": [
    "print(iterative_channel_selection_accuracies_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2e8eb500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(best_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7d1eb73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1432+1433', 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG0112+0113', 'MEG0132+0133', 'MEG1222+1223', 'MEG1322+1323']\n"
     ]
    }
   ],
   "source": [
    "selected_channels_1=selected_channels[:-1]\n",
    "print(selected_channels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "58ad7bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MEG0142+0143', 'MEG1512+1513', 'MEG1542+1543', 'MEG1432+1433', 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG0112+0113', 'MEG0132+0133', 'MEG1222+1223', 'MEG1322+1323', 'MEG1522+1523']\n"
     ]
    }
   ],
   "source": [
    "selected_channels_2=selected_channels\n",
    "print(selected_channels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "05b1c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEG0142+0143\n",
      "MEG1512+1513\n",
      "MEG1542+1543\n",
      "MEG1432+1433\n",
      "MEG2612+2613\n",
      "MEG2622+2623\n",
      "MEG2642+2643\n",
      "MEG0112+0113\n",
      "MEG0132+0133\n",
      "MEG1222+1223\n",
      "MEG1322+1323\n"
     ]
    }
   ],
   "source": [
    "a=[3, 54, 57, 52, 98, 99, 101, 0, 2, 43, 47]\n",
    "for i in a:\n",
    "    print(list_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "d8d32d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 0.9\n",
      "Index of maximum value: 46\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_value=0\n",
    "for i in range(len(iterative_channel_selection_accuracies_rs)):\n",
    "    if iterative_channel_selection_accuracies_rs[i]>max_value:\n",
    "        max_value=iterative_channel_selection_accuracies_rs[i]\n",
    "        max_index=i\n",
    "    \n",
    "# # Find the index of the maximum value\n",
    "# max_index = np.argmax(iterative_channel_selection_accuracies_rs)\n",
    "\n",
    "# # Find the maximum value\n",
    "# max_value = iterative_channel_selection_accuracies_rs[max_index]\n",
    "\n",
    "print(\"Maximum value:\", max_value)\n",
    "print(\"Index of maximum value:\", max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7d904660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 172,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 185]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features44[46]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635808cd",
   "metadata": {},
   "source": [
    "# channel selection strategies for task state data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94a866",
   "metadata": {},
   "source": [
    "## iterative channel selection for task data: selecting a channel if and only if its inclusion improves the mean classification performance of 2 anomaly detectors for task state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "35be12ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEG0142+0143',\n",
       " 'MEG1512+1513',\n",
       " 'MEG1542+1543',\n",
       " 'MEG1812+1813',\n",
       " 'MEG1622+1623',\n",
       " 'MEG1522+1523',\n",
       " 'MEG1612+1613',\n",
       " 'MEG1632+1633',\n",
       " 'MEG0232+0233',\n",
       " 'MEG0242+0243']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "eedd2ba1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEG1622+1623',\n",
       " 'MEG1342+1343',\n",
       " 'MEG1632+1633',\n",
       " 'MEG0232+0233',\n",
       " 'MEG0242+0243',\n",
       " 'MEG0112+0113',\n",
       " 'MEG0122+0123',\n",
       " 'MEG0222+0223',\n",
       " 'MEG1122+1123',\n",
       " 'MEG1222+1223',\n",
       " 'MEG0142+0143',\n",
       " 'MEG1512+1513',\n",
       " 'MEG1542+1543',\n",
       " 'MEG1812+1813',\n",
       " 'MEG1622+1623',\n",
       " 'MEG1522+1523',\n",
       " 'MEG1612+1613']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_channels_clicks1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8108db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the pipeline with SelectKBest and OneClassSVM\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM())\n",
    "])\n",
    "iterative_channel_selection_accuracies_ts=[]\n",
    "\n",
    "# Initialize variables\n",
    "\n",
    "\n",
    "\n",
    "##IMPORTANT-TO-DO--------------------------> this cell is to be run THREE TIMES with different initializations in the project methodology\n",
    "##-----------------------------------------> PHASE ONE: \n",
    "##----------------------------------------->        part1: initialize selected_channels_clicks= lhs_only given below; it will return best 2 channels from 10 audotory channels on left side of the brain\n",
    "##----------------------------------------->        part2: initialize selected_channels_clicks= rhs_only given below; it will return best 1 channel from 10 audotory channels on right side of the brain\n",
    "##-----------------------------------------> PHASE TWO: \n",
    "##----------------------------------------->        initialize selected_channels_clicks= lhs+rhs given below; it will return best 15 channels from 20 audotory channels of the brain\n",
    "\n",
    "\n",
    "selected_channels_clicks = [ 'MEG2412+2413' , 'MEG2222+2223','MEG2422+2423','MEG2442+2443' , 'MEG1432+1433' , 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343' , 'MEG0142+0143' , 'MEG1512+1513', 'MEG1542+1543' ,'MEG1812+1813', 'MEG1622+1623' , 'MEG1522+1523' , 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "\n",
    "#lhs only ['MEG0142+0143' ,'MEG1512+1513', 'MEG1542+1543','MEG1812+1813' , 'MEG1622+1623' , 'MEG1522+1523', 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "#right only ['MEG2412+2413' , 'MEG2222+2223','MEG2422+2423','MEG2442+2443' , 'MEG1432+1433' , 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343']\n",
    "\n",
    "# lhs+rhs [ 'MEG2412+2413' , 'MEG2222+2223','MEG2422+2423','MEG2442+2443' , 'MEG1432+1433' , 'MEG2612+2613', 'MEG2622+2623', 'MEG2642+2643', 'MEG1332+1333', 'MEG1342+1343' , 'MEG0142+0143' , 'MEG1512+1513', 'MEG1542+1543' ,'MEG1812+1813', 'MEG1622+1623' , 'MEG1522+1523' , 'MEG1612+1613', 'MEG1632+1633', 'MEG0232+0233', 'MEG0242+0243']\n",
    "\n",
    "# selected_channels_clicks=['MEG1622+1623',\n",
    "#  'MEG1342+1343',\n",
    "#  'MEG1632+1633',\n",
    "#  'MEG0232+0233',\n",
    "#  'MEG0242+0243',\n",
    "#  'MEG0112+0113',\n",
    "#  'MEG0122+0123',\n",
    "#  'MEG0142+0143',\n",
    "#  'MEG1512+1513',\n",
    "#  'MEG1542+1543',\n",
    "#  'MEG1812+1813',\n",
    "#  'MEG1622+1623',\n",
    "#  'MEG1522+1523',\n",
    "#  'MEG1612+1613']\n",
    "\n",
    "best_performance = 0.0   \n",
    "# Initialize with the worst performance\n",
    "selected_features11=[]\n",
    "selected_features22=[]\n",
    "j=0\n",
    "\n",
    "# Iterate through channels\n",
    "for channel in list_1:\n",
    "    selected_features1=[]\n",
    "    selected_features2=[]\n",
    "    print(\"---------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if channel in selected_channels_clicks:\n",
    "        continue  # Skip if channel already selected\n",
    "\n",
    "    # Add the current channel to selected channels\n",
    "    selected_channels_clicks.append(channel)\n",
    "    print('selected channels')\n",
    "    print(selected_channels_clicks)\n",
    "    selected_channel_indices = [list_1.index(i) for i in selected_channels_clicks]\n",
    "    print('selected channels indices')\n",
    "    print(selected_channel_indices)\n",
    "    print(\"---------------------------------------------------------------------------------------------------\")\n",
    "    print('2nd click performance now')\n",
    "    \n",
    "\n",
    "    train_healthy_psd_2nd_click = usable_features_psd_2nd_click[:11,selected_channel_indices,:]\n",
    "    test_psd_2nd_click = usable_features_psd_2nd_click[11:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_2nd_click = features_erp_2nd_click[:11,selected_channel_indices,:]\n",
    "    test_erp_2nd_click = features_erp_2nd_click[11:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_2nd_click.shape)\n",
    "    print(train_healthy_erp_2nd_click.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_2nd_click = np.concatenate((train_healthy_psd_2nd_click.reshape(11, -1),\n",
    "                                                        train_healthy_erp_2nd_click.reshape(11, -1)), axis=1)\n",
    "    print(train_healthy_features_2nd_click.shape)\n",
    "    chosen_indices1=[]\n",
    "    #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_2nd_click.reshape(11, -1)\n",
    "\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "    for i in range(reshaped_features.shape[1]):\n",
    "    #     print(i)\n",
    "        if i in constant_feature_indices:\n",
    "    #         print('true')\n",
    "            continue\n",
    "        else:\n",
    "            chosen_indices1.append(i)\n",
    "    print('remaining indices')\n",
    "    print(chosen_indices1)\n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_2nd_click= np.delete(train_healthy_features_2nd_click, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_2nd_click.shape)\n",
    "\n",
    "\n",
    "    test_features_2nd_click = np.concatenate((test_psd_2nd_click.reshape(10, -1),\n",
    "                                               test_erp_2nd_click.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_2nd_click=np.delete(test_features_2nd_click, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_2nd_click=usable_train_healthy_features_2nd_click.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_2nd_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_2nd_click).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_2nd_click\n",
    "    usable_nonnan_train_healthy_features_2nd_click = usable_train_healthy_features_2nd_click[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_2nd_click.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_2nd_click  = usable_test_features_2nd_click[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_2nd_click.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_2nd_click\n",
    "    _, y = usable_nonnan_train_healthy_features_2nd_click.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_2nd_click, [1] * usable_nonnan_train_healthy_features_2nd_click.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_2nd_click = selector.fit_transform(usable_nonnan_train_healthy_features_2nd_click, [1] * usable_nonnan_train_healthy_features_2nd_click.shape[0])\n",
    "\n",
    "\n",
    "    print(len(selector.get_support()))\n",
    "    print(selector.get_support())\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        # Check if x value is True\n",
    "        if val:\n",
    "            # Append the corresponding y value to selected_y\n",
    "            selected_features1.append(chosen_indices1[idx])\n",
    "    print('remaining feature indices selected after grid search ')\n",
    "    print(selected_features1)\n",
    "    \n",
    "    selected_features11.append(selected_features1)\n",
    "    print('iteration j')\n",
    "    print(j)\n",
    "    print('selected features 11')\n",
    "    print( selected_features11)\n",
    "    print(len(selected_features11))\n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_2nd_click[:, selector.get_support()]\n",
    "\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy_2nd_click, fold_accuracies_2nd_click = evaluate_performance(train_healthy_selected_features_2nd_click, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy_2nd_click)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies_2nd_click)\n",
    "    \n",
    "    print(\"---------------------------------------------------------------------------------------------------\")\n",
    "    print('1st click performance now')\n",
    "    train_healthy_psd_1st_click = usable_features_psd_1st_click[:11,selected_channel_indices,:]\n",
    "    test_psd_1st_click = usable_features_psd_1st_click[11:,selected_channel_indices,:]\n",
    "\n",
    "    train_healthy_erp_1st_click = features_erp_1st_click[:11,selected_channel_indices,:]\n",
    "    test_erp_1st_click = features_erp_1st_click[11:,selected_channel_indices,:]\n",
    "    \n",
    "    \n",
    "    print(train_healthy_psd_1st_click.shape)\n",
    "    print(train_healthy_erp_1st_click.shape)\n",
    "\n",
    "    # 2. Feature Extraction\n",
    "    # Flatten the PSD and ERP features\n",
    "    train_healthy_features_1st_click = np.concatenate((train_healthy_psd_1st_click.reshape(11, -1),\n",
    "                                                        train_healthy_erp_1st_click.reshape(11, -1)), axis=1)\n",
    "    print(train_healthy_features_1st_click.shape)\n",
    "    \n",
    "    chosen_indices2=[]\n",
    "     #removing constant features\n",
    "    # Reshape the array to make it a 2D array where each row represents a feature\n",
    "    reshaped_features = train_healthy_features_1st_click.reshape(11, -1)\n",
    "    # Calculate the variance along axis 0\n",
    "    variances = np.var(reshaped_features, axis=0)\n",
    "\n",
    "    # Find indices of constant features (where variance is zero)\n",
    "    constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "    print(\"Indices of constant features:\", constant_feature_indices)\n",
    "    for i in range(reshaped_features.shape[1]):\n",
    "    #     print(i)\n",
    "        if i in constant_feature_indices:\n",
    "    #         print('true')\n",
    "            continue\n",
    "        else:\n",
    "            chosen_indices2.append(i)\n",
    "    print('remaining indices')\n",
    "    print(chosen_indices2)\n",
    "\n",
    "    # Remove constant features\n",
    "    usable_train_healthy_features_1st_click= np.delete(train_healthy_features_1st_click, constant_feature_indices, axis=1)\n",
    "\n",
    "    # Verify the shape after removing constant features\n",
    "    print(\"Shape after removing constant features:\", usable_train_healthy_features_1st_click.shape)\n",
    "\n",
    "\n",
    "    test_features_1st_click = np.concatenate((test_psd_1st_click.reshape(10, -1),\n",
    "                                               test_erp_1st_click.reshape(10, -1)), axis=1)\n",
    "    usable_test_features_1st_click=np.delete(test_features_1st_click, constant_feature_indices, axis=1)\n",
    "    # Convert data to numerical type if necessary\n",
    "   \n",
    "    usable_train_healthy_features_1st_click=usable_train_healthy_features_1st_click.astype(float)\n",
    "\n",
    "    # Find indices of columns with NaN values in train_healthy_selected_features_2nd_click\n",
    "    nan_indices = np.isnan(usable_train_healthy_features_1st_click).any(axis=0)\n",
    "    # Remove columns with NaN values from train_healthy_selected_features_2nd_click\n",
    "    usable_nonnan_train_healthy_features_1st_click = usable_train_healthy_features_1st_click[:, ~nan_indices]\n",
    "        # Print shape after removing NaN columns\n",
    "    print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_1st_click.shape)\n",
    "\n",
    "    # Remove corresponding columns from X_test\n",
    "    usable_nonnan_test_features_1st_click  = usable_test_features_1st_click[:, ~nan_indices]\n",
    "\n",
    "\n",
    "    print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_1st_click.shape)\n",
    "\n",
    "       \n",
    "        # Perform the grid search\n",
    "    # Assuming y is the second dimension of usable_nonnan_train_healthy_features_2nd_click\n",
    "    _, y = usable_nonnan_train_healthy_features_1st_click.shape\n",
    "\n",
    "    # Create a list of indices with step size 10\n",
    "    indices = list(range(10, y+1, 10))\n",
    "    print(indices)\n",
    "\n",
    "\n",
    "    # Print the selected indices and corresponding values\n",
    "    print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "    # Define the range of k values to try\n",
    "    param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "    from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "    \n",
    "\n",
    "    # Define a custom scoring function for anomaly detection\n",
    "    # Example: F1-score\n",
    "    scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "    grid_search.fit(usable_nonnan_train_healthy_features_1st_click, [1] * usable_nonnan_train_healthy_features_1st_click.shape[0])\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_k = grid_search.best_params_['selector__k']\n",
    "    print(\"Best value of k:\", best_k)\n",
    "\n",
    "    # Select the best k features\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    train_healthy_selected_features_1st_click = selector.fit_transform(usable_nonnan_train_healthy_features_1st_click, [1] * usable_nonnan_train_healthy_features_1st_click.shape[0])\n",
    "\n",
    "    print(len(selector.get_support()))\n",
    "    print(selector.get_support())\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        # Check if x value is True\n",
    "        if val:\n",
    "            # Append the corresponding y value to selected_y\n",
    "            selected_features2.append(chosen_indices2[idx])\n",
    "    print('remaining feature indices selected after grid search ')\n",
    "    print(selected_features2)\n",
    "    \n",
    "    selected_features22.append(selected_features2)\n",
    "    print('iteration j')\n",
    "    print(j)\n",
    "    print('selected features 22')\n",
    "    print( selected_features22)\n",
    "    print(len(selected_features22))\n",
    "    j=j+1\n",
    "  \n",
    "    # Use selected features for testing\n",
    "    X_test = usable_nonnan_test_features_1st_click[:, selector.get_support()]\n",
    "\n",
    "    # Create labels for healthy subjects (0) and MCI subjects (1)\n",
    "    y_test = np.ones(X_test.shape[0])\n",
    "    y_test[5:] = -1  # Labels for MCI subjects\n",
    "    print(y_test)\n",
    "    \n",
    "    \n",
    "    test_set_accuracy_1st_click, fold_accuracies_1st_click = evaluate_performance(train_healthy_selected_features_1st_click, X_test, y_test)\n",
    "    print(\"Test Set Accuracy:\", test_set_accuracy_1st_click)\n",
    "    print(\"Fold Accuracies:\", fold_accuracies_1st_click)\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "  \n",
    "\n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    print('--------------------------------------------------------------------------------')\n",
    "\n",
    "    print('END OF 2 CLASSSIFICS')\n",
    "    print('2nd click accuracy')\n",
    "    print(test_set_accuracy_2nd_click)\n",
    "    print('1st click accuracy')\n",
    "    print(test_set_accuracy_1st_click)\n",
    "\n",
    "     # Evaluate performance\n",
    "    accuracies= [test_set_accuracy_2nd_click,test_set_accuracy_1st_click]\n",
    "    performance=sum(accuracies) / len(accuracies)\n",
    "    print('MEAN ACCURACY OF 2 CLASSIFS')\n",
    "    print(performance)\n",
    "    iterative_channel_selection_accuracies_ts.append(performance)\n",
    "\n",
    "    # Check if performance improved\n",
    "    if performance > best_performance or performance == best_performance:\n",
    "        best_performance = performance\n",
    "    else:\n",
    "        # Remove the last added channel if no improvement\n",
    "        selected_channels_clicks.pop()\n",
    "\n",
    "# Print selected channels and best performance\n",
    "print(\"Selected Channels:\", selected_channels_clicks)\n",
    "print(\"Best Performance:\")\n",
    "print(best_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "49a65bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2920653",
   "metadata": {},
   "source": [
    "### after this find union of 3 arrays of selected_channels_clicks obtained by running this section 3 times. It will yeild 16 channels.\n",
    " ----> use that 16 channel subset for anomaly detector of 1st click \n",
    " ----> for 2nd click's anomaly detector, run iterative channel elimination on the 16 channel subset to obtain optimal 13 channel subset, on which the anomaly detector can be trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466ba05",
   "metadata": {},
   "source": [
    "# anomaly detection: eyes closed data using iterative channel elimination's results; differentiating between movie state and resting state for eyes closed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0e8a4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels=['MEG0112+0113',\n",
    " 'MEG0122+0123',\n",
    " 'MEG0132+0133',\n",
    " 'MEG0142+0143',\n",
    " 'MEG0212+0213',\n",
    " 'MEG0222+0223',\n",
    " 'MEG0232+0233',\n",
    " 'MEG0242+0243',\n",
    " 'MEG0312+0313',\n",
    " 'MEG0322+0323',\n",
    " 'MEG0332+0333',\n",
    " 'MEG0342+0343',\n",
    " 'MEG0412+0413',\n",
    " 'MEG0422+0423',\n",
    " 'MEG0432+0433',\n",
    " 'MEG0442+0443',\n",
    " 'MEG0512+0513',\n",
    " 'MEG0522+0523',\n",
    " 'MEG0532+0533',\n",
    " 'MEG0542+0543',\n",
    " 'MEG0612+0613',\n",
    " 'MEG0622+0623',\n",
    " 'MEG0632+0633',\n",
    " 'MEG0642+0643',\n",
    " 'MEG0712+0713',\n",
    " 'MEG0722+0723',\n",
    " 'MEG0732+0733',\n",
    " 'MEG0742+0743',\n",
    " 'MEG0812+0813',\n",
    " 'MEG0822+0823',\n",
    " 'MEG0912+0913',\n",
    " 'MEG0922+0923',\n",
    " 'MEG0932+0933',\n",
    " 'MEG0942+0943',\n",
    " 'MEG1012+1013',\n",
    " 'MEG1022+1023',\n",
    " 'MEG1032+1033',\n",
    " 'MEG1042+1043',\n",
    " 'MEG1112+1113',\n",
    " 'MEG1122+1123',\n",
    " 'MEG1132+1133',\n",
    " 'MEG1142+1143',\n",
    " 'MEG1212+1213',\n",
    " 'MEG1222+1223',\n",
    " 'MEG1232+1233',\n",
    " 'MEG1242+1243',\n",
    " 'MEG1312+1313',\n",
    " 'MEG1322+1323',\n",
    " 'MEG1332+1333',\n",
    " 'MEG1342+1343',\n",
    " 'MEG1412+1413',\n",
    " 'MEG1422+1423',\n",
    " 'MEG1432+1433',\n",
    " 'MEG1442+1443',\n",
    " 'MEG1512+1513',\n",
    " 'MEG1522+1523',\n",
    " 'MEG1542+1543',\n",
    " 'MEG1612+1613',\n",
    " 'MEG1622+1623',\n",
    " 'MEG1632+1633',\n",
    " 'MEG1642+1643',\n",
    " 'MEG1712+1713',\n",
    " 'MEG1722+1723',\n",
    " 'MEG1732+1733',\n",
    " 'MEG1742+1743',\n",
    " 'MEG1822+1823',\n",
    " 'MEG1842+1843',\n",
    " 'MEG1922+1923',\n",
    " 'MEG1932+1933',\n",
    " 'MEG1942+1943',\n",
    " 'MEG2012+2013',\n",
    " 'MEG2022+2023',\n",
    " 'MEG2032+2033',\n",
    " 'MEG2042+2043',\n",
    " 'MEG2112+2113',\n",
    " 'MEG2122+2123',\n",
    " 'MEG2132+2133',\n",
    " 'MEG2142+2143',\n",
    " 'MEG2212+2213',\n",
    " 'MEG2222+2223',\n",
    " 'MEG2232+2233',\n",
    " 'MEG2312+2313',\n",
    " 'MEG2332+2333',\n",
    " 'MEG2412+2413',\n",
    " 'MEG2422+2423',\n",
    " 'MEG2432+2433',\n",
    " 'MEG2442+2443',\n",
    " 'MEG2512+2513',\n",
    " 'MEG2522+2523',\n",
    " 'MEG2532+2533',\n",
    " 'MEG2542+2543',\n",
    " 'MEG2612+2613',\n",
    " 'MEG2622+2623',\n",
    " 'MEG2642+2643']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cfae6dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_performance(X_train, X_test, y_test):\n",
    "    size = X_train.shape[0]\n",
    "    y_train = np.ones(size)\n",
    "    one_class_svm = OneClassSVM()\n",
    "    loo = LeaveOneOut()\n",
    "    fold_accuracies = []\n",
    "    predictions = []\n",
    "    for train_index, test_index in loo.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        one_class_svm.fit(X_train_fold)\n",
    "        predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "        predictions.append(predictions_fold)\n",
    "            # Print classification report for the fold\n",
    "        print(f\"Classification Report - Fold:\")\n",
    "        print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Combine predictions from all folds\n",
    "    predictions = np.concatenate(predictions)\n",
    "    print('concatenated predictions are')\n",
    "    print(predictions)\n",
    "    test_predictions = one_class_svm.predict(X_test)\n",
    "   \n",
    "\n",
    "\n",
    "    print(\"Final Classification Report:\")\n",
    "    report=classification_report(y_test, test_predictions, output_dict=True)\n",
    "    print(report)\n",
    "   \n",
    "    \n",
    "    # Extract metrics\n",
    "    accuracy_scores = report['accuracy']\n",
    "    mavg_precision_scores=report['macro avg']['precision']\n",
    "    mavg_recall_scores=report['macro avg']['recall']\n",
    "    mavg_f1_scores=report['macro avg']['f1-score']\n",
    "    wavg_precision_scores=report['weighted avg']['precision']\n",
    "    wavg_recall_scores=report['weighted avg']['recall']\n",
    "    wavg_f1_scores=report['weighted avg']['f1-score']\n",
    "\n",
    "    # Check if both classes are present in the testing data\n",
    "    if '1.0' in report:\n",
    "        precision_0_scores=report['1.0']['precision']\n",
    "        recall_0_scores=report['1.0']['recall']\n",
    "        f1_0_scores=report['1.0']['f1-score']\n",
    "\n",
    "    if '-1.0' in report:\n",
    "        precision_1_scores=report['-1.0']['precision']\n",
    "        recall_1_scores=report['-1.0']['recall']\n",
    "        f1_1_scores=report['-1.0']['f1-score']\n",
    "\n",
    "    \n",
    "    return (accuracy_scores, mavg_precision_scores, mavg_recall_scores, mavg_f1_scores, \n",
    "            wavg_precision_scores, wavg_recall_scores, wavg_f1_scores, \n",
    "            precision_0_scores, recall_0_scores, f1_0_scores, \n",
    "            precision_1_scores, recall_1_scores, f1_1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f40a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM(kernel='rbf', gamma=0.6))\n",
    "])\n",
    "\n",
    "# Prepare the data\n",
    "selected_channel_indices = [list_1.index(i) for i in selected_channels]\n",
    "print('selected channels indices')\n",
    "print(selected_channel_indices)\n",
    "train_healthy_psd_rsec = usable_features_psd_rsec[:16, selected_channel_indices, :]\n",
    "test_psd_rsec = usable_features_psd_rsec[16:, selected_channel_indices, :]\n",
    "train_healthy_erp_rsec = features_erp_rsec[:16, selected_channel_indices, :]\n",
    "test_erp_rsec = features_erp_rsec[16:, selected_channel_indices, :]\n",
    "\n",
    "train_healthy_features_rsec = np.concatenate((train_healthy_psd_rsec.reshape(16, -1),\n",
    "                                              train_healthy_erp_rsec.reshape(16, -1)), axis=1)\n",
    "chosen_indices = []\n",
    "# Remove constant features\n",
    "variances = np.var(train_healthy_features_rsec, axis=0)\n",
    "constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "print(\"Indices of constant features:\", constant_feature_indices)\n",
    "for i in range(train_healthy_features_rsec.shape[1]):\n",
    "    if i in constant_feature_indices:\n",
    "        continue\n",
    "    else:\n",
    "        chosen_indices.append(i)\n",
    "print('remaining indices')\n",
    "print(chosen_indices)\n",
    "print(len(chosen_indices))\n",
    "\n",
    "usable_train_healthy_features_rsec = np.delete(train_healthy_features_rsec, constant_feature_indices, axis=1)\n",
    "\n",
    "# Prepare test data\n",
    "test_features_rsec = np.concatenate((test_psd_rsec.reshape(4, -1),\n",
    "                                     test_erp_rsec.reshape(4, -1)), axis=1)\n",
    "usable_test_features_rsec = np.delete(test_features_rsec, constant_feature_indices, axis=1)\n",
    "usable_train_healthy_features_rsec = usable_train_healthy_features_rsec.astype(float)\n",
    "# Remove NaN columns\n",
    "nan_indices = np.isnan(usable_train_healthy_features_rsec).any(axis=0)\n",
    "usable_nonnan_train_healthy_features_rsec = usable_train_healthy_features_rsec[:, ~nan_indices]\n",
    "usable_nonnan_test_features_rsec = usable_test_features_rsec[:, ~nan_indices]\n",
    "chosen_indices2 = []\n",
    "print(\"nan_indices are\")\n",
    "print(nan_indices)\n",
    "print(len(nan_indices))\n",
    "for i in range(len(nan_indices)):\n",
    "    if not nan_indices[i]:\n",
    "        chosen_indices2.append(chosen_indices[i])\n",
    "    else:\n",
    "        print(i)\n",
    "        print('the element is')\n",
    "        print(chosen_indices[i])\n",
    "\n",
    "print('chosen indices after removing Nan columns')\n",
    "print(chosen_indices2)\n",
    "# Print shape after removing NaN columns\n",
    "print(\"Shape of train_healthy_selected_features_rsec after removing NaN columns:\", usable_nonnan_train_healthy_features_rsec.shape)\n",
    "\n",
    "# Remove corresponding columns from X_test\n",
    "usable_nonnan_test_features_rsec = usable_test_features_rsec[:, ~nan_indices]\n",
    "\n",
    "print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rsec.shape)\n",
    "\n",
    "# Indices for training and test sets\n",
    "A_indices = list(range(11))\n",
    "B_indices = list(range(11, 16))\n",
    "\n",
    "# Lists to store metrics for each repetition\n",
    "accuracy_scores = []\n",
    "precision_0_scores = []\n",
    "precision_1_scores = []\n",
    "recall_0_scores = []\n",
    "recall_1_scores = []\n",
    "f1_0_scores = []\n",
    "f1_1_scores = []\n",
    "mavg_precision_scores = []\n",
    "mavg_recall_scores = []\n",
    "mavg_f1_scores = []\n",
    "wavg_precision_scores = []\n",
    "wavg_recall_scores = []\n",
    "wavg_f1_scores = []\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "\n",
    "\n",
    "for b_index in B_indices:\n",
    "    for a_index in A_indices:\n",
    "        current_A_indices = A_indices.copy()\n",
    "        current_A_indices[a_index] = b_index\n",
    "        \n",
    "        train_sets.append(current_A_indices)\n",
    "        print(\"training indices\")\n",
    "        print(current_A_indices)\n",
    "        test_healthy_indices= []\n",
    "        for i in range(16):\n",
    "            print(i)\n",
    "            if i in current_A_indices:\n",
    "                continue\n",
    "            else:\n",
    "                test_healthy_indices.append(i)\n",
    "            \n",
    "        \n",
    "        print(\"healthy testing indices nowwwwwwww\")\n",
    "        print(test_healthy_indices)\n",
    "\n",
    "        X_train = usable_nonnan_train_healthy_features_rsec[current_A_indices]\n",
    "        y_train = np.ones(X_train.shape[0])\n",
    "        print(\"initial shape of usable_nonnan_train_healthy_features_rsec\")\n",
    "        print(usable_nonnan_train_healthy_features_rsec.shape)\n",
    "        print(\"selecting features fromit\")\n",
    "        print(test_healthy_indices)\n",
    "        test_healthy_features = usable_nonnan_train_healthy_features_rsec[test_healthy_indices]\n",
    "        print(\"shape of remaining healthy subjects to be used for testing\")\n",
    "        print(test_healthy_features.shape)\n",
    "\n",
    "        # Combine the test healthy features with MCI features\n",
    "        X_test = np.vstack((test_healthy_features, usable_nonnan_test_features_rsec))\n",
    "        y_test = np.concatenate((np.ones(test_healthy_features.shape[0]), -1 * np.ones(usable_nonnan_test_features_rsec.shape[0])))\n",
    "\n",
    "        print(\"Shape of train and test features\")\n",
    "        print(X_train.shape)\n",
    "        print(y_train)\n",
    "  \n",
    "        print(\"length of testing data\")\n",
    "        print(X_test.shape)\n",
    "        print(y_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy_score, mavg_precision_score, mavg_recall_score, mavg_f1_score, wavg_precision_score, wavg_recall_score, wavg_f1_score, precision_0_score, recall_0_score, f1_0_score, precision_1_score, recall_1_score, f1_1_score = evaluate_performance(X_train, X_test, y_test)\n",
    "        accuracy_scores.append(accuracy_score)\n",
    "        mavg_precision_scores.append(mavg_precision_score)\n",
    "        mavg_recall_scores.append(mavg_recall_score)\n",
    "        mavg_f1_scores.append(mavg_f1_score)\n",
    "        wavg_precision_scores.append(wavg_precision_score)\n",
    "        wavg_recall_scores.append(wavg_recall_score)\n",
    "        wavg_f1_scores.append(wavg_f1_score)\n",
    "        precision_0_scores.append(precision_0_score)\n",
    "        recall_0_scores.append(recall_0_score)\n",
    "        f1_0_scores.append(f1_0_score)\n",
    "        precision_1_scores.append(precision_1_score)\n",
    "        recall_1_scores.append(recall_1_score)\n",
    "        f1_1_scores.append(f1_1_score)\n",
    "# Print results\n",
    "print('accuracy_scores are')\n",
    "print(accuracy_scores)\n",
    "print(\"Accuracy: {:.2f}  {:.2f}\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"Precision (class 0): {:.2f}  {:.2f}\".format(np.mean(precision_0_scores), np.std(precision_0_scores)))\n",
    "print(\"Precision (class 1): {:.2f}  {:.2f}\".format(np.mean(precision_1_scores), np.std(precision_1_scores)))\n",
    "print(\"Recall (class 0): {:.2f}  {:.2f}\".format(np.mean(recall_0_scores), np.std(recall_0_scores)))\n",
    "print(\"Recall (class 1): {:.2f}  {:.2f}\".format(np.mean(recall_1_scores), np.std(recall_1_scores)))\n",
    "print(\"F1-score (class 0): {:.2f}  {:.2f}\".format(np.mean(f1_0_scores), np.std(f1_0_scores)))\n",
    "print(\"F1-score (class 1): {:.2f}  {:.2f}\".format(np.mean(f1_1_scores), np.std(f1_1_scores)))\n",
    "print(\"Macro avg precision: {:.2f}  {:.2f}\".format(np.mean(mavg_precision_scores), np.std(mavg_precision_scores)))\n",
    "print(\"Macro avg recall: {:.2f}  {:.2f}\".format(np.mean(mavg_recall_scores), np.std(mavg_recall_scores)))\n",
    "print(\"Macro avg f1-score: {:.2f}  {:.2f}\".format(np.mean(mavg_f1_scores), np.std(mavg_f1_scores)))\n",
    "print(\"Weighted avg precision: {:.2f}  {:.2f}\".format(np.mean(wavg_precision_scores), np.std(wavg_precision_scores)))\n",
    "print(\"weighted avg recall: {:.2f}  {:.2f}\".format(np.mean(wavg_recall_scores), np.std(wavg_recall_scores)))\n",
    "print(\"weighted avg f1-score: {:.2f}  {:.2f}\".format(np.mean(wavg_f1_scores), np.std(wavg_f1_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0ea91",
   "metadata": {},
   "source": [
    "#  anomaly detection: eyes open data using iterative channel elimination's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "e74a20af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24110c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_performance(X_train, X_test, y_test):\n",
    "    size = X_train.shape[0]\n",
    "    y_train = np.ones(size)\n",
    "    one_class_svm = OneClassSVM()\n",
    "    loo = LeaveOneOut()\n",
    "    fold_accuracies = []\n",
    "    predictions = []\n",
    "    for train_index, test_index in loo.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        one_class_svm.fit(X_train_fold)\n",
    "        predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "        predictions.append(predictions_fold)\n",
    "            # Print classification report for the fold\n",
    "        print(f\"Classification Report - Fold:\")\n",
    "        print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Combine predictions from all folds\n",
    "    predictions = np.concatenate(predictions)\n",
    "    print('concatenated predictions are')\n",
    "    print(predictions)\n",
    "    test_predictions = one_class_svm.predict(X_test)\n",
    "   \n",
    "\n",
    "\n",
    "    print(\"Final Classification Report:\")\n",
    "    report=classification_report(y_test, test_predictions, output_dict=True)\n",
    "    print(report)\n",
    "   \n",
    "    \n",
    "    # Extract metrics\n",
    "    accuracy_scores = report['accuracy']\n",
    "    mavg_precision_scores=report['macro avg']['precision']\n",
    "    mavg_recall_scores=report['macro avg']['recall']\n",
    "    mavg_f1_scores=report['macro avg']['f1-score']\n",
    "    wavg_precision_scores=report['weighted avg']['precision']\n",
    "    wavg_recall_scores=report['weighted avg']['recall']\n",
    "    wavg_f1_scores=report['weighted avg']['f1-score']\n",
    "\n",
    "    # Check if both classes are present in the testing data\n",
    "    if '1.0' in report:\n",
    "        precision_0_scores=report['1.0']['precision']\n",
    "        recall_0_scores=report['1.0']['recall']\n",
    "        f1_0_scores=report['1.0']['f1-score']\n",
    "\n",
    "    if '-1.0' in report:\n",
    "        precision_1_scores=report['-1.0']['precision']\n",
    "        recall_1_scores=report['-1.0']['recall']\n",
    "        f1_1_scores=report['-1.0']['f1-score']\n",
    "\n",
    "    \n",
    "    return (accuracy_scores, mavg_precision_scores, mavg_recall_scores, mavg_f1_scores, \n",
    "            wavg_precision_scores, wavg_recall_scores, wavg_f1_scores, \n",
    "            precision_0_scores, recall_0_scores, f1_0_scores, \n",
    "            precision_1_scores, recall_1_scores, f1_1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5982f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM(kernel='rbf', gamma=0.6))\n",
    "])\n",
    "\n",
    "# Prepare the data\n",
    "selected_channel_indices = [list_1.index(i) for i in selected_channels]\n",
    "print('selected channels indices')\n",
    "print(selected_channel_indices)\n",
    "train_healthy_psd_rseo = usable_features_psd_rseo[:16, selected_channel_indices, :]\n",
    "test_psd_rseo = usable_features_psd_rseo[16:, selected_channel_indices, :]\n",
    "train_healthy_erp_rseo = features_erp_rseo[:16, selected_channel_indices, :]\n",
    "test_erp_rseo = features_erp_rseo[16:, selected_channel_indices, :]\n",
    "\n",
    "train_healthy_features_rseo = np.concatenate((train_healthy_psd_rseo.reshape(16, -1),\n",
    "                                              train_healthy_erp_rseo.reshape(16, -1)), axis=1)\n",
    "chosen_indices = []\n",
    "# Remove constant features\n",
    "variances = np.var(train_healthy_features_rseo, axis=0)\n",
    "constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "print(\"Indices of constant features:\", constant_feature_indices)\n",
    "for i in range(train_healthy_features_rseo.shape[1]):\n",
    "    if i in constant_feature_indices:\n",
    "        continue\n",
    "    else:\n",
    "        chosen_indices.append(i)\n",
    "print('remaining indices')\n",
    "print(chosen_indices)\n",
    "print(len(chosen_indices))\n",
    "\n",
    "usable_train_healthy_features_rseo = np.delete(train_healthy_features_rseo, constant_feature_indices, axis=1)\n",
    "\n",
    "# Prepare test data\n",
    "test_features_rseo = np.concatenate((test_psd_rseo.reshape(5, -1),\n",
    "                                     test_erp_rseo.reshape(5, -1)), axis=1)\n",
    "usable_test_features_rseo = np.delete(test_features_rseo, constant_feature_indices, axis=1)\n",
    "usable_train_healthy_features_rseo = usable_train_healthy_features_rseo.astype(float)\n",
    "# Remove NaN columns\n",
    "nan_indices = np.isnan(usable_train_healthy_features_rseo).any(axis=0)\n",
    "usable_nonnan_train_healthy_features_rseo = usable_train_healthy_features_rseo[:, ~nan_indices]\n",
    "usable_nonnan_test_features_rseo = usable_test_features_rseo[:, ~nan_indices]\n",
    "chosen_indices2 = []\n",
    "print(\"nan_indices are\")\n",
    "print(nan_indices)\n",
    "print(len(nan_indices))\n",
    "for i in range(len(nan_indices)):\n",
    "    if not nan_indices[i]:\n",
    "        chosen_indices2.append(chosen_indices[i])\n",
    "    else:\n",
    "        print(i)\n",
    "        print('the element is')\n",
    "        print(chosen_indices[i])\n",
    "\n",
    "print('chosen indices after removing Nan columns')\n",
    "print(chosen_indices2)\n",
    "# Print shape after removing NaN columns\n",
    "print(\"Shape of train_healthy_selected_features_rseo after removing NaN columns:\", usable_nonnan_train_healthy_features_rseo.shape)\n",
    "\n",
    "# Remove corresponding columns from X_test\n",
    "usable_nonnan_test_features_rseo = usable_test_features_rseo[:, ~nan_indices]\n",
    "\n",
    "print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_rseo.shape)\n",
    "\n",
    "# Indices for training and test sets\n",
    "A_indices = list(range(11))\n",
    "B_indices = list(range(11, 16))\n",
    "\n",
    "# Lists to store metrics for each repetition\n",
    "accuracy_scores = []\n",
    "precision_0_scores = []\n",
    "precision_1_scores = []\n",
    "recall_0_scores = []\n",
    "recall_1_scores = []\n",
    "f1_0_scores = []\n",
    "f1_1_scores = []\n",
    "mavg_precision_scores = []\n",
    "mavg_recall_scores = []\n",
    "mavg_f1_scores = []\n",
    "wavg_precision_scores = []\n",
    "wavg_recall_scores = []\n",
    "wavg_f1_scores = []\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "\n",
    "\n",
    "for b_index in B_indices:\n",
    "    for a_index in A_indices:\n",
    "        current_A_indices = A_indices.copy()\n",
    "        current_A_indices[a_index] = b_index\n",
    "        \n",
    "        train_sets.append(current_A_indices)\n",
    "        print(\"training indices\")\n",
    "        print(current_A_indices)\n",
    "        test_healthy_indices= []\n",
    "        for i in range(16):\n",
    "            print(i)\n",
    "            if i in current_A_indices:\n",
    "                continue\n",
    "            else:\n",
    "                test_healthy_indices.append(i)\n",
    "            \n",
    "        \n",
    "        print(\"healthy testing indices nowwwwwwww\")\n",
    "        print(test_healthy_indices)\n",
    "\n",
    "        X_train = usable_nonnan_train_healthy_features_rseo[current_A_indices]\n",
    "        y_train = np.ones(X_train.shape[0])\n",
    "        print(\"initial shape of usable_nonnan_train_healthy_features_rseo\")\n",
    "        print(usable_nonnan_train_healthy_features_rseo.shape)\n",
    "        print(\"selecting features fromit\")\n",
    "        print(test_healthy_indices)\n",
    "        test_healthy_features = usable_nonnan_train_healthy_features_rseo[test_healthy_indices]\n",
    "        print(\"shape of remaining healthy subjects to be used for testing\")\n",
    "        print(test_healthy_features.shape)\n",
    "\n",
    "        # Combine the test healthy features with MCI features\n",
    "        X_test = np.vstack((test_healthy_features, usable_nonnan_test_features_rseo))\n",
    "        y_test = np.concatenate((np.ones(test_healthy_features.shape[0]), -1 * np.ones(usable_nonnan_test_features_rseo.shape[0])))\n",
    "\n",
    "        print(\"Shape of train and test features\")\n",
    "        print(X_train.shape)\n",
    "        print(y_train)\n",
    "  \n",
    "        print(\"length of testing data\")\n",
    "        print(X_test.shape)\n",
    "        print(y_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy_score, mavg_precision_score, mavg_recall_score, mavg_f1_score, wavg_precision_score, wavg_recall_score, wavg_f1_score, precision_0_score, recall_0_score, f1_0_score, precision_1_score, recall_1_score, f1_1_score = evaluate_performance(X_train, X_test, y_test)\n",
    "        accuracy_scores.append(accuracy_score)\n",
    "        mavg_precision_scores.append(mavg_precision_score)\n",
    "        mavg_recall_scores.append(mavg_recall_score)\n",
    "        mavg_f1_scores.append(mavg_f1_score)\n",
    "        wavg_precision_scores.append(wavg_precision_score)\n",
    "        wavg_recall_scores.append(wavg_recall_score)\n",
    "        wavg_f1_scores.append(wavg_f1_score)\n",
    "        precision_0_scores.append(precision_0_score)\n",
    "        recall_0_scores.append(recall_0_score)\n",
    "        f1_0_scores.append(f1_0_score)\n",
    "        precision_1_scores.append(precision_1_score)\n",
    "        recall_1_scores.append(recall_1_score)\n",
    "        f1_1_scores.append(f1_1_score)\n",
    "# Print results\n",
    "print('accuracy_scores are')\n",
    "print(accuracy_scores)\n",
    "print(\"Accuracy: {:.2f}  {:.2f}\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"Precision (class 0): {:.2f}  {:.2f}\".format(np.mean(precision_0_scores), np.std(precision_0_scores)))\n",
    "print(\"Precision (class 1): {:.2f}  {:.2f}\".format(np.mean(precision_1_scores), np.std(precision_1_scores)))\n",
    "print(\"Recall (class 0): {:.2f}  {:.2f}\".format(np.mean(recall_0_scores), np.std(recall_0_scores)))\n",
    "print(\"Recall (class 1): {:.2f}  {:.2f}\".format(np.mean(recall_1_scores), np.std(recall_1_scores)))\n",
    "print(\"F1-score (class 0): {:.2f}  {:.2f}\".format(np.mean(f1_0_scores), np.std(f1_0_scores)))\n",
    "print(\"F1-score (class 1): {:.2f}  {:.2f}\".format(np.mean(f1_1_scores), np.std(f1_1_scores)))\n",
    "print(\"Macro avg precision: {:.2f}  {:.2f}\".format(np.mean(mavg_precision_scores), np.std(mavg_precision_scores)))\n",
    "print(\"Macro avg recall: {:.2f}  {:.2f}\".format(np.mean(mavg_recall_scores), np.std(mavg_recall_scores)))\n",
    "print(\"Macro avg f1-score: {:.2f}  {:.2f}\".format(np.mean(mavg_f1_scores), np.std(mavg_f1_scores)))\n",
    "print(\"Weighted avg precision: {:.2f}  {:.2f}\".format(np.mean(wavg_precision_scores), np.std(wavg_precision_scores)))\n",
    "print(\"weighted avg recall: {:.2f}  {:.2f}\".format(np.mean(wavg_recall_scores), np.std(wavg_recall_scores)))\n",
    "print(\"weighted avg f1-score: {:.2f}  {:.2f}\".format(np.mean(wavg_f1_scores), np.std(wavg_f1_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8e442",
   "metadata": {},
   "source": [
    "# anomaly detection: 1st click data using iterative channel selection's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels_1st_click=['MEG1622+1623','MEG1342+1343','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG0112+0113','MEG0122+0123','MEG0222+0223','MEG1122+1123','MEG1222+1223','MEG0142+0143','MEG1512+1513','MEG1542+1543','MEG1812+1813','MEG1522+1523','MEG1612+1613']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM(kernel='rbf', gamma=0.6))\n",
    "])\n",
    "\n",
    "# Prepare the data\n",
    "selected_channel_indices = [list_1.index(i) for i in selected_channels_1st_click]\n",
    "print('selected channels indices')\n",
    "print(selected_channel_indices)\n",
    "train_healthy_psd_1st_click = usable_features_psd_1st_click[:16, selected_channel_indices, :]\n",
    "test_psd_1st_click = usable_features_psd_1st_click[16:, selected_channel_indices, :]\n",
    "train_healthy_erp_1st_click = features_erp_1st_click[:16, selected_channel_indices, :]\n",
    "test_erp_1st_click = features_erp_1st_click[16:, selected_channel_indices, :]\n",
    "\n",
    "train_healthy_features_1st_click = np.concatenate((train_healthy_psd_1st_click.reshape(16, -1),\n",
    "                                              train_healthy_erp_1st_click.reshape(16, -1)), axis=1)\n",
    "\n",
    "\n",
    "print(\"shape of training data\")\n",
    "print(train_healthy_features_1st_click.shape)\n",
    "chosen_indices = []\n",
    "# Remove constant features\n",
    "variances = np.var(train_healthy_features_1st_click, axis=0)\n",
    "constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "print(\"Indices of constant features:\", constant_feature_indices)\n",
    "for i in range(train_healthy_features_1st_click.shape[1]):\n",
    "    if i in constant_feature_indices:\n",
    "        continue\n",
    "    else:\n",
    "        chosen_indices.append(i)\n",
    "print('remaining indices')\n",
    "print(chosen_indices)\n",
    "print(len(chosen_indices))\n",
    "\n",
    "usable_train_healthy_features_1st_click = np.delete(train_healthy_features_1st_click, constant_feature_indices, axis=1)\n",
    "\n",
    "# Prepare test data\n",
    "test_features_1st_click = np.concatenate((test_psd_1st_click.reshape(5, -1),\n",
    "                                     test_erp_1st_click.reshape(5, -1)), axis=1)\n",
    "\n",
    "print(\"shape of testing data\")\n",
    "print(test_features_1st_click.shape)\n",
    "print(\"shape of training data after removing constant features\")\n",
    "print(usable_train_healthy_features_1st_click.shape)\n",
    "usable_test_features_1st_click = np.delete(test_features_1st_click, constant_feature_indices, axis=1)\n",
    "print(\"shape of testing data after removing constant features\")\n",
    "print(usable_test_features_1st_click.shape)\n",
    "\n",
    "usable_train_healthy_features_1st_click = usable_train_healthy_features_1st_click.astype(float)\n",
    "# Remove NaN columns\n",
    "nan_indices = np.isnan(usable_train_healthy_features_1st_click).any(axis=0)\n",
    "usable_nonnan_train_healthy_features_1st_click = usable_train_healthy_features_1st_click[:, ~nan_indices]\n",
    "usable_nonnan_test_features_1st_click = usable_test_features_1st_click[:, ~nan_indices]\n",
    "chosen_indices2 = []\n",
    "print(\"nan_indices are\")\n",
    "print(nan_indices)\n",
    "print(len(nan_indices))\n",
    "for i in range(len(nan_indices)):\n",
    "    if not nan_indices[i]:\n",
    "        chosen_indices2.append(chosen_indices[i])\n",
    "    else:\n",
    "        print(i)\n",
    "        print('the element is')\n",
    "        print(chosen_indices[i])\n",
    "\n",
    "print('chosen indices after removing Nan columns')\n",
    "print(chosen_indices2)\n",
    "# Print shape after removing NaN columns\n",
    "print(\"Shape of train_healthy_selected_features_1st_click after removing NaN columns:\", usable_nonnan_train_healthy_features_1st_click.shape)\n",
    "\n",
    "# Remove corresponding columns from X_test\n",
    "usable_nonnan_test_features_1st_click = usable_test_features_1st_click[:, ~nan_indices]\n",
    "\n",
    "print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_1st_click.shape)\n",
    "\n",
    "# Indices for training and test sets\n",
    "A_indices = list(range(11))\n",
    "B_indices = list(range(11, 16))\n",
    "\n",
    "# Lists to store metrics for each repetition\n",
    "accuracy_scores = []\n",
    "precision_0_scores = []\n",
    "precision_1_scores = []\n",
    "recall_0_scores = []\n",
    "recall_1_scores = []\n",
    "f1_0_scores = []\n",
    "f1_1_scores = []\n",
    "mavg_precision_scores = []\n",
    "mavg_recall_scores = []\n",
    "mavg_f1_scores = []\n",
    "wavg_precision_scores = []\n",
    "wavg_recall_scores = []\n",
    "wavg_f1_scores = []\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "\n",
    "\n",
    "for b_index in B_indices:\n",
    "    for a_index in A_indices:\n",
    "        current_A_indices = A_indices.copy()\n",
    "        current_A_indices[a_index] = b_index\n",
    "        \n",
    "        train_sets.append(current_A_indices)\n",
    "        print(\"training indices\")\n",
    "        print(current_A_indices)\n",
    "        test_healthy_indices= []\n",
    "        for i in range(16):\n",
    "            print(i)\n",
    "            if i in current_A_indices:\n",
    "                continue\n",
    "            else:\n",
    "                test_healthy_indices.append(i)\n",
    "            \n",
    "        \n",
    "        print(\"healthy testing indices nowwwwwwww\")\n",
    "        print(test_healthy_indices)\n",
    "\n",
    "        X_train = usable_nonnan_train_healthy_features_1st_click[current_A_indices]\n",
    "        y_train = np.ones(X_train.shape[0])\n",
    "        print(\"initial shape of usable_nonnan_train_healthy_features_1st_click\")\n",
    "        print(usable_nonnan_train_healthy_features_1st_click.shape)\n",
    "        print(\"selecting features fromit\")\n",
    "        print(test_healthy_indices)\n",
    "        test_healthy_features = usable_nonnan_train_healthy_features_1st_click[test_healthy_indices]\n",
    "        print(\"shape of remaining healthy subjects to be used for testing\")\n",
    "        print(test_healthy_features.shape)\n",
    "\n",
    "        # Combine the test healthy features with MCI features\n",
    "        X_test = np.vstack((test_healthy_features, usable_nonnan_test_features_1st_click))\n",
    "        y_test = np.concatenate((np.ones(test_healthy_features.shape[0]), -1 * np.ones(usable_nonnan_test_features_1st_click.shape[0])))\n",
    "\n",
    "        print(\"Shape of train and test features\")\n",
    "        print(X_train.shape)\n",
    "        print(y_train)\n",
    "  \n",
    "        print(\"length of testing data\")\n",
    "        print(X_test.shape)\n",
    "        print(y_test)\n",
    "            # Assuming y is the second dimension of usable_nonnan_train_healthy_features_1st_click\n",
    "        _, y = X_train.shape\n",
    "\n",
    "        # Create a list of indices with step size 10\n",
    "        indices = list(range(10, y+1, 10))\n",
    "        print(indices)\n",
    "\n",
    "\n",
    "        # Print the selected indices and corresponding values\n",
    "        print(\"Selected Indices:\", indices)\n",
    "\n",
    "\n",
    "        # Define the range of k values to try\n",
    "        param_grid = {'selector__k': indices}  # Adjust the range as needed\n",
    "        from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "        scorer = make_scorer(f1_score)  # pos_label=1 for the anomaly class\n",
    "\n",
    "        # Initialize the GridSearchCV object\n",
    "        grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scorer)\n",
    "\n",
    "\n",
    "        grid_search.fit(X_train, [1] * X_train.shape[0])\n",
    "\n",
    "        # Get the best value of k\n",
    "        best_k = grid_search.best_params_['selector__k']\n",
    "        print(\"Best value of k:\", best_k)\n",
    "\n",
    "        # Select the best k features\n",
    "        selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "        train_healthy_selected_features_1st_click = selector.fit_transform(X_train, [1] * X_train.shape[0])\n",
    "\n",
    "        selected_features_1st_click=[]\n",
    "        print(len(selector.get_support()))\n",
    "        print(selector.get_support())\n",
    "        for idx, val in enumerate(selector.get_support()):\n",
    "            # Check if x value is True\n",
    "            if val:\n",
    "                # Append the corresponding y value to selected_y\n",
    "                selected_features_1st_click.append(chosen_indices[idx])\n",
    "        print('remaining feature indices selected after grid search ')\n",
    "        print(selected_features_1st_click)\n",
    "\n",
    "        # Use selected features for testing\n",
    "        X_test = X_test[:, selector.get_support()]\n",
    "        X_train=train_healthy_selected_features_1st_click\n",
    "        print(\"affftttrrtttt\")\n",
    "        print(\"shape of train and test features\")\n",
    "        print(X_train.shape)\n",
    "        print(y_train)\n",
    "        print(X_test.shape)\n",
    "        print(y_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy_score, mavg_precision_score, mavg_recall_score, mavg_f1_score, wavg_precision_score, wavg_recall_score, wavg_f1_score, precision_0_score, recall_0_score, f1_0_score, precision_1_score, recall_1_score, f1_1_score = evaluate_performance(X_train, X_test, y_test)\n",
    "        accuracy_scores.append(accuracy_score)\n",
    "        mavg_precision_scores.append(mavg_precision_score)\n",
    "        mavg_recall_scores.append(mavg_recall_score)\n",
    "        mavg_f1_scores.append(mavg_f1_score)\n",
    "        wavg_precision_scores.append(wavg_precision_score)\n",
    "        wavg_recall_scores.append(wavg_recall_score)\n",
    "        wavg_f1_scores.append(wavg_f1_score)\n",
    "        precision_0_scores.append(precision_0_score)\n",
    "        recall_0_scores.append(recall_0_score)\n",
    "        f1_0_scores.append(f1_0_score)\n",
    "        precision_1_scores.append(precision_1_score)\n",
    "        recall_1_scores.append(recall_1_score)\n",
    "        f1_1_scores.append(f1_1_score)\n",
    "# Print results\n",
    "print('accuracy_scores are')\n",
    "print(accuracy_scores)\n",
    "print(\"Accuracy: {:.2f}  {:.2f}\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"Precision (class 0): {:.2f}  {:.2f}\".format(np.mean(precision_0_scores), np.std(precision_0_scores)))\n",
    "print(\"Precision (class 1): {:.2f}  {:.2f}\".format(np.mean(precision_1_scores), np.std(precision_1_scores)))\n",
    "print(\"Recall (class 0): {:.2f}  {:.2f}\".format(np.mean(recall_0_scores), np.std(recall_0_scores)))\n",
    "print(\"Recall (class 1): {:.2f}  {:.2f}\".format(np.mean(recall_1_scores), np.std(recall_1_scores)))\n",
    "print(\"F1-score (class 0): {:.2f}  {:.2f}\".format(np.mean(f1_0_scores), np.std(f1_0_scores)))\n",
    "print(\"F1-score (class 1): {:.2f}  {:.2f}\".format(np.mean(f1_1_scores), np.std(f1_1_scores)))\n",
    "print(\"Macro avg precision: {:.2f}  {:.2f}\".format(np.mean(mavg_precision_scores), np.std(mavg_precision_scores)))\n",
    "print(\"Macro avg recall: {:.2f}  {:.2f}\".format(np.mean(mavg_recall_scores), np.std(mavg_recall_scores)))\n",
    "print(\"Macro avg f1-score: {:.2f}  {:.2f}\".format(np.mean(mavg_f1_scores), np.std(mavg_f1_scores)))\n",
    "print(\"Weighted avg precision: {:.2f}  {:.2f}\".format(np.mean(wavg_precision_scores), np.std(wavg_precision_scores)))\n",
    "print(\"weighted avg recall: {:.2f}  {:.2f}\".format(np.mean(wavg_recall_scores), np.std(wavg_recall_scores)))\n",
    "print(\"weighted avg f1-score: {:.2f}  {:.2f}\".format(np.mean(wavg_f1_scores), np.std(wavg_f1_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871774cc",
   "metadata": {},
   "source": [
    "# anomaly detection: 2nd click data using iterative channel selection B's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels_2nd_click=['MEG1622+1623','MEG1342+1343','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG0112+0113','MEG0122+0123','MEG0142+0143','MEG1512+1513','MEG1542+1543','MEG1812+1813','MEG1622+1623','MEG1522+1523','MEG1612+1613']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d148acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_performance(X_train, X_test, y_test):\n",
    "    size = X_train.shape[0]\n",
    "    y_train = np.ones(size)\n",
    "    one_class_svm = OneClassSVM()\n",
    "    loo = LeaveOneOut()\n",
    "    fold_accuracies = []\n",
    "    predictions = []\n",
    "    for train_index, test_index in loo.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        one_class_svm.fit(X_train_fold)\n",
    "        predictions_fold = one_class_svm.predict(X_test_fold)\n",
    "        predictions.append(predictions_fold)\n",
    "            # Print classification report for the fold\n",
    "        print(f\"Classification Report - Fold:\")\n",
    "        print(classification_report(y_test_fold,predictions_fold,zero_division=0)) \n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Combine predictions from all folds\n",
    "    predictions = np.concatenate(predictions)\n",
    "    print('concatenated predictions are')\n",
    "    print(predictions)\n",
    "    test_predictions = one_class_svm.predict(X_test)\n",
    "   \n",
    "\n",
    "\n",
    "    print(\"Final Classification Report:\")\n",
    "    report=classification_report(y_test, test_predictions, output_dict=True)\n",
    "    print(report)\n",
    "   \n",
    "    \n",
    "    # Extract metrics\n",
    "    accuracy_scores = report['accuracy']\n",
    "    mavg_precision_scores=report['macro avg']['precision']\n",
    "    mavg_recall_scores=report['macro avg']['recall']\n",
    "    mavg_f1_scores=report['macro avg']['f1-score']\n",
    "    wavg_precision_scores=report['weighted avg']['precision']\n",
    "    wavg_recall_scores=report['weighted avg']['recall']\n",
    "    wavg_f1_scores=report['weighted avg']['f1-score']\n",
    "\n",
    "    # Check if both classes are present in the testing data\n",
    "    if '1.0' in report:\n",
    "        precision_0_scores=report['1.0']['precision']\n",
    "        recall_0_scores=report['1.0']['recall']\n",
    "        f1_0_scores=report['1.0']['f1-score']\n",
    "\n",
    "    if '-1.0' in report:\n",
    "        precision_1_scores=report['-1.0']['precision']\n",
    "        recall_1_scores=report['-1.0']['recall']\n",
    "        f1_1_scores=report['-1.0']['f1-score']\n",
    "\n",
    "    \n",
    "    return (accuracy_scores, mavg_precision_scores, mavg_recall_scores, mavg_f1_scores, \n",
    "            wavg_precision_scores, wavg_recall_scores, wavg_f1_scores, \n",
    "            precision_0_scores, recall_0_scores, f1_0_scores, \n",
    "            precision_1_scores, recall_1_scores, f1_1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('svm', OneClassSVM(kernel='rbf', gamma=0.7))\n",
    "])\n",
    "\n",
    "# Prepare the data\n",
    "selected_channel_indices = [list_1.index(i) for i in selected_channels_2nd_click]\n",
    "print('selected channels indices')\n",
    "print(selected_channel_indices)\n",
    "train_healthy_psd_2nd_click = usable_features_psd_2nd_click[:16, selected_channel_indices, :]\n",
    "test_psd_2nd_click = usable_features_psd_2nd_click[16:, selected_channel_indices, :]\n",
    "train_healthy_erp_2nd_click = features_erp_2nd_click[:16, selected_channel_indices, :]\n",
    "test_erp_2nd_click = features_erp_2nd_click[16:, selected_channel_indices, :]\n",
    "\n",
    "train_healthy_features_2nd_click = np.concatenate((train_healthy_psd_2nd_click.reshape(16, -1),\n",
    "                                              train_healthy_erp_2nd_click.reshape(16, -1)), axis=1)\n",
    "chosen_indices = []\n",
    "# Remove constant features\n",
    "variances = np.var(train_healthy_features_2nd_click, axis=0)\n",
    "constant_feature_indices = np.where(variances == 0)[0]\n",
    "\n",
    "print(\"Indices of constant features:\", constant_feature_indices)\n",
    "for i in range(train_healthy_features_2nd_click.shape[1]):\n",
    "    if i in constant_feature_indices:\n",
    "        continue\n",
    "    else:\n",
    "        chosen_indices.append(i)\n",
    "print('remaining indices')\n",
    "print(chosen_indices)\n",
    "print(len(chosen_indices))\n",
    "\n",
    "usable_train_healthy_features_2nd_click = np.delete(train_healthy_features_2nd_click, constant_feature_indices, axis=1)\n",
    "\n",
    "# Prepare test data\n",
    "test_features_2nd_click = np.concatenate((test_psd_2nd_click.reshape(5, -1),\n",
    "                                     test_erp_2nd_click.reshape(5, -1)), axis=1)\n",
    "usable_test_features_2nd_click = np.delete(test_features_2nd_click, constant_feature_indices, axis=1)\n",
    "usable_train_healthy_features_2nd_click = usable_train_healthy_features_2nd_click.astype(float)\n",
    "# Remove NaN columns\n",
    "nan_indices = np.isnan(usable_train_healthy_features_2nd_click).any(axis=0)\n",
    "usable_nonnan_train_healthy_features_2nd_click = usable_train_healthy_features_2nd_click[:, ~nan_indices]\n",
    "usable_nonnan_test_features_2nd_click = usable_test_features_2nd_click[:, ~nan_indices]\n",
    "chosen_indices2 = []\n",
    "print(\"nan_indices are\")\n",
    "print(nan_indices)\n",
    "print(len(nan_indices))\n",
    "for i in range(len(nan_indices)):\n",
    "    if not nan_indices[i]:\n",
    "        chosen_indices2.append(chosen_indices[i])\n",
    "    else:\n",
    "        print(i)\n",
    "        print('the element is')\n",
    "        print(chosen_indices[i])\n",
    "\n",
    "print('chosen indices after removing Nan columns')\n",
    "print(chosen_indices2)\n",
    "# Print shape after removing NaN columns\n",
    "print(\"Shape of train_healthy_selected_features_2nd_click after removing NaN columns:\", usable_nonnan_train_healthy_features_2nd_click.shape)\n",
    "\n",
    "# Remove corresponding columns from X_test\n",
    "usable_nonnan_test_features_2nd_click = usable_test_features_2nd_click[:, ~nan_indices]\n",
    "\n",
    "print(\"Shape of X_test after removing NaN columns:\", usable_nonnan_test_features_2nd_click.shape)\n",
    "\n",
    "# Indices for training and test sets\n",
    "A_indices = list(range(11))\n",
    "B_indices = list(range(11, 16))\n",
    "\n",
    "# Lists to store metrics for each repetition\n",
    "accuracy_scores = []\n",
    "precision_0_scores = []\n",
    "precision_1_scores = []\n",
    "recall_0_scores = []\n",
    "recall_1_scores = []\n",
    "f1_0_scores = []\n",
    "f1_1_scores = []\n",
    "mavg_precision_scores = []\n",
    "mavg_recall_scores = []\n",
    "mavg_f1_scores = []\n",
    "wavg_precision_scores = []\n",
    "wavg_recall_scores = []\n",
    "wavg_f1_scores = []\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "\n",
    "\n",
    "for b_index in B_indices:\n",
    "    for a_index in A_indices:\n",
    "        current_A_indices = A_indices.copy()\n",
    "        current_A_indices[a_index] = b_index\n",
    "        \n",
    "        train_sets.append(current_A_indices)\n",
    "        print(\"training indices\")\n",
    "        print(current_A_indices)\n",
    "        test_healthy_indices= []\n",
    "        for i in range(16):\n",
    "            print(i)\n",
    "            if i in current_A_indices:\n",
    "                continue\n",
    "            else:\n",
    "                test_healthy_indices.append(i)\n",
    "            \n",
    "        \n",
    "        print(\"healthy testing indices nowwwwwwww\")\n",
    "        print(test_healthy_indices)\n",
    "\n",
    "        X_train = usable_nonnan_train_healthy_features_2nd_click[current_A_indices]\n",
    "        y_train = np.ones(X_train.shape[0])\n",
    "        print(\"initial shape of usable_nonnan_train_healthy_features_2nd_click\")\n",
    "        print(usable_nonnan_train_healthy_features_2nd_click.shape)\n",
    "        print(\"selecting features fromit\")\n",
    "        print(test_healthy_indices)\n",
    "        test_healthy_features = usable_nonnan_train_healthy_features_2nd_click[test_healthy_indices]\n",
    "        print(\"shape of remaining healthy subjects to be used for testing\")\n",
    "        print(test_healthy_features.shape)\n",
    "\n",
    "        # Combine the test healthy features with MCI features\n",
    "        X_test = np.vstack((test_healthy_features, usable_nonnan_test_features_2nd_click))\n",
    "        y_test = np.concatenate((np.ones(test_healthy_features.shape[0]), -1 * np.ones(usable_nonnan_test_features_2nd_click.shape[0])))\n",
    "\n",
    "        print(\"Shape of train and test features\")\n",
    "        print(X_train.shape)\n",
    "        print(y_train)\n",
    "  \n",
    "        print(\"length of testing data\")\n",
    "        print(X_test.shape)\n",
    "        print(y_test)\n",
    "        # Evaluate performance\n",
    "        accuracy_score, mavg_precision_score, mavg_recall_score, mavg_f1_score, wavg_precision_score, wavg_recall_score, wavg_f1_score, precision_0_score, recall_0_score, f1_0_score, precision_1_score, recall_1_score, f1_1_score = evaluate_performance(X_train, X_test, y_test)\n",
    "        accuracy_scores.append(accuracy_score)\n",
    "        mavg_precision_scores.append(mavg_precision_score)\n",
    "        mavg_recall_scores.append(mavg_recall_score)\n",
    "        mavg_f1_scores.append(mavg_f1_score)\n",
    "        wavg_precision_scores.append(wavg_precision_score)\n",
    "        wavg_recall_scores.append(wavg_recall_score)\n",
    "        wavg_f1_scores.append(wavg_f1_score)\n",
    "        precision_0_scores.append(precision_0_score)\n",
    "        recall_0_scores.append(recall_0_score)\n",
    "        f1_0_scores.append(f1_0_score)\n",
    "        precision_1_scores.append(precision_1_score)\n",
    "        recall_1_scores.append(recall_1_score)\n",
    "        f1_1_scores.append(f1_1_score)\n",
    "# Print results\n",
    "print('accuracy_scores are')\n",
    "print(accuracy_scores)\n",
    "print(\"Accuracy: {:.2f}  {:.2f}\".format(np.mean(accuracy_scores), np.std(accuracy_scores)))\n",
    "print(\"Precision (class 0): {:.2f}  {:.2f}\".format(np.mean(precision_0_scores), np.std(precision_0_scores)))\n",
    "print(\"Precision (class 1): {:.2f}  {:.2f}\".format(np.mean(precision_1_scores), np.std(precision_1_scores)))\n",
    "print(\"Recall (class 0): {:.2f}  {:.2f}\".format(np.mean(recall_0_scores), np.std(recall_0_scores)))\n",
    "print(\"Recall (class 1): {:.2f}  {:.2f}\".format(np.mean(recall_1_scores), np.std(recall_1_scores)))\n",
    "print(\"F1-score (class 0): {:.2f}  {:.2f}\".format(np.mean(f1_0_scores), np.std(f1_0_scores)))\n",
    "print(\"F1-score (class 1): {:.2f}  {:.2f}\".format(np.mean(f1_1_scores), np.std(f1_1_scores)))\n",
    "print(\"Macro avg precision: {:.2f}  {:.2f}\".format(np.mean(mavg_precision_scores), np.std(mavg_precision_scores)))\n",
    "print(\"Macro avg recall: {:.2f}  {:.2f}\".format(np.mean(mavg_recall_scores), np.std(mavg_recall_scores)))\n",
    "print(\"Macro avg f1-score: {:.2f}  {:.2f}\".format(np.mean(mavg_f1_scores), np.std(mavg_f1_scores)))\n",
    "print(\"Weighted avg precision: {:.2f}  {:.2f}\".format(np.mean(wavg_precision_scores), np.std(wavg_precision_scores)))\n",
    "print(\"weighted avg recall: {:.2f}  {:.2f}\".format(np.mean(wavg_recall_scores), np.std(wavg_recall_scores)))\n",
    "print(\"weighted avg f1-score: {:.2f}  {:.2f}\".format(np.mean(wavg_f1_scores), np.std(wavg_f1_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e46cf",
   "metadata": {},
   "source": [
    "## visualization of channel subsets being used for different anomaly detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels=['MEG0112+0113',\n",
    " 'MEG0122+0123',\n",
    " 'MEG0132+0133',\n",
    " 'MEG0142+0143',\n",
    " 'MEG0212+0213',\n",
    " 'MEG0222+0223',\n",
    " 'MEG0232+0233',\n",
    " 'MEG0242+0243',\n",
    " 'MEG0312+0313',\n",
    " 'MEG0322+0323',\n",
    " 'MEG0332+0333',\n",
    " 'MEG0342+0343',\n",
    " 'MEG0412+0413',\n",
    " 'MEG0422+0423',\n",
    " 'MEG0432+0433',\n",
    " 'MEG0442+0443',\n",
    " 'MEG0512+0513',\n",
    " 'MEG0522+0523',\n",
    " 'MEG0532+0533',\n",
    " 'MEG0542+0543',\n",
    " 'MEG0612+0613',\n",
    " 'MEG0622+0623',\n",
    " 'MEG0632+0633',\n",
    " 'MEG0642+0643',\n",
    " 'MEG0712+0713',\n",
    " 'MEG0722+0723',\n",
    " 'MEG0732+0733',\n",
    " 'MEG0742+0743',\n",
    " 'MEG0812+0813',\n",
    " 'MEG0822+0823',\n",
    " 'MEG0912+0913',\n",
    " 'MEG0922+0923',\n",
    " 'MEG0932+0933',\n",
    " 'MEG0942+0943',\n",
    " 'MEG1012+1013',\n",
    " 'MEG1022+1023',\n",
    " 'MEG1032+1033',\n",
    " 'MEG1042+1043',\n",
    " 'MEG1112+1113',\n",
    " 'MEG1122+1123',\n",
    " 'MEG1132+1133',\n",
    " 'MEG1142+1143',\n",
    " 'MEG1212+1213',\n",
    " 'MEG1222+1223',\n",
    " 'MEG1232+1233',\n",
    " 'MEG1242+1243',\n",
    " 'MEG1312+1313',\n",
    " 'MEG1322+1323',\n",
    " 'MEG1332+1333',\n",
    " 'MEG1342+1343',\n",
    " 'MEG1412+1413',\n",
    " 'MEG1422+1423',\n",
    " 'MEG1432+1433',\n",
    " 'MEG1442+1443',\n",
    " 'MEG1512+1513',\n",
    " 'MEG1522+1523',\n",
    " 'MEG1542+1543',\n",
    " 'MEG1612+1613',\n",
    " 'MEG1622+1623',\n",
    " 'MEG1632+1633',\n",
    " 'MEG1642+1643',\n",
    " 'MEG1712+1713',\n",
    " 'MEG1722+1723',\n",
    " 'MEG1732+1733',\n",
    " 'MEG1742+1743',\n",
    " 'MEG1822+1823',\n",
    " 'MEG1842+1843',\n",
    " 'MEG1922+1923',\n",
    " 'MEG1932+1933',\n",
    " 'MEG1942+1943',\n",
    " 'MEG2012+2013',\n",
    " 'MEG2022+2023',\n",
    " 'MEG2032+2033',\n",
    " 'MEG2042+2043',\n",
    " 'MEG2112+2113',\n",
    " 'MEG2122+2123',\n",
    " 'MEG2132+2133',\n",
    " 'MEG2142+2143',\n",
    " 'MEG2212+2213',\n",
    " 'MEG2222+2223',\n",
    " 'MEG2232+2233',\n",
    " 'MEG2312+2313',\n",
    " 'MEG2332+2333',\n",
    " 'MEG2412+2413',\n",
    " 'MEG2422+2423',\n",
    " 'MEG2432+2433',\n",
    " 'MEG2442+2443',\n",
    " 'MEG2512+2513',\n",
    " 'MEG2522+2523',\n",
    " 'MEG2532+2533',\n",
    " 'MEG2542+2543',\n",
    " 'MEG2612+2613',\n",
    " 'MEG2622+2623',\n",
    " 'MEG2642+2643']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f798f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels_1st_click=['MEG1342+1343','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG0112+0113','MEG0122+0123','MEG0222+0223','MEG1122+1123','MEG1222+1223','MEG0142+0143','MEG1512+1513','MEG1542+1543','MEG1812+1813','MEG1622+1623','MEG1522+1523','MEG1612+1613']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels_2nd_click=['MEG1622+1623','MEG1342+1343','MEG1632+1633','MEG0232+0233','MEG0242+0243','MEG0112+0113','MEG0122+0123','MEG0142+0143','MEG1512+1513','MEG1542+1543','MEG1812+1813','MEG1622+1623','MEG1522+1523','MEG1612+1613']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "# Load layout file\n",
    "layout = mne.channels.read_layout('neuromag306cmb.lay')\n",
    "\n",
    "# List of channels you want to plot\n",
    "channels_to_plot = ['MEG0112+0113', 'MEG0122+0123', 'MEG0132+0133']  # Add your channels here\n",
    "\n",
    "# Create figure\n",
    "fig = mne.viz.plot_layout(layout, show=False)\n",
    "\n",
    "# Plot channel locations\n",
    "for ch in layout.names[:102]:\n",
    "    color = 'r' if ch in selected_channels else 'k'\n",
    "    pos = layout.pos[layout.names.index(ch)]\n",
    "    fig.gca().plot(pos[0], pos[1], 'o', color=color)\n",
    "plt.rcParams.update({'font.size': 4})\n",
    "plt.tight_layout()\n",
    "plt.savefig('channel_locations_rs.jpeg', format='jpeg')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "# Load layout file\n",
    "layout = mne.channels.read_layout('neuromag306cmb.lay')\n",
    "\n",
    "# Create figure\n",
    "fig = mne.viz.plot_layout(layout, show=False)\n",
    "\n",
    "# Plot channel locations\n",
    "for ch in layout.names[:102]:\n",
    "    color = 'r' if ch in selected_channels_1st_click else 'k'\n",
    "    pos = layout.pos[layout.names.index(ch)]\n",
    "    fig.gca().plot(pos[0], pos[1], 'o', color=color)\n",
    "plt.rcParams.update({'font.size': 4})\n",
    "plt.tight_layout()\n",
    "plt.savefig('channel_locations_2nd_click.jpeg', format='jpeg')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "# Load layout file\n",
    "layout = mne.channels.read_layout('neuromag306cmb.lay')\n",
    "\n",
    "# Create figure\n",
    "fig = mne.viz.plot_layout(layout, show=False)\n",
    "\n",
    "# Plot channel locations\n",
    "for ch in layout.names[:102]:\n",
    "    color = 'r' if ch in selected_channels_2nd_click else 'k'\n",
    "    pos = layout.pos[layout.names.index(ch)]\n",
    "    fig.gca().plot(pos[0], pos[1], 'o', color=color)\n",
    "plt.rcParams.update({'font.size': 4})\n",
    "plt.tight_layout()\n",
    "plt.savefig('channel_locations_2nd_click.jpeg', format='jpeg')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293de1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
